{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83d\udc4b Hi! I\u2019m Tom","text":""},{"location":"#hi-im-tom","title":"\ud83d\udc4b Hi! I\u2019m Tom","text":"<p>\ud83d\udcbb Passionate Programmer | \ud83c\udfa8 Hobbyist Painter | \ud83d\udcd6 Philosophy Enthusiast</p> <p>Here\u2019s the entrance to my \ud83d\ude80 Blog, where I share my study notes \ud83d\udcdd and daily thoughts \ud83d\udcad.</p>"},{"location":"#workstation","title":"\ud83d\udda5\ufe0f Workstation","text":"<p>LINUX I use Arch(1), btw \ud83e\udd13</p> <ol> <li>Actually I use endeavouros, not a pure Arch, forgive me!</li> </ol> <p>\ud83d\udcdd My-Linux-Config</p>"},{"location":"#programming-languages","title":"\ud83d\udee0\ufe0f Programming Languages","text":"<ul> <li> <p>\u2615 Java earn for a living</p> </li> <li> <p>\ud83d\udc0d Python write interesting scripts</p> </li> <li> <p>\u26a1 C/C++ explore computer science basics</p> </li> <li> <p>\ud83d\udcdc Shell enjoy linux</p> </li> </ul>"},{"location":"#other-interests","title":"\ud83c\udfa8 Other Interests","text":"<p>\u2728 I also dabble in painting \ud83d\udd8c\ufe0f and enjoy philosophy \ud83d\udcda.</p>"},{"location":"art/","title":"Overview","text":""},{"location":"art/#art","title":"Art","text":"<p>\u6211\u4ece\u6765\u6ca1\u6709\u7cfb\u7edf\u7684\u5b66\u4e60\u8fc7\u753b\u753b\uff0c\u53ef\u662f\u6211\u559c\u6b22\u753b\u753b\u3002\u4ee3\u7801\uff0c\u7ed8\u753b\u90fd\u662f\u521b\u4f5c\u7684\u8fc7\u7a0b\uff0c\u4eba\u7c7b\u521b\u9020\u7684\u5feb\u4e50\u4f30\u8ba1\u548c\u4e0a\u5e1d\u521b\u9020\u4e07\u7269\u65f6\u4e00\u6837\u5427\u3002\u6211\u7684\u8fd9\u4e9b\u4e71\u6d82\u4e71\u753b\u6709\u4e9b\u662f\u5fc3\u60c5\u70e6\u95f7\u65f6\u7684\u6292\u53d1\uff0c\u6709\u4e9b\u662f\u9762\u5bf9\u56f0\u987f\u3001\u865a\u65e0\u65f6\u7684\u81ea\u6211\u9f13\u52b1\u3002\u65e0\u8bba\u672c\u8d28\u662f\u5426\u5b58\u5728\uff0c\u662f\u4e0a\u5e1d\u65e2\u5b9a\u597d\u7684\uff0c\u6216\u662f\u8981\u4eba\u4eec\u901a\u8fc7\u5b9e\u8df5\u800c\u5f97\u51fa\u7684\uff0c\u827a\u672f\u4e00\u5b9a\u662f\u5728\u901a\u5f80\u672c\u8d28\u7684\u8def\u4e0a\u6700\u597d\u7684\u5b89\u6170\u3002\u4e5f\u8bb8\u6211\u4eec\u4e00\u751f\u90fd\u65e0\u6cd5\u8fbe\u5230\u7406\u60f3\uff0c\u53ef\u662f\u6211\u4eec\u81ea\u7531\u521b\u9020\u7684\u4e00\u5207\uff0c\u90fd\u662f\u6211\u4eec\u5bf9\u672c\u8d28\u7684\u771f\u5207\u56de\u5e94\uff01</p> <p>I've never systematically learned how to draw, but I love painting. Coding and painting are both acts of creation\u2014perhaps the joy of human creation is akin to the joy God felt when creating the world. Some of my doodles are expressions of frustration, while others are self-encouragement in the face of hardship and nihilism. Regardless of whether essence exists\u2014whether it is predetermined by God or something we must discover through practice\u2014art is surely the greatest solace on the journey toward it. Perhaps we may never reach the ideal in our lifetime, but everything we freely create is our genuine response to the essence of things!</p>"},{"location":"art/collection1/","title":"Collection1","text":""},{"location":"art/collection1/#collection1","title":"Collection1","text":"My Avatar Father and Son Depature Kids or Not? Void or Not?"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2025/06/23/boundaries/","title":"Boundaries","text":"","tags":["clean code"]},{"location":"blog/2025/06/23/boundaries/#boundaries","title":"Boundaries","text":"<p>We seldom control all the software in our systems. Sometimes we buy third-party packages or use open source. Other times we depend on teams in our own company to produce components or subsystems for us. Somehow we must cleanly integrate this foreign code with our own.</p>","tags":["clean code"]},{"location":"blog/2025/06/23/boundaries/#using-third-party-code","title":"Using Third-Party Code","text":"<ul> <li> <p>Natural tension between the provider of an interface and the user of an interface.</p> <ul> <li> <p>Providers of third-party packages and frameworks strive for broad applicability so they can work in many environments and appeal to a wide audience.</p> </li> <li> <p>Users, on the other hand, want an interface that is focused on their particular needs. This tension can cause problems at the boundaries of our systems.</p> </li> </ul> </li> </ul>","tags":["clean code"]},{"location":"blog/2023/05/30/categorical-propositions/","title":"Categorical propositions","text":"<ul> <li>Four Kinds of Categorical propositions</li> <li>A: Universal Affirmative propositions</li> <li>E: Universal Negative propositions</li> <li>I: Particular Affirmative propositions</li> <li> <p>O: Particular Negative propositions </p> </li> <li> <p>Quality, Quantity and Distribution</p> </li> <li>Quality</li> <li>Quantity</li> <li>General Schema</li> <li>Distribution</li> <li>The traditional square of opposition</li> <li>Contradictories</li> <li>Contraries<ul> <li>Contingent</li> </ul> </li> <li>Subcontraries</li> <li>Subalternation</li> <li>The Square of Opposition</li> <li>Immediate Inferences</li> <li>Further Immediate Inferences</li> <li>Conversion</li> <li>Classes and Class Complements</li> <li>Obversion</li> <li>Contraposition</li> <li>Existential Import and the Interpretation of Categorical Propositions</li> <li>Existential Import</li> <li> Boolean Interpretation of categorical logic </li> </ul>"},{"location":"blog/2023/05/30/categorical-propositions/#four-kinds-of-categorical-propositions","title":"Four Kinds of Categorical propositions","text":""},{"location":"blog/2023/05/30/categorical-propositions/#a-universal-affirmative-propositions","title":"A: Universal Affirmative propositions","text":"All S is P"},{"location":"blog/2023/05/30/categorical-propositions/#e-universal-negative-propositions","title":"E: Universal Negative propositions","text":"No S is P"},{"location":"blog/2023/05/30/categorical-propositions/#i-particular-affirmative-propositions","title":"I: Particular Affirmative propositions","text":"Some S is P"},{"location":"blog/2023/05/30/categorical-propositions/#o-particular-negative-propositions","title":"O: Particular Negative propositions","text":"Some S is not P"},{"location":"blog/2023/05/30/categorical-propositions/#quality-quantity-and-distribution","title":"Quality, Quantity and Distribution","text":""},{"location":"blog/2023/05/30/categorical-propositions/#quality","title":"Quality","text":"<ul> <li>Affirmative(A, I): the propositions affirms some class inclusion, whether complete or   partial.</li> <li>Negative(E, O): the propositions denies some class inclusion, whether complete or   partial.</li> </ul>"},{"location":"blog/2023/05/30/categorical-propositions/#quantity","title":"Quantity","text":"<ul> <li>Universal(A, E): the propositions refers to <code>all members</code> of the class as its subjects.</li> <li>Particular(I, O): the propositions refers only to <code>some members</code> of the class designated   by its subject.</li> </ul>"},{"location":"blog/2023/05/30/categorical-propositions/#general-schema","title":"General Schema","text":"Quantifier + Subject + Copula + Predicate"},{"location":"blog/2023/05/30/categorical-propositions/#distribution","title":"Distribution","text":"<p>A proposition distributes a term if it refers to <code>all members</code> of the class designated by that term.</p> <ul> <li>the quantity of any standard-form Categorical proposition determines whether   its subject term is distributed or undistributed.</li> <li>the quality of any standard-form Categorical proposition determines whether   its predicate term is distributed or undistributed.</li> </ul> Predicate term undistributed Predicate term distributed Subject term distributed A: All S is P E: No S is P Subject term undistributed I: Some S is P O: Some S is not P"},{"location":"blog/2023/05/30/categorical-propositions/#the-traditional-square-of-opposition","title":"The traditional square of opposition","text":"<ul> <li>Opposition: Standard-form categorical propositions having the same subject   terms and the same predicate may differ from each other in quality or in   quantity or in both. Any such kind of differing has been traditionally called   <code>opposition</code>.</li> <li>Differ in quality: contraries &amp; subcontraries</li> <li>Differ in quantity: subalternation</li> <li>Differ in both quality and quantity: contradictories</li> </ul>"},{"location":"blog/2023/05/30/categorical-propositions/#contradictories","title":"Contradictories","text":"<ul> <li>Two propositions are contradictories if one is the denial or negation of the other.</li> <li>They can not be both true and cannot be both false.</li> <li>Example:</li> </ul> <pre><code>A: All judges are lawyers.\nO: Some judges are not lawyers.\nBoth opposed in quality and quantity.\n</code></pre> <pre><code>E: No politicians are idealists.\nI: Some politicians are idealists.\nBoth opposed in quality and quantity.\n</code></pre>"},{"location":"blog/2023/05/30/categorical-propositions/#contraries","title":"Contraries","text":"<ul> <li>Two propositions are said to be contraries if they cannot both be true.</li> <li>The truth of one entails the falsity of the other.</li> <li>But both can be false</li> <li>Example:</li> </ul> <pre><code>P1: Texas will win the coming game with Oklahoma.\nP2: Oklahoma will win the coming game with Texas.\n\nThe truth of P1 entails the falsity of P2.\nThe truth of P2 entails the falsity of P1.\nP1 and P2 can also be false since Texas and Oklahoma could be a draw.\n\nA: All poets are dreamers.\nE: No poets are dreamers.\nA and E can not both be true, but can both be false(Some poets are dreamers).\n</code></pre>"},{"location":"blog/2023/05/30/categorical-propositions/#contingent","title":"Contingent","text":"<p>A and E cannot be regarded as contraries when either the A or E proposition is necessarily true, if either is a logical or mathematical truth.</p> <pre><code>A: All squares are rectangles.\nE: No squares are rectangles.\n</code></pre> <p>Here, E is a mathematical truth, it has no possibility to be false. So, A and E are not contraries. Since two propositions can only be contraries if they can be both false.</p> <p><code>Contingent</code>: Propositions that are neither necessarily true nor necessarily false are said to be <code>contingent</code>.</p>"},{"location":"blog/2023/05/30/categorical-propositions/#subcontraries","title":"Subcontraries","text":"<ul> <li>Two propositions are said to be <code>Subcontraries</code> if they cannot both be false,</li> <li>They may both be true.</li> <li>Examples:</li> </ul> <pre><code>I: Some diamonds are precious stones.\nO: Some diamonds are not precious stones.\n</code></pre> <ul> <li> Contingent</li> </ul> <pre><code>I: Some squares are rectangles.\nO: Some squares are not rectangles.\n\nHere, I can never be true, so I and O can not be Subcontraries.\n</code></pre>"},{"location":"blog/2023/05/30/categorical-propositions/#subalternation","title":"Subalternation","text":"<ul> <li> <p>Two propositions have the same subject and same predicate terms, and   agree in quality (both affirming or both denying) but differ in quantity (one universal, the other particular). They are called <code>Corresponding Propositions</code>.</p> </li> <li> <p>The opposition between a universal proposition and its corresponding particular   proposition is known as <code>Subalternation</code>.</p> </li> <li> <p>In classic analysis, the superaltern implies the truth of the subaltern.</p> </li> <li>Example:</li> </ul> <pre><code>A: All spiders are eight-legged animals. (superaltern of I)\nI: Some spiders are eight-legged animals. (subalternation of A)\n\nE: No whales are fishes. (superaltern of O)\nO: Some whales are not fishes. (subalternation of E)\n</code></pre>"},{"location":"blog/2023/05/30/categorical-propositions/#the-square-of-opposition","title":"The Square of Opposition","text":""},{"location":"blog/2023/05/30/categorical-propositions/#immediate-inferences","title":"Immediate Inferences","text":"<ul> <li>A is given as true:E is false; I is true; O is false.</li> <li>E is given as true:A is false; I is false; O is true.</li> <li>I is given as true:E is false; A and O are undetermined.</li> <li>O is given as true:A is false; E and I are undetermined.</li> <li>A is given as false:O is true; E and I are undetermined.</li> <li>E is given as false:I is true; A and O are undetermined.</li> <li>I is given as false:A is false; E is true; O is true.</li> <li>O is given as false:A is true; E is false; I is true.</li> </ul>"},{"location":"blog/2023/05/30/categorical-propositions/#further-immediate-inferences","title":"Further Immediate Inferences","text":"<ul> <li>Interchange S and P: Conversion</li> <li>Change quality &amp; turn P to non-P: Obversion</li> <li>Interchange S and P &amp; turn S, P to non-S, non-P: Contraposition</li> </ul>"},{"location":"blog/2023/05/30/categorical-propositions/#conversion","title":"Conversion","text":"<p><code>conversion</code> is an inference that proceeds by interchanging the subject and predicate terms of a proposition.</p> <pre><code>E proposition\nP1: No men are angles.\nP2: No angles are men.\n-------------\nI proposition\nP3: Some writers are women.\nP4: Some women are writers.\n</code></pre> <ul> <li>Conversion is perfectly valid for all E and I propositions.</li> <li>The conversion of an O propositions is not valid.</li> </ul> <pre><code>P1: Some animals are not dogs.\nP2: Some dogs are not animals.\n</code></pre> <ul> <li>Conversion of A is special</li> </ul> <pre><code>A: All dogs are animals.\nConverse: All animals are dog. (X)\n</code></pre> <p>However, we can use <code>subaltern</code> to do Conversion by limitation</p> <pre><code>graph TD;\n\"\"A[\"A: All dogs are animals\"] --&gt; I[\"I: Some dogs are animals\"]\nI --conversion--&gt; I1[\"I1: Some animals are dogs\"]\n\n\na[\"A: All S is P\"] --&gt; i[\"I: Some P is S\"]</code></pre> <ul> <li>Summary</li> </ul> Convertend Converse A: All S is P I: Some P is S(by limitation) E: No S is P E: No P is S I: Some S is P I: Some P is S O: Some S is not P Not valid"},{"location":"blog/2023/05/30/categorical-propositions/#classes-and-class-complements","title":"Classes and Class Complements","text":"<p>Every class has, associated with it, a complementary class, or complement, which is the collection of all things that do not belong to the original class.</p> <ul> <li>Examples:</li> </ul> <pre><code>Class: People\nComplement (Class of Non-persons): Contains no People, but contains everything else.\n</code></pre> <ul> <li>Contrary and complementary terms</li> </ul> <pre><code>Contraries: hero, coward\nComplementary: hero, non-hero\ncoward is not non-hero!!!\n</code></pre>"},{"location":"blog/2023/05/30/categorical-propositions/#obversion","title":"Obversion","text":"<p>Obversion: change its quality and replace the predicate term with its complement.</p> <ul> <li>Obversion of A == E</li> </ul> <pre><code>A: All residents are voters.\nObverse:\nE: No residents are non-voters.\n</code></pre> <ul> <li>Obversion of E == A</li> </ul> <pre><code>E: No umpires are partisans.\nObverse:\nA: All umpires are Non-partisans.\n</code></pre> <ul> <li>Obversion of I == O</li> </ul> <pre><code>I: Some mentals are conductors.\nObverse:\nO: Some mentals are not non-conductors.\n</code></pre> <ul> <li>Obversion of O == I</li> </ul> <pre><code>O: Some nations were not belligerents.\nObverse:\nI: Some nations were non-belligerents.\n</code></pre> <ul> <li>Summary</li> </ul> Obvertend Obverse A: All S is P E: No S is non-P E: No S is P A: All S is non-P I: Some S is P O: Some S is not non-P O: Some S is not P I: Some S is non-P"},{"location":"blog/2023/05/30/categorical-propositions/#contraposition","title":"Contraposition","text":"<p>Contraposition:</p> <ul> <li>replace the subject term with the complement of its   predicate term</li> <li>and replace its predicate term with the complement of its subject   term.</li> <li>Neither the quality nor the quantity of the original proposition is changes</li> </ul> <ul> <li>Contraposition of A == A</li> </ul> <pre><code>A: All members are voters.\nContraposition\nA: All non-voters are non-members.\n\n--- My example ---\nA: All dogs are animals.\nContraposition\nA: All non-animals are non-dogs.\n</code></pre> <ul> <li>Contraposition of O == O</li> </ul> <pre><code>O: Some students are not idealists.\nContraposition\nO: Some non-idealists are not non-students\n</code></pre> <p>Another way to explain Contraposition of O</p> <pre><code>graph TD;\nO[\"O: Some S is not P\"] -- obverts--&gt; I[\"I: Some S is non-P\"];\nI -- conversion--&gt; I1[\"I1: Some non-P is S\"]\nI1 -- obverts--&gt; O1[\"O1: Some non-P is not non-S\"]</code></pre> <ul> <li>Contraposition of I != I</li> </ul> <pre><code>I: Some citizens are nonlegislators.\nContraposition\nI: Some legislators are non-citizens.\n</code></pre> <p>Another way to explain the Contraposition of I</p> <pre><code>graph TD;\nI[\"I: Some S is P\"] -- obverts--&gt; O[\"O: Some S is not non-P\"];\nO -- conversion--&gt; O1[\"O1: Some non-P is not S\"]\nO -- not equal --&gt; O1</code></pre> <ul> <li>Contraposition of E != E, however.</li> </ul> <pre><code>E: No wrestlers are weaklings.\nContraposition\nE: No non-weakings are non-wrestlers.\n</code></pre> <pre><code>graph TD;\nE[E: No S is P] -- obverts--&gt; A[A: All S is non-P]\nA -- converts by limitation--&gt; I[I: Some non-P is S]\nI -- obverts--&gt; O[O: Some non-P is not non-S]\nE -- Contraposition by limitation--&gt; O</code></pre> <ul> <li> <p>Summary</p> </li> <li> <p>Contraposition is thus seen to be valid only when applied to A and O propositions.</p> </li> <li>Not valid at all for I proposition.</li> <li>Valid for E only by limitations.</li> </ul> Premise Contraposition A: All S is P A: All non-P is non-S E: No S is P O: Some non-P is not non-S(by limitation) I: Some S is P not valid O: Some S is not P O: Some non-P is not non-S"},{"location":"blog/2023/05/30/categorical-propositions/#existential-import-and-the-interpretation-of-categorical-propositions","title":"Existential Import and the Interpretation of Categorical Propositions","text":""},{"location":"blog/2023/05/30/categorical-propositions/#existential-import","title":"Existential Import","text":"<p>Existential Import: A proposition is said to have existential import if it typically is uttered to assert the existence of objects of some kind.</p> <ul> <li>Consequences of existential import</li> </ul> <p>I and O propositions have existential import.</p> <pre><code>I: Some soldiers are heroes.\n--&gt; there exists at least one soldier who is a hero.\nO: Some dogs are not companions.\n--&gt; there exists at least one dog that is not a companion.\n</code></pre> <p>In earlier introduction we supposed that an I   proposition follows validly from its corresponding A proposition by   subalternation. Similarly, we supposed that an O proposition follows   validly from its corresponding E proposition.</p> <p>Therefore, if I and O propositions have existential import and they follow   validly from their corresponding A and E propositions, then A and E   propositions must also have existential import. Because a proposition with   existential import cannot be derived validly from another that does not have   such import.</p> <ul> <li>The problem of the Consequences</li> </ul> <p>In traditional square of opposition, A and O   propositions are contradictories. Contradictories can not both be true and   both be false. They can only be one true and one false.</p> <pre><code>A: All inhabitants of Mars are blonde.\nContradictories\nO: Some inhabitants of Mars are not blonde.\n</code></pre> <p>If we interpreted A and O as asserting that there are inhabitants of Mars,   then both of these propositions are false if Mars has no inhabitants.</p> <p> So A and O are not Contradictories!!!</p> <ul> <li>How to solve the Problem?</li> </ul> <p>To rescue the square of opposition, we might insist that all propositions(A,   E, I, O) PRESUPPOSE that the classes to which they refer do have   members.</p> <p>To achieve this result, however, we must pay by accepting the blanket presupposition that all classes(including their complements) designated by our terms do have members---are not empty.</p> <ul> <li> <p>The cost of blanket presupposition</p> </li> <li> <p>we will never be able to formulate the proposition that denies that the     class has members. Example:</p> <pre><code>No unicorns are creatures that exist.\n</code></pre> </li> <li> <p>even ordinary usage of language is not in complete accord with this     blanket presupposition. \"All\" may refer to possibly empty classes.</p> <pre><code>\"All trespassers will be prosecuted.\"\nThe speaker said this would be intending to ensure that the class will\nbecome and remain empty.\n</code></pre> </li> <li> <p>In science and other theoretical spheres, we often wish to reason without     making any presupposition about existence. Example,</p> <p>Newton\u2019s first law of motion, for example, asserts that certain things are true about bodies that are not acted on by any external forces: They remain at rest, or they continue their straight-line motion. The law may be true; a physicist may wish to express and defend it without wanting to presuppose that there actually are any bodies that are not acted on by external forces.</p> </li> </ul>"},{"location":"blog/2023/05/30/categorical-propositions/#boolean-interpretation-of-categorical-logic","title":"Boolean Interpretation of categorical logic","text":"<ol> <li>I and O propositions continue to have existential import in the    Boolean Interpretation.</li> </ol> <p>However, if the class S is empty, the propositions \"Some S is not P\" and    \"Some S is P\" are both false.</p> <ol> <li>A and E are the contradictories of the particular propositions, O    and I.</li> </ol> <p>However, in the boolean interpretation, universal propositions are    interpreted as having no existential import.</p> <pre><code>A and E can both be true even if there might be no unicorns\nA: All unicorns have horns.\nE: No unicorns have wings.\n--------------------------\nI and O will both be false if there are no unicorns.\nI: Some unicorns have horns.\nO: Some unicorns do not have wings.\n</code></pre> <ol> <li>If we utter a universal proposition with which we do intend to assert    existence. Boolean interpretation permits this to be expressed.</li> </ol> <p>However, it requires two propositions.</p> <ul> <li>one existential in force but particular.</li> <li>the other universal but not existential in force.</li> </ul> <pre><code>\"All planets in our solar system revolve around the sun.\"\n--&gt; A universal proposition that has no existential import.\n\nif we express the propositon intending also to assert the existence of\nplanets in our solar system that do so revolve, we would need to add:\n\n\"mars is a planet in our solar system.\"\n--&gt; A particular proposition that has desired existential force.\n</code></pre> <ol> <li> <p>Changes from adoption of Boolean interpretation</p> </li> <li> <p>Corresponding A and E propositions can both be true and are   therefore   not contraries. This may seem paradoxical, but look at the example:</p> </li> </ol> <pre><code>A: All unicorns have wings.\n--&gt; if there is a unicorn, then it has wings.\nE: No unicorns have wings.\n--&gt; if there is a unicorn, then it does not have wings.\n</code></pre> <p>If there is no unicorn, then A and E can both be true.</p> <ul> <li>Corresponding I and O propositions can both be false and are   therefore not subcontraries.</li> </ul> <pre><code>I: Some unicorns have wings.\nO: Some unicorns does not have wings.\n</code></pre> <p>I and O have existential import, if unicorn does not exist, then they both be   false.</p> <ul> <li>Subalternation is not valid.</li> </ul> <p>Because one may not validly infer a proposition that has existential import   from one that does not.</p> <ol> <li> <p>Immediate Inferences in Boolean Interpretation</p> </li> <li> <p>Conversion for E and I is preserved.</p> </li> <li>Contraposition for A and O is preserved.</li> <li>Obversion for any proposition is preserved.</li> <li> <p>Conversion by limitation and Contraposition by limitation are not valid.</p> </li> <li> <p>Summary</p> </li> </ol> <p>The traditional square of opposition, in the Boolean Interpretation, is transformed in the following general way:</p> <ul> <li>Relations along the side of the square are undone.</li> <li>Relations along the diagonal, contradictory relations remain in force.</li> </ul> <p>In short, the blanket existential presupposition is rejected by modern logicians. It is a mistake, we hold, to assume that a class has members if it is not asserted explicitly that it does. Any argument that relies on this mistaken assumption is said to commit the fallacy of existential assumption, or more briefly, the existential fallacy.</p>"},{"location":"blog/2023/05/30/categorical-propositions/#symbolism-and-diagrams-for-categorical-propositions","title":"Symbolism and Diagrams for Categorical Propositions","text":"<ul> <li> <p>To say that a class designated by the term S has no members:   $$ S = 0 $$</p> </li> <li> <p>To say that a class designated by the term S has members:   $$ S \\neq 0 $$</p> </li> <li> <p>To symbolize a class designated by the term non-S:   $$ \\bar S$$</p> </li> </ul>"},{"location":"blog/2023/05/30/categorical-propositions/#symbolic-representation-of-categorical-propositions","title":"Symbolic Representation of Categorical Propositions","text":"Form Propositon Symbolic Representation A All S is P \\(S \\bar P = 0\\) E No S is P \\(S  P = 0\\) I Some S is P \\(S P \\neq 0\\) O Some S is not P \\(S \\bar P \\neq 0\\)"},{"location":"blog/2023/05/30/categorical-propositions/#venn-graph-representation","title":"Venn Graph Representation","text":""},{"location":"blog/2023/05/20/categorical-syllogisms/","title":"Categorical Syllogisms","text":"<ul> <li>Standard-Form Categorical Syllogisms</li> <li>Terms of the Syllogisms: Major, Minor, and Middle</li> <li>The mood of the Syllogism</li> <li> <p>The figure of the Syllogism </p> </li> <li> <p>The Formal Nature of Syllogistic Argument</p> </li> <li>Venn Diagram Technique for Testing Syllogisms</li> <li>Example: Venn Graph for AAA-1</li> <li>Diagram the universal premise first</li> <li> Put x at border</li> <li>Technique Summary</li> <li>Why Venn Diagram can tell the validity?</li> <li>Syllogistic Rules and Syllogistic Fallacies</li> <li>Rule 1: Avoid Four Terms</li> <li>Rule 2: Distribute the middle term in at least one premise</li> <li>Rule 3: Any term distributed in the conclusion must be distributed in the premises.</li> <li>Rule 4: Avoid two negative premises</li> <li>Rule 5: If either premise is negative, the conclusion must be negative</li> <li>Rule 6: From two universal premises no particular conclusion may be drawn</li> <li> Exposition of the Fifteen Valid Forms of the Categorical Syllogism</li> </ul>"},{"location":"blog/2023/05/20/categorical-syllogisms/#standard-form-categorical-syllogisms","title":"Standard-Form Categorical Syllogisms","text":"<p>Categorical Syllogisms is defined as a deductive argument consisting of three categorical propositions that together contain exactly three terms, each of which occurs in exactly two of the constituent propositions.</p> <ul> <li>Standard-Form</li> </ul> <p>A Categorical Syllogisms is said to be <code>Standard-Form</code> when two things are   true of it:</p> <ol> <li>its premises and its conclusion are all Standard-Form categorical syllogisms propositions(A,E,I or O).</li> <li>those propositions are arranged in a specified standard order.</li> </ol>"},{"location":"blog/2023/05/20/categorical-syllogisms/#terms-of-the-syllogisms-major-minor-and-middle","title":"Terms of the Syllogisms: Major, Minor, and Middle","text":"<pre><code>No heros are cowards.\nSome soldiers are cowards.\nTherefore some soldiers are not heros.\n\nMajor Term: hero\nMinor Term: soldier\nMiddle Term: coward\nMajor Premise: No heros are cowards.\nMinor Premise: Some soldiers are cowards.\n</code></pre> Term Parts Major Term The predicate term of the conclusion. Minor Term The subject term of the conclusion. Middle Term The term that appears in both premises but not in the conclusion Major Premise The premise containing the major term. Minor Premise The premise containing the minor term. <p>In a standard-form syllogism, the major premise is always stated first, the minor premise second, and the conclusion last.</p>"},{"location":"blog/2023/05/20/categorical-syllogisms/#the-mood-of-the-syllogism","title":"The mood of the Syllogism","text":"<p>mood: is determined by the types (A, E, I, O) of standard-form categorical propositions it contains. For example, the mood of the syllogism below is called EIO.</p> <pre><code>No heros are cowards. (E)\nSome soldiers are cowards. (I)\nTherefore some soldiers are not heros. (O)\n</code></pre>"},{"location":"blog/2023/05/20/categorical-syllogisms/#the-figure-of-the-syllogism","title":"The figure of the Syllogism","text":"<p>The mood of a standard-form syllogism is not enough, by itself, to characterize its logical form. Look at the two syllogisms shown below, they have the same mood AII but the first is not valid. The difference is the relative positions of their middle terms, and this is called figure.</p> \\[ \\begin{align*} &amp; \\text{ All } P \\text{ is } M. \\\\ &amp; \\text{ Some } S \\text{ is } M. \\\\ \\hline &amp; \\therefore \\text{ Some } S \\text{ is } P. \\end{align*} \\] \\[ \\begin{align*} &amp; \\text{ All } M \\text{ is } P. \\\\ &amp; \\text{ Some } M \\text{ is } S. \\\\ \\hline &amp; \\therefore \\text{ Some } S \\text{ is } P. \\end{align*} \\] <ul> <li> <p>Syllogisms can have four -- and only four -- possible different figures.</p> </li> <li> <p>First Figure</p> </li> </ul> \\[ \\begin{align*} &amp; M - P \\\\ &amp; S - M \\\\ \\hline &amp; \\therefore S - P \\end{align*} \\] <ul> <li>Second Figure</li> </ul> \\[ \\begin{align*} &amp; P - M \\\\ &amp; S - M \\\\ \\hline &amp; \\therefore S - P \\end{align*} \\] <ul> <li>Third Figure</li> </ul> \\[ \\begin{align*} &amp; M - P \\\\ &amp; M - S \\\\ \\hline &amp; \\therefore S - P \\end{align*} \\] <ul> <li>Fourth Figure</li> </ul> \\[ \\begin{align*} &amp; P - M \\\\ &amp; M - S \\\\ \\hline &amp; \\therefore S - P \\end{align*} \\] <ul> <li> <p>Any standard-form syllogisms is completely described when we specify its mood   and its figure.</p> </li> <li> <p>Summary</p> </li> </ul> <p>There are \\(4 * 4 *4 = 64\\) moods and 4 figures. So, syllogisms have \\(64 * 4 =   256\\) forms.</p>"},{"location":"blog/2023/05/20/categorical-syllogisms/#the-formal-nature-of-syllogistic-argument","title":"The Formal Nature of Syllogistic Argument","text":"<p>Deductive Logic: aim to discriminate valid arguments from invalid ones;</p> <p>Classic Logic: aim to discriminate valid syllogisms from invalid ones;</p> <p>It is reasonable to assume that the constituent propositions of a syllogism are all contingent\u2014that is, that no one of those propositions is necessarily true, or necessarily false.</p> <p>Under this assumption, the validity and invalidity of an syllogism depends entirely on its form.</p> <p>Examples:</p> <ul> <li>AAA-1</li> </ul> \\[ \\begin{align*} &amp; \\text{All M is P} \\\\ &amp; \\text{All S is M} \\\\ \\hline &amp; \\therefore \\text{All S is P} \\end{align*} \\] <p>Any syllogism of the form AAA-1 is valid, regardless of its subject matter. We can substitute S, P and M to Athenians, humans and Greeks.</p> \\[ \\begin{align*} &amp; \\text{All Greeks are humans} \\\\ &amp; \\text{All Athenians are Greeks} \\\\ \\hline &amp; \\therefore \\text{All Athenians are humans} \\end{align*} \\] <ul> <li> <p>If any syllogism is valid in virtue of its form alone, any other syllogism   having that same form will also be valid.</p> </li> <li> <p>If a syllogism is invalid, any other syllogism having that same form will also   be invalid.</p> </li> <li> <p>Examples:</p> </li> </ul> \\[ \\begin{align*} &amp; \\text{All liberals(P) are proponents of national health insurance(M)} \\\\ &amp; \\text{Some members of the administration(S) are propositions of national health insurance(M)} \\\\ \\hline &amp; \\therefore \\text{Some members of the administration are liberals} \\end{align*} \\] <p>The best way to expose its fallacious character is to construct another argument that has exactly the same form but whose invalidity is immediately apparent.</p> \\[ \\begin{align*} &amp; \\text{All rabbits(P) are very fast runners(M)} \\\\ &amp; \\text{Some horses(S) are very fast runners(M)} \\\\ \\hline &amp; \\therefore \\text{Some horses are rabbits.} \\end{align*} \\]"},{"location":"blog/2023/05/20/categorical-syllogisms/#venn-diagram-technique-for-testing-syllogisms","title":"Venn Diagram Technique for Testing Syllogisms","text":"<p>The syllogism can be drawn as three overlapping circles. </p>"},{"location":"blog/2023/05/20/categorical-syllogisms/#example-venn-graph-for-aaa-1","title":"Example: Venn Graph for AAA-1","text":"\\[ \\begin{align*} &amp; \\text{All M is P} \\\\ &amp; \\text{All S is M} \\\\ \\hline &amp; \\therefore \\text{All S is P} \\end{align*} \\] <ul> <li>All M is P and All S is M</li> </ul> <ul> <li>Both  <p>Combine the two premises</p> </li> </ul> <p>This syllogism is valid if and only if the two premises imply or entail the conclusion -- that is, if together they say what is said by the conclusion.</p>"},{"location":"blog/2023/05/20/categorical-syllogisms/#diagram-the-universal-premise-first","title":"Diagram the universal premise first","text":"\\[ \\begin{align*} &amp; \\text{All artists are egotists} \\\\ &amp; \\text{Some artists are paupers} \\\\ \\hline &amp; \\therefore \\text{Some paupers are egotists} \\end{align*} \\] <p>Had we tried to diagram the particular premise first, before the region \\(S\\bar PM\\) was shaded out along with \\(\\bar S \\bar P M\\) in diagramming the universal premise, we would not have known whether to insert an x in \\(SPM\\) or in \\(S \\bar P M\\) or in both.</p>"},{"location":"blog/2023/05/20/categorical-syllogisms/#put-x-at-border","title":"Put x at border","text":"\\[ \\begin{align*} &amp; \\text{All great scientists are college graduates} \\\\ &amp; \\text{Some professional athletes are college graduates} \\\\ \\hline &amp; \\therefore \\text{Some professional athletes are great scientists} \\end{align*} \\] <p>we may still be puzzled about where to put the x needed in order to diagram the particular premise. That premise is \u201cSome professional athletes are college graduates,\u201d so an x must be inserted somewhere in the overlapping part of the two circles labeled \u201cProfessional athletes\u201dand \u201cCollege graduates.\u201d That overlapping part, however, contains two regions, SPM and SPM. In which of these should we put an x? The premises do not tell us, and if we make an arbitrary decision to place it in one rather than the other, we would be inserting more information into the diagram than the premises warrant\u2014which would spoil the diagram\u2019s use as a test for validity.</p> <p>Placing an x on the line that divides the overlapping region. This indicate that there is something that belongs in one of them, but does not indicate which one.</p>"},{"location":"blog/2023/05/20/categorical-syllogisms/#technique-summary","title":"Technique Summary","text":"<ol> <li>Label the circles of a three-circle Venn diagram with the syllogism's three    terms.</li> <li>Diagram both premises, diagramming the universal one first if there is one    universal and one particular.</li> <li>In diagramming a particular proposition, to put an x on a line if the    premises do not determine on which side of the line it should go.</li> <li>Inspect the diagram to see whether the diagram of the premises contains a    diagram of the conclusion.</li> </ol>"},{"location":"blog/2023/05/20/categorical-syllogisms/#why-venn-diagram-can-tell-the-validity","title":"Why Venn Diagram can tell the validity?","text":"<ul> <li> <p>It was shown there that one legitimate test of the validity or invalidity of a syllogism is to establish the validity or   invalidity of a different syllogism that has exactly the same form.</p> </li> <li> <p>Example</p> </li> </ul> \\[ \\begin{align*} &amp; \\text{All successful people are people who are keenly interested in their work} \\\\ &amp; \\text{No people who are keenly interested in their work are people whose attention is easily distracted when they are working} \\\\ \\hline &amp; \\therefore \\text{No People whose attention is easily distracted when they are working are successful} \\end{align*} \\] <p>How does this Venn Diagram tell us that the given syllogism is valid?</p> <p> We can construct a syllogism of the same form that involves objects that are immediately present and directly available for our inspection.</p> <p>Here is the new syllogism:</p> \\[ \\begin{align*} &amp; \\text{All points with in the unshaded part of the circle labeled P are points within the unshaded part of the circle labeled M.} \\\\ &amp; \\text{No points within the unshaded part of the circle labeled M are points within the unshaded part of the circle labeled S.} \\\\ \\hline &amp; \\therefore \\text{No points within the unshaded part of the circle labeled S are points within the unshaded part of the circle labeled P} \\end{align*} \\]"},{"location":"blog/2023/05/20/categorical-syllogisms/#syllogistic-rules-and-syllogistic-fallacies","title":"Syllogistic Rules and Syllogistic Fallacies","text":""},{"location":"blog/2023/05/20/categorical-syllogisms/#rule-1-avoid-four-terms","title":"Rule 1: Avoid Four Terms","text":"<p>A valid standard-form categorical syllogism must contain exactly three terms, each of which is used in the same sense throughout the argument.</p> <p>If more than three terms are involved, the syllogism is invalid. The fallacy thus committed is called the fallacy of four terms.</p>"},{"location":"blog/2023/05/20/categorical-syllogisms/#rule-2-distribute-the-middle-term-in-at-least-one-premise","title":"Rule 2: Distribute the middle term in at least one premise","text":"<p>A term is \"distributed\" in a proposition when the proposition refers to all members of the class designated by that term. If the middle term is not distributed in at least one premise, the connection required by the conclusion cannot be made.</p> <ul> <li>Example</li> </ul> \\[ \\begin{align*} &amp; \\text{All Russians were revolutionists} \\\\ &amp; \\text{All anarchists were revolutionists} \\\\ \\hline &amp; \\therefore \\text{All anarchists were Russians} \\end{align*} \\] <p>This syllogism is plainly invalid. Its mistake is that it asserts a connection between anarchists and Russians by relying on the links between each of those classes and the class of revolutionists\u2014but revolutionists is an undistributed term in both of the premises. The first premise does not refer to all revolutionists, and neither does the second. \u201cRevolutionists\u201d is the middle term in this argument, and if the middle term is not distributed in at least one premise of a syllogism, that syllogism cannot be valid.</p> <p>This is called the fallacy of the undistributed middle.</p> <p>We want to use middle term to link the minor and major term. Either the subject or the predicate of the conclusion must be related to the whole of the class designated by the middle term. If that is not so, it is possible that each of the terms in the conclusion may be connected to a different part of the middle term, and not necessarily connected with each other.</p>"},{"location":"blog/2023/05/20/categorical-syllogisms/#rule-3-any-term-distributed-in-the-conclusion-must-be-distributed-in-the-premises","title":"Rule 3: Any term distributed in the conclusion must be distributed in the premises.Example","text":"<ul> <li>To refer to all members of a class is to say more about that class than is said when only some of its members are   referred to.</li> <li>Therefore, when the conclusion of a syllogism distributes a term that was undistributed in the premises, it   says more about that term than the premises did.</li> <li>But a valid argument is one whose premises logically entail its   conclusion, and for that to be true the conclusion must not assert any more than is asserted in the premises.</li> <li>A term that is distributed in the conclusion but is not distributed in the premises is therefore a sure mark that the conclusion   has gone beyond its premises and has reached too far.</li> <li>This is called the fallacy of illicit process.</li> <li> </li> <li> <p>Illicit process of the major term</p> \\[ \\begin{align*} &amp; \\text{All dogs are mammals(Not distributed)} \\\\ &amp; \\text{No cats are dogs} \\\\ \\hline &amp; \\therefore \\text{No cats are mammals(Distributed)} \\end{align*} \\] </li> <li> <p>Illicit process of the minor term</p> \\[ \\begin{align*} &amp; \\text{All traditionally religious people are fundamentalists} \\\\ &amp; \\text{All traditionally religious people are opponents of abortion(Not distributed)} \\\\ \\hline &amp; \\therefore \\text{All opponents of abortion(Distributed) are fundamentalists} \\end{align*} \\] </li> </ul>"},{"location":"blog/2023/05/20/categorical-syllogisms/#rule-4-avoid-two-negative-premises","title":"Rule 4: Avoid two negative premisesFurther Reflection","text":"<ul> <li>Any negative proposition (E or O) denies class inclusion; it asserts that some or all of one class is excluded from the   whole of the other class.</li> <li>Two premises asserting such exclusion cannot yield the linkage that the conclusion asserts,   and therefore cannot yield a valid argument.</li> <li>The mistake is named the fallacy of exclusive premises.</li> <li> </li> <li> <p>S is wholly or partially excluded from all or part of M</p> </li> <li>P is wholly or partially excluded from all or part of M</li> <li>However, any one of these relations may very well be established no matter     how S and P are related.</li> </ul>"},{"location":"blog/2023/05/20/categorical-syllogisms/#rule-5-if-either-premise-is-negative-the-conclusion-must-be-negative","title":"Rule 5: If either premise is negative, the conclusion must be negative","text":"<ul> <li>If the conclusion is affirmative\u2014that is, if it asserts that one of the two classes, S or P , is wholly or partly contained   in the other\u2014it can only be inferred from premises that assert the existence of a third class that contains the first   and is itself contained in the second.</li> <li>However, class inclusion can be stated only by affirmative propositions.</li> <li>Therefore, an affirmative conclusion can follow validly only from two affirmative premises.</li> </ul> <ul> <li>The mistake here is called the fallacy of drawing an affirmative conclusion from a negative premise.</li> <li>This fallacy is uncommon, since is quite easy to tell</li> </ul> \\[ \\begin{align*} &amp; \\text{No poets are accountants} \\\\ &amp; \\text{Some artists are poets} \\\\ \\hline &amp; \\therefore \\text{Some artists are accountants} \\end{align*} \\]"},{"location":"blog/2023/05/20/categorical-syllogisms/#rule-6-from-two-universal-premises-no-particular-conclusion-may-be-drawn","title":"Rule 6: From two universal premises no particular conclusion may be drawn","text":"<p>In the Boolean interpretation of categorical propositions, universal propositions (A and E) have no existential import, but particular propositions (I and O) do have such import. Wherever the Boolean interpretation is supposed, as in this book, a rule is needed that precludes passage from premises that have no existential import to a conclusion that does have such import.</p> <ul> <li>Because of the Boolean Interpretation, it will show a clear fallacy that if the premises   of an argument do not assert the existence of anything at all, the conclusion   inferred asserts the existence of something.</li> <li>This mistake is called existential fallacy.</li> <li>Example</li> </ul> \\[ \\begin{align*} &amp; \\text{All household pets are domestic animals} \\\\ &amp; \\text{No unicorns(no existential import) are domestic animals} \\\\ \\hline &amp; \\therefore \\text{Some unicorns(have existential import) are not household pets} \\end{align*} \\]"},{"location":"blog/2023/05/20/categorical-syllogisms/#exposition-of-the-fifteen-valid-forms-of-the-categorical-syllogism","title":"Exposition of the Fifteen Valid Forms of the Categorical Syllogism","text":"<ul> <li>AAA-1  Barbara</li> <li>EAE-1  Celarent</li> <li>AII-1  Darii</li> <li>EIO-1  Ferio</li> </ul> <ul> <li>AEE-2  Camestres</li> <li>EAE-2  Cesare</li> <li>AOO-2  Baroko</li> <li>EIO-2  Festino</li> </ul> <ul> <li>AII-3  Datisi</li> <li>IAI-3  Disamis</li> <li>EIO-3  Ferison</li> <li>OAO-3  Bokardo</li> </ul> <ul> <li>AEE-4  Camenes</li> <li>IAI-4  Dimaris</li> <li>EIO-4  Fresison</li> </ul>"},{"location":"blog/2025/05/24/error-handling/","title":"Error Handling","text":"","tags":["clean code"]},{"location":"blog/2025/05/24/error-handling/#error-handling","title":"Error Handling","text":"<p>Error handling is important, but if it obscures logic, it\u2019s wrong.</p>","tags":["clean code"]},{"location":"blog/2025/05/24/error-handling/#use-exceptions-rather-than-return-codes","title":"Use Exceptions Rather than Return Codes","text":"Use Return Codes<pre><code>public class DeviceController {\n\n    private static final DeviceId DEV1 = DeviceId.DEVICE_1; // Assuming a predefined constant\n    private DeviceRecord record;\n    private Logger logger = Logger.getLogger(DeviceController.class.getName());\n\n    public void sendShutDown() {\n        DeviceHandle handle = getHandle(DEV1);\n\n        // Check the state of the device\n        if (handle != DeviceHandle.INVALID) {\n            // Save the device status to the record field\n            retrieveDeviceRecord(handle);\n\n            // If not suspended, shut down\n            if (record.getStatus() != DeviceStatus.DEVICE_SUSPENDED) {\n                pauseDevice(handle);\n                clearDeviceWorkQueue(handle);\n                closeDevice(handle);\n            } else {\n                logger.log(\"Device suspended. Unable to shut down\");\n            }\n        } else {\n            logger.log(\"Invalid handle for: \" + DEV1.toString());\n        }\n    }\n}\n</code></pre> Use Exceptions<pre><code>public class DeviceController {\n\n    private static final DeviceId DEV1 = DeviceId.DEVICE_1; // Assumed constant\n    private DeviceRecord record;\n    private Logger logger = Logger.getLogger(DeviceController.class.getName());\n\n    public void sendShutDown() {\n        try {\n            tryToShutDown();\n        } catch (DeviceShutDownError e) {\n            logger.log(e);\n        }\n    }\n  private void tryToShutDown() throws DeviceShutDownError {\n      DeviceHandle handle = getHandle(DEV1);\n      DeviceRecord record = retrieveDeviceRecord(handle);\n      pauseDevice(handle);\n      clearDeviceWorkQueue(handle);\n      closeDevice(handle);\n  }\n\n  private DeviceHandle getHandle(DeviceID id) {\n      ...\n      throw new DeviceShutDownError(\"Invalid handle for: \" + id.toString());\n      ...\n  }\n}\n</code></pre>","tags":["clean code"]},{"location":"blog/2025/05/24/error-handling/#write-your-try-catch-finally-statement-first","title":"Write Your <code>Try-Catch-Finally</code> Statement First","text":"<ul> <li>TDD</li> </ul>","tags":["clean code"]},{"location":"blog/2025/05/24/error-handling/#use-unchecked-exceptions","title":"Use Unchecked Exceptions","text":"<ul> <li>Whether checked exceptions are worth their price? -&gt; <code>Open/Close Principle</code> violation</li> </ul> <p>If you throw a checked exception from a method in your code and the catch is three levels above, you must declare that exception in the signature of each method between you and the catch. This means that a change at a low level of the software can force signature changes on many higher levels. The changed modules must be rebuilt and redeployed, even though nothing they care about changed.</p> <ul> <li>Checked exceptions can sometimes be useful if you are writing a critical library: You must catch them.</li> </ul>","tags":["clean code"]},{"location":"blog/2025/05/24/error-handling/#provide-context-with-exceptions","title":"Provide Context with Exceptions","text":"<ul> <li>Each exception that you throw should provide enough context to determine the source and location of an error.</li> <li>Mention the operation that failed and the type of the failure.</li> </ul>","tags":["clean code"]},{"location":"blog/2025/05/24/error-handling/#define-exception-classes-in-terms-of-a-callers-needs","title":"Define Exception Classes in Terms of a Caller's Needs","text":"<p>when we define exception classes in an application, our most important concern should be how they are caught</p> Poor Exception Classification<pre><code>ACMEPort port = new ACMEPort(12);\n\ntry {\n    port.open();\n} catch (DeviceResponseException e) {\n    reportPortError(e);\n    logger.log(\"Device response exception\", e);\n} catch (ATM1212UnlockedException e) {\n    reportPortError(e);\n    logger.log(\"Unlock exception\", e);\n} catch (GMXError e) {\n    reportPortError(e);\n    logger.log(\"Device response exception\");\n} finally {\n    ...\n}\n</code></pre> Exception with wrapper<pre><code>LocalPort port = new LocalPort(12);\n\ntry {\n    port.open();\n} catch (PortDeviceFailure e) {\n    reportError(e);\n    logger.log(e.getMessage(), e);\n} finally {\n    ...\n}\n\npublic class LocalPort{\n  private ACMEPort innerPort;\n\n  public LocalPort(int portNumber) {\n    innerPort = new ACMEPort(portNumber);\n  }\n\n  public void open() {\n    try {\n        port.open();\n    } catch (DeviceResponseException e) {\n        throw new PortDeviceFailure(e);\n    } catch (ATM1212UnlockedException e) {\n        throw new PortDeviceFailure(e);\n    } catch (GMXError e) {\n        throw new PortDeviceFailure(e);\n    }\n}\n</code></pre> <ul> <li>Wrapping third-party APIs minimize your dependencies upon it.</li> <li>you can choose to move to a different library in the future without much penalty.</li> <li>also makes it easier to mock out third-party calls when you are testing your own code.</li> </ul>","tags":["clean code"]},{"location":"blog/2025/05/24/error-handling/#define-the-normal-flow","title":"Define the Normal Flow","text":"<p>Separation between business logic and error handling is good. However, the process of doing this pushes error detection to the edges of your program. We can define a handler to deal with any aborted computaiton. BUT There are some times when you may not want to abort.</p> Handle logic in catch<pre><code>try {\n  MealExpenses expenses = expenseReportDAO.getMeals(employeegetID())\n  m_total += expenses.getTotal();\n}\ncatch(MealExpensesNotFound e) {\n  m_total += getMealPerDiem();\n}\n</code></pre> Use Special Case Pattern<pre><code>  MealExpenses expenses = expenseReportDAO.getMeals(employeegetID())\n  m_total += expenses.getTotal();\n\n  public class PerDiemMealExpenses implements MealExpenses {\n    public int getTotal() {\n      // return the per diem default\n    }\n  }\n</code></pre> <p>Special Case Pattern</p> <p>you create a class or configure an object so that it handles a special case for you. When you do, the client code doesn\u2019t have to deal with exceptional behavior. That behavior is encapsulated in the special case object.</p>","tags":["clean code"]},{"location":"blog/2025/05/24/error-handling/#dont-return-null","title":"Don't Return Null","text":"Many Null checks<pre><code>public void registerItem(Item item) {\n  if (item != null) {\n    ItemRegistry registry = peristentStore.getItemRegistry();\n    if (registry != null) {\n    Item existing = registry.getItem(item.getID());\n      if (existing.getBillingPeriod().hasRetailOwner()) {\n        existing.register(item)\n      }\n    }\n  }\n}\n</code></pre> <ul> <li>When return <code>null</code>, we are essentially creating work for ourselves and foisting problems upon our callers.</li> <li>If you are tempted to return <code>null</code> from a method, consider throwing an exception or returning a SPECIAL CASE object instead.</li> <li>If you are calling a <code>null</code> returnging method from a third-party API, consider wrapping that method with a method that either throws an excepiton or returns a special case object.</li> </ul> <p>Example: Java has <code>Collections.emptyList()</code>, it returns a predefined immutable list that we can use as a Special Case object, rather than return <code>null</code> to the caller who needs a List Object.</p>","tags":["clean code"]},{"location":"blog/2025/05/24/error-handling/#dont-pass-null","title":"Don't Pass Null","text":"<p>Returning null from methods is bad, but passing null into methods is worse. Unless you are working with an API which expects you to pass null, you should avoid passing null in your code whenever possible.</p> Null pointer Exception<pre><code>public class MetricsCalculator  {\n  public double xProjection(Point p1, Point p2) {\n    return (p2.x \u2013 p1.x) * 1.5;\n  }\n}\n</code></pre> Handle Null Args Exception<pre><code>public class MetricsCalculator  {\n  public double xProjection(Point p1, Point p2) {\n    if (p1 == null || p2 == null) {\n      throw InvalidArgumentExcepiton(\"XXX\");\n    }\n    return (p2.x \u2013 p1.x) * 1.5;\n  }\n}\n</code></pre> Assert Not Null<pre><code>public class MetricsCalculator  {\n  public double xProjection(Point p1, Point p2) {\n    assert p1 != null : \"xxx\";\n    assert p2 != null : \"xxx\";\n    return (p2.x \u2013 p1.x) * 1.5;\n  }\n}\n</code></pre> <p>In most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default. When you do, you can code with the knowledge that a null in an argument list is an indication of a problem, and end up with far fewer careless mistakes.</p>","tags":["clean code"]},{"location":"blog/2023/05/25/fallacies-of-logic/","title":"Fallacies of Logic","text":""},{"location":"blog/2023/05/25/fallacies-of-logic/#fallacies-of-relevance","title":"Fallacies of relevance","text":"<ul> <li>The appeal to the populace (ad populum):</li> </ul> <p>When correct reasoning is replaced by devices calculated to elicit emotional   and nonrational support for the conclusion urged.</p> <ul> <li>The appeal to emotion</li> </ul> <p>When correct reasoning is replaced by appeals to specific emotions, such as   pity, pride, or envy.</p> <ul> <li>The red herring:</li> </ul> <p>When correct reasoning is manipulated by the introduction of some event or   character that deliberately misleads the audience and thus hinders rational   inference.</p> <ul> <li>The straw man:</li> </ul> <p>When correct reasoning is undermined by the deliberate misrepresentation of   the opponent's position.</p> <ul> <li>The attack on the person (ad hominem):</li> </ul> <p>When correct reasoning about some issue is replaced by an attack upon the   character or special circumstances of the opponent.</p> <ul> <li>The appeal to force (ad baculum):</li> </ul> <p>When reasoning is replaced by threats in the   effort to win support or assent.</p> <ul> <li>Missing the point (ignoratio elenchi):</li> </ul> <p>When correct reasoning is replaced by the mistaken refutation of a position   that was not really at issue.</p>"},{"location":"blog/2023/05/25/fallacies-of-logic/#fallacies-of-defective-induction","title":"Fallacies of defective induction","text":"<ul> <li>The argument from ignorances (ad ignorantiam):</li> </ul> <p>When it is argued that a proposition is true on the ground that it has not   been proved false, or when it is argued that a proposition is false because it   has not been proved true.</p> <ul> <li>The appeal to inappropriate authority (as verecundiam):</li> </ul> <p>When the premises of an argument appeal to the judgement of some person or   persons who have no legitimate claim to authority in the matter at hand.</p> <ul> <li>False cause (non causa pro causa):</li> </ul> <p>When one treats as the cause of a thing that which is not really the cause of   that thing, often relying(as in the subtype <code>post hoc ergo propter hoc</code>)   merely on the close temporal succession of two events.</p> <ul> <li>Hasty generalization(converse accident):</li> </ul> <p>When one moves carelessly or too quickly from one or a vary few instances to a   broad or universal claim.</p>"},{"location":"blog/2023/05/25/fallacies-of-logic/#fallacies-of-presumptions","title":"Fallacies of presumptions","text":"<ul> <li>Accident:</li> </ul> <p>When one mistakenly applies a generalization to an individual case that it   does not properly govern.</p> <ul> <li>Complex question:</li> </ul> <p>When one argues by asking a question in such a way as to presuppose the truth   of some assumption buried in that question.</p> <ul> <li>Begging the question (petitio principii):</li> </ul> <p>When one assumes in the premises of an argument the truth of what one seeks to   establish in the conclusion of that same argument.</p>"},{"location":"blog/2023/05/25/fallacies-of-logic/#fallacies-of-ambiguity","title":"Fallacies of ambiguity","text":"<ul> <li>Equivocation(\u6b67\u4e49):</li> </ul> <p>When the same word or phrase is used with two or more meanings, deliberately   or accidentally, in formulating an argument.</p> <ul> <li>Amphiboly(\u53cc\u5173):</li> </ul> <p>When one of the statements in an argument has more than one plausible meaning,   because of the loose or awkward way in which the words in that statement have   been combined.</p> <ul> <li>Accent</li> <li> <p>Compostion:</p> </li> <li> <p>when one reasons mistakenly from the attributes of a part to the attributes     of the whole</p> </li> <li> <p>when one reasons mistakenly from the attributes of an individual memeber of     some collection to the attributes of the totality of that collection.</p> </li> <li> <p>Division:</p> </li> <li> <p>when one reasons mistakenly from the attributes of a whole to the attributes     of one of its parts</p> </li> <li>when one reasons mistakenly from the attributes of a totality of some     collection of entities to the attributes of an individual entities within     that collection.</li> </ul>"},{"location":"blog/2025/03/18/functions/","title":"Functions","text":"","tags":["clean code"]},{"location":"blog/2025/03/18/functions/#functions","title":"Functions","text":"","tags":["clean code"]},{"location":"blog/2025/03/18/functions/#small","title":"Small!","text":"","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/","title":"Meaningful Names","text":"","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#meaningful-names","title":"Meaningful Names","text":"","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#use-intention-revealing-names","title":"Use Intention-Revealing Names","text":"<ul> <li>fields</li> </ul> <pre><code>// BAD\nint d; // elapsed time in days\n\n// GOOD\nint elapsedTimeInDays;\n</code></pre> <ul> <li>functions</li> </ul> <p><code>implicity</code> of the code: the degree to which the context is not explicit in the   code itself.</p> bad example<pre><code>public List&lt;int[]&gt; getThem() {\n  List&lt;int[]&gt; list1 = new ArrayList&lt;int[]&gt;();\n  for (int[] x : theList)\n  if (x[0] == 4)\n    list1.add(x);\n  return list1;\n}\n</code></pre> good example<pre><code>public List&lt;Cell&gt; getFlaggedCells() {\n  List&lt;Cell&gt; flaggedCells = new ArrayList&lt;Cell&gt;();\n  for (Cell cell : gameBoard)\n  if (cell.isFlagged())\n    flaggedCells.add(cell);\n  return flaggedCells;\n}\n</code></pre>","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#avoid-disinformation","title":"Avoid Disinformation","text":"<ul> <li> <p>Avoid names whose entrenched meanings vary from our intended meaning.</p> <p>eg: <code>hp</code>, <code>aix</code>, <code>sco</code> -&gt; Unix platforms or variants</p> </li> <li> <p>Name for a group of things</p> <p>eg: <code>accountList</code> -&gt; the data structure may not be a list. Better names:</p> <p><code>accountGroup</code>, <code>bunchOfAccounts</code> Or <code>accounts</code></p> </li> <li> <p>Name with small difference</p> <p>eg: <code>XYZControllerForEfficientHandlingOfStrings</code> and   <code>XYZControllerForEfficientStorageOfStrings</code></p> </li> <li> <p>Spelling similar concepts similarly is <code>information</code>; Using inconsistent   spellings is <code>disinformation</code></p> <p>eg: IDE will prompt all desired functions that can do replacment if we enter   \"replace\"</p> </li> <li> <p>Lowercase l and Uppercase O</p> </li> </ul>","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#make-meaningful-distinctions","title":"Make Meaningful Distinctions","text":"<ul> <li>Number-series naming <code>(a1, a2, a3)</code> -&gt; noninformative</li> <li> <p>Noise words -&gt; redundant</p> <p>eg: Class <code>Product</code>, <code>ProductInfo</code>, <code>ProductData</code></p> <p>eg: Class <code>Name</code>, <code>NameString</code></p> <p>eg: Function <code>getActiveAccount()</code>, <code>getActiveAccounts()</code>, <code>getActiveAccountInfo()</code></p> </li> </ul>","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#use-pronounceable-names","title":"Use Pronounceable Names","text":"","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#use-searchable-names","title":"Use Searchable Names","text":"<ul> <li><code>MAX_CLASSES_PER_STUDENT</code> is better than <code>7</code></li> <li>single-letter names can ONLY be used as local variables inside short   methods</li> </ul>","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#avoid-encodings","title":"Avoid Encodings","text":"","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#hungarian-notation-old-naming-fashions","title":"Hungarian(\u5308\u7259\u5229) Notation -&gt; Old Naming fashions","text":"<ul> <li>type is the prefix of the variable name: <code>chName</code></li> </ul>","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#memeber-prefixes","title":"Memeber Prefixes","text":"<ul> <li>class field member prefix with <code>m_</code>, eg: <code>private String m_name</code></li> <li>modern IDE has solved this through colorize members to make them distinct</li> </ul>","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#interfaces-and-implementations","title":"Interfaces and Implementations","text":"<ul> <li><code>IShapeFactory</code> or <code>ShapeFactory</code></li> </ul> <p>I prefer to leave interfaces unadorned. The preceding I, so common in today\u2019s legacy wads, is a distraction at best and too much information at worst. I don\u2019t want my users knowing that I\u2019m handing them an interface.</p> <ul> <li>Encode implementation, not interface</li> </ul> <p>Interface: <code>ShapeFactory</code></p> <p>Concrete Class: <code>ShapeFactoryImp</code></p>","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#avoid-mental-mapping","title":"Avoid Mental Mapping","text":"<p>Readers shouldn\u2019t have to mentally translate your names into other names they already know.</p>","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#class-names","title":"Class Names","text":"<p>noun and noun phrase, no verb</p>","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#method-names","title":"Method Names","text":"<p>have verb or verb phrase + predicates</p> <p>Give Overloaded Constructors Name</p> <p>when facing with constructors overloaded, static factory methods with names that describes the arguments is better.</p> <pre><code>Complex fulcrumPoint = Complex.FromRealNumber(23.0); // Better\nComplex fulcrumPoint = new Complex(23.0);\n</code></pre>","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#pick-one-word-per-concept","title":"Pick One Word per Concept","text":"<ul> <li><code>fetch</code>, <code>retrieve</code>, <code>get</code> -&gt; stick to one!</li> </ul>","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#dont-pun","title":"Don't Pun","text":"<p>Avoid using the same word for two purposes</p> <ul> <li>Use <code>add</code> for concatenating</li> <li>Use <code>insert</code> for puts a value into a collection</li> </ul>","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#use-solution-domain-names","title":"Use Solution Domain Names","text":"<p>Use names that programmer will understand rather than terms from customers</p>","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#use-problem-domain-names","title":"Use Problem Domain Names","text":"<p>When there is no programmer term for the names, use the name from the problem domain.</p>","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#add-meaningful-context","title":"Add Meaningful Context","text":"<ul> <li> <p>Most names are not meaningful in and of themsevles.</p> </li> <li> <p>you need to place names in context for your reader by enclosing them in   well-named classes, functions, or namespaces.</p> </li> <li> <p>When all else fails, then pre\ufb01xing the name may be necessary as a last resort.</p> </li> </ul> <p>Example 1: Address Variables</p> Variables Together As ContextPrefix As ContextClass as Context <pre><code>// Together seems to be the attributes of address\n// What if we use state alone in a method?\nString firstName;\nString lastName;\nString street;\nString houseNumber;\nString city;\nString state;\n</code></pre> <pre><code>String addrFirstName;\nString addrLastName;\n...\n</code></pre> <pre><code>class Address {\n  String firstName;\n  String lastName;\n  String street;\n  ....\n}\n</code></pre> <p>Example 2: Variables in Function</p> Variables with unclear context<pre><code>// number, verb, pluralModifier must be infered from the code\nprivate void printGuessStatistics(char candidate, int count) {\nString number;\nString verb;\nString pluralModifier;\nif (count == 0) {\nnumber = \"no\";\nverb = \"are\";\npluralModifier = \"s\";\n} else if (count == 1) {\nnumber = \"1\";\nverb = \"is\";\npluralModifier = \"\";\n} else {\nnumber = Integer.toString(count);\nverb = \"are\";\npluralModifier = \"s\";\n}\nString guessMessage = String.format( \"There %s %s %s%s\", verb, number, candidate, pluralModifier);\nprint(guessMessage);\n}\n</code></pre> Variables have a context<pre><code>public class GuessStatisticsMessage {\n  private String number;\n  private String verb;\n  private String pluralModifier;\n  public String make(char candidate, int count) {\n  createPluralDependentMessageParts(count);\n    return String.format( \"There %s %s %s%s\", verb, number, candidate, pluralModifier );\n  }\n  private void createPluralDependentMessageParts(int count) {\n    if (count == 0) {\n      thereAreNoLetters();\n    } else if (count == 1) {\n        thereIsOneLetter();\n    } else {\n        thereAreManyLetters(count);\n    }\n  }\n  private void thereAreManyLetters(int count) {\n    number = Integer.toString(count);\n    verb = \"are\";\n    pluralModifier = \"s\";\n  }\n  private void thereIsOneLetter() {\n    number = \"1\";\n    verb = \"is\";\n    pluralModifier = \"\";\n  }\n  private void thereAreNoLetters() {\n    number = \"no\";\n    verb = \"are\";\n    pluralModifier = \"s\";\n  }\n}\n</code></pre>","tags":["clean code"]},{"location":"blog/2025/03/15/meaningful-names/#dont-add-gratuitous-context","title":"Don't Add Gratuitous(\u65e0\u7406\u7531\u7684) Context","text":"<p>\ud83d\udeab Example 1: \"GAS Station Deluxe\" Application -&gt; prefix every class with <code>GSD</code></p> <p>\ud83d\udeab Example 2: \"MailingAddress\" in GSD's accounting module -&gt; <code>GSDAccountAddress</code></p> <ul> <li>Short names are generally better than longer ones, so long as they are clear.</li> <li>Add no more context to a name than is necessary.</li> </ul>","tags":["clean code"]},{"location":"blog/2024/01/07/philosophy-of-software-design/","title":"Philosophy of Software Design","text":"","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#nature-of-complexity","title":"Nature of Complexity","text":"","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#definition","title":"Definition","text":"<p>Complexity is anything related to the structure of a software system that makes it hard to understand and modify the system.</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#symptoms-of-complexity","title":"Symptoms of complexity","text":"<ul> <li>Change amplification <p>a seemingly simple change requires code modifications in many different places.</p> </li> <li>Cognitive load <p>refers to how much a developer needs to know in order to complete a task.</p> </li> <li>Unknown unknowns <p>it is not obvious which pieces of code must be modified to complete a task, or what information a developer must have to carry out the task successfully.</p> </li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#causes-of-complexity","title":"Causes of Complexity","text":"<ul> <li>Dependencies</li> <li>Obscurity</li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#complexity-is-incremental","title":"Complexity is Incremental","text":"","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#strategic-tactical-programming","title":"Strategic &amp; Tactical Programming","text":"","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#tactical-programming","title":"Tactical programming","text":"<p>In the tactical approach, your main focus is to get something working, such as a new feature or a bug fix. At first glance this seems totally reasonable: what could be more important than writing code that works? However, tactical programming makes it nearly impossible to produce a good system design.</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#strategic-programming","title":"Strategic programming","text":"<p>Working code isn't enough Your primary goal must be to produce a great design, which also happens to work.</p> <ul> <li> <p>Proactive Investments</p> </li> <li> <p>taking extra time to find a better design rather the first one comes to mind.</p> </li> <li> <p>good documentation</p> </li> <li> <p>Reactive Investments</p> <p>No matter how much you invest up front,</p> </li> </ul> <p>there will inevitably be mistakes in your design decisions.</p> <pre><code>  - Take extra time to fix design problems!!!\n</code></pre>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#modules-should-be-deep","title":"Modules Should Be Deep","text":"<p>Modules can take many forms -&gt; classes, subsystems, or services.</p> <ul> <li> <p>Ideally, each module would be completely independent of the others &gt; a developer could work in any of the modules without   knowing anything about any of the other modules</p> </li> <li> <p>Reality, modules must work together by calling each others's functions or methods. Dependencies always exists!!!</p> </li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#modular-design","title":"Modular Design","text":"<ul> <li> <p>Two parts of Module</p> </li> <li> <p>interface</p> </li> <li> <p>implementation</p> </li> <li> <p>Best Modules</p> </li> </ul> <p>whose interfaces are much simpler than their implementations</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#whats-in-an-interface","title":"What's in an interface","text":"<ul> <li>formal information: information that are specified explicitly in the code.</li> <li>informal information: information that are not specified in a way that can be understood or enforced by the programming language.</li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#abstractions","title":"Abstractions","text":"<p>An abstraction is a simplified view of an entity, which omits unimportant details.</p> <ul> <li>Include unimportant details -&gt; increase <code>cognitive load</code></li> <li>Omit important details -&gt; increase <code>obscurity</code></li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#deep-modules","title":"Deep Modules","text":"<p>The best modules are those that provide powerful functionality yet have simple interfaces.</p> <p></p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#shallow-modules","title":"Shallow Modules","text":"<p>a shallow module is one whose interface is relatively complex in comparison to the functionality that it provides.</p> <p>Extremes Examples:</p> <pre><code>private void addNullValueForAttribute(String attribute) {\n    data.put(attribute, null);\n}\n</code></pre>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#shallow-module","title":"Shallow Module","text":"<p>A shallow module is one whose interface is complicated relative to the functionality it provides. Shallow modules don\u2019t help much in the battle against complexity, because the benefit they provide (not having to learn about how they work internally) is negated by the cost of learning and using their interfaces. Small modules tend to be shallow.</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#information-hidingand-leakage","title":"Information Hiding(and Leakage)","text":"<p>techniques for creating deep modules</p> <ul> <li>reduce cognitive load -&gt; simplifies interface</li> <li>easier to evolve</li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#information-leakage","title":"Information Leakage","text":"<p>Information leakage occurs when the same knowledge is used in multiple places, such as two different classes that both understand the format of a particular type of file</p> <ul> <li>How can I recognize these classes so that this particular piece of knowledge   only affects a single class?</li> <li>Answer1: merge them into a single class</li> <li>Answer2: create a new class that encapsulates just that information</li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#temporal-decomposition","title":"Temporal Decomposition","text":"<p>In temporal decomposition, the structure of a system corresponds to the time order in which operations will occur.</p> <ul> <li>Examples:</li> </ul> <pre><code>Application -&gt; reads a file in a particular format -&gt; modifies -&gt; writes;\n\nDesign -&gt; Three Classes:\n1. read file\n2. perform modifications\n3. write out new version\n\nProblem: Both three class has knowledge about the file format -&gt; results in\ninformation leakage.\n\nSolution: Combine the core mechanisms for reading and writing files into single\nclass.\n</code></pre> <ul> <li>Conclusion:   Order usually does matter, but it shouldn't be reflected in the module structure   unless that structure is consistent with information hiding.When design   modules, focus on the knowledge that's needed to perform each task, not the   order in which tasks occur.</li> </ul> <p>In temporal decomposition, execution order is reflected in the code structure: operations that happen at different times are in different methods or classes. If the same knowledge is used at different points in execution, it gets encoded in multiple places, resulting in information leakage.</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#overexposure","title":"Overexposure","text":"<p>If the API for a commonly used feature forces users to learn about other features that are rarely used, this increases the cognitive load on users who don't need the rarely used features.</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#general-purpose-modules-are-deeper","title":"General-Purpose Modules are Deeper","text":"<p>Questions: When Designing Modules,</p> <ul> <li>General Purpose? -&gt; might include facilities that are never actually needed.</li> <li>Special Purpose? -&gt; you can always refactor it to make it general purpose.</li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#make-classes-somewhat-general-purpose","title":"Make classes somewhat general-purpose","text":"<p>somewhat general-purpose means that the module's functionality should reflect your current needs, but its interface should be general enough to support multiple uses.</p> <ul> <li>Examples:</li> </ul> <p>App -&gt; GUI text editor</p> <pre><code>Design 1:\nvoid backspace(Cursor cursor);\nvoid delete(Cursor cursor);\nvoid deleteSelection(Selection selection);\n\n- high cognitive load\n- shallow methods -&gt; each method only suitable for one user interface\n  operation\n- user had to learn about a large number of methods\n</code></pre> <pre><code>Design 2:\nvoid insert(Position position, String newText);\nvoid delete(Position start, String end);\nPosition changePosition(Position position, int numChars);\n\nnow, the delete key looks like:\ntext.delete(cursor, text.changePosition(cursor, 1));\nthe backspace looks like:\ntext.delete(text.changePosition(cursor, -1), cursor);\n</code></pre> <p>Here, the details are important: user wants to know which characters are   deleted. When the details are important it is better to make them explicit   and as obvious as possible.</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#how-to-design-general-purpose-class","title":"How to design general-purpose class?","text":"<ul> <li>What is the simplest interface that will cover all my current needs?</li> </ul> <p>If you reduce the number of methods in an API without reducing its overall capabilities, then you are probably creating more general-purpose methods.</p> <ul> <li>In how many situations will this method be used? -&gt; Don't be special   purpose!!!</li> <li>Is this API easy to use for my current needs? -&gt; Don't go too far!!!</li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#different-layer-different-abstraction","title":"Different Layer, Different Abstraction","text":"","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#pass-through-methods","title":"Pass-through methods","text":"<p>When adjacent layers have similar abstractions, the problem often manifests itself in the form of <code>pass-through</code> methods. A pass-through method is one that does little except invoke another method, whose signature is similar or identical to that of the calling method.</p> <ul> <li> <p>make methods shallower -&gt; increase the interface complexity; no contribution   to the functionality of the system.</p> </li> <li> <p>indicates that there is a confusion over the division of responsibility   between classes.</p> </li> </ul> <pre><code>public class TextDocument ... {\n    private TextArea textArea;\n    private TextDocumentListener listener;\n    ...\n    public Character getLastTypedCharacter() {\n        return textArea.getLastTypedCharacter();\n    }\n\n    public int getCursorOffset() {\n        return textArea.getCursorOffset();\n    }\n    public void insertString(String textToInsert, int offset) {\n        textArea.insertString(textToInsert, offset);\n    }\n    public void willInsertString(String stringToInsert, int offset) {\n        if (listener != null) {\n            listener.willInsertString(this, stringToInsert, offset);\n        }\n    }\n    ...\n}\n</code></pre> <p>A pass-through method is one that does nothing except pass its arguments to another method, usually with the same API as the pass-through method. This typically indicates that there is not a clean division of responsibility between the classes.</p> <ul> <li> <p>Solutions:   </p> </li> <li> <p>(7.1b) expose the lower level class directly to the callers of the higher     level class.</p> </li> <li> <p>(7.1c) redistribute the functionality between the classes</p> </li> <li>(7.1d) if the class cannot be disentangled, merge them together</li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#when-is-duplications-ok","title":"When is Duplications OK?","text":"<p>Having methods with the same signature is not always bad. The important thing is that each new method should contribute significant functionality.</p> <ul> <li>several methods have same signature as long as each of them provides   useful and distinct functionality.</li> <li>several methods provide different implementations of the same interface.</li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#decorator-design-pattern","title":"Decorator Design Pattern","text":"<p>Decorator Design Pattern encourages API duplication across layers. The decorator objects provides an API similar or identical to the underlying object and its method invoke the methods of the underlying object.</p> <ul> <li>Motivation: separate special-purpose extensions of a class from a more generic   core.</li> <li>Problem: decorator classes tend to be shallow. -&gt; a large amount of   boilerplate for a small amount of new functionality</li> <li>Note: easy to overuse!!!</li> </ul> <p>Whether to use Decorator?</p> <ul> <li>Could you add the new functionality directly to the underlying class, rather   than creating a decorator class?</li> <li>If the functionality is specialized for a particular use case, would it make   sense to merge it with the use case rather than creating a separate class?</li> <li>Could you merge the new functionality with an existing decorator?</li> <li>Whether the new functionality really needs to wrap the existing   functionality.</li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#interface-vs-implementation","title":"Interface VS Implementation","text":"<p>Another application of the \"different layer, different abstraction\" rule is that the interface of a class should normally be different from its implementation: the representations used internally should be different from the abstractions that appear in the interface. -&gt; If the two have similar abstractions, then the class probably isn't very deep.</p> <p>Examples:</p> <pre><code>App: text editor -&gt; the text are stores as lines\n\nDesign 1:\ngetLine()\nputLine()\n\nProblem:\nshallow and awkward to use, the interface getLine() has the implementations of\nget line, when user use this, they have to handle the changes between lines.\n\nDesign 2:\ninsert() -&gt; characters at some position\ndelete() -&gt; characters at some position\n\nNote:\nthe API insert() and delete() uses lines representations, but it provides a\ncharacter based interface, which makes the text class deeper and simplifies\nhigher level code that uses the class.\n</code></pre>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#pass-through-variables","title":"Pass-through Variables","text":"<p>Another form of API duplication across layers is a pass-through variable, which is a variable that is passed down through the long chain of methods.</p> <p>Pass-through Variables add complexity because they force all of the intermediate methods to be aware of their existence, even though the methods have no use for the variables (See Figure a).</p> <p></p> <p>How to solve?</p> <ul> <li> <p>If there is already an object shared between the topmost and bottommost   methods. (See Figure b) However, if there is such an object, then it may   itself be a pass-through variable(how else does m3 get access to it).</p> </li> <li> <p>Store information in a global variable.(See Figure c) However, global   variables make it impossible to create two independent instances of the same   system in the same process, since access to the global variables will   conflict. Examples: when you do testing, you want to use different   configurations.</p> </li> <li> <p>Introduce a context object (See Figure d)</p> </li> </ul> <p>The context allows multiple   instances of the system to coexist in a single process, each with its own   context. The class of m3 and class of m1 stores a reference to the context   object. Thus, the context is available everywhere, but it only appears as an   explicit argument in constructors.</p> <p>However, it has disadvantages:</p> <ul> <li> <p>it may not be obvious why a particular variable is present, or where it     is used.</p> </li> <li> <p>Without discipline, a context can turn into a huge grab-bag of data that creates notorious dependencies throughout the system.</p> </li> <li>Contexts may also create thread-safety issues</li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#pull-complexity-downwards","title":"Pull Complexity Downwards","text":"<p>Suppose you are developing a new module, and you discover a piece of unavoidable complexity. Which is better?</p> <ul> <li>let the users deal with the complexity</li> <li>handle the complexity internally within the module</li> </ul> <p>It is more important for a module to have a simple interface than a simple implementation</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#examples-configuration-parameters","title":"Examples: Configuration Parameters","text":"<p>Configuration parameters are an example of moving complexity upwards instead of down. Rather than determining a particular behavior internally, a class can export a few parameters that control its behavior, such as the size of a cache or the number of times to retry a request before giving up. Users of the class must then specify appropriate values for the parameters. Configuration parameters have become very popular in systems today; some systems have hundreds of them.</p> <ul> <li>Good Ways: allow user to tune system for their particular requirements and workloads.</li> <li>Bad Ways: provide an easy excuse to avoid dealing with important issues and pass them on to someone else.</li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#when-to-pull-complexity-downwards","title":"When to pull complexity downwards?","text":"<ul> <li>the complexity being pulled down is closely related to the class's existing functionality.</li> <li>pulling the complexity down simplifies the class's interface</li> <li>the goal is to minimize overall system complexity</li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#better-together-or-better-apart","title":"Better Together Or Better Apart","text":"<p>When deciding whether to combine or separate, the goal is to reduce the complexity of the system as a whole and improve its modularity. It might appear that the best way to achieve this goal is to divide the system into a large number of small components.</p> <p>Problem of Subdivision:</p> <ul> <li>Some complexity comes just from the number of components -&gt; harder to keep track of and harder to find a desired component.</li> <li>Result in additional code to manage the components</li> <li>Creates separation -&gt; make the developer harder to see the components at the same time or even be aware of their existence.</li> <li>Result in duplications</li> </ul> <p>When it makes sense to separate?</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#bring-together-if-information-is-shared","title":"Bring together if information is shared","text":"<p>Examples:</p> <pre><code>App -&gt; Http Server\n\nImplementation:\nString read(text from network socket)\nMap parse(String from read())\n\nProblem: both of the methods ended up with\nconsiderable knowledge of the format of HTTP requests: the first method was\nonly trying to read the request, not parse it, but it couldn\u2019t identify the end of the\nrequest without doing most of the work of parsing it (for example, it had to parse\nheader lines in order to identify the header containing the overall request length).\n</code></pre>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#bring-together-if-it-will-simplify-the-interface","title":"Bring together if it will simplify the interface","text":"<p>When two or more modules are combined into a single module, it may be possible to define an interface for the new module that is simpler or easier to use than the original interfaces. This often happens when the original modules each implement part of the solution to a problem.</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#bring-together-to-eliminate-duplication","title":"Bring together to eliminate duplication","text":"<p>If you find the same pattern of code repeated over and over, see if you can reorganize the code to eliminate the repetition.</p> <ul> <li>Approach 1: refactor the repeated code to eliminate the repetition. -&gt; Most effective when the replacement method has a simple signature.</li> <li>Approach 2: refactor the code so that the snippet in question only needs to be executed in one place</li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#repetition","title":"Repetition","text":"<p>If the same piece of code (or code that is almost the same) appears over and over again, that\u2019s a red flag that you haven\u2019t found the right abstractions.</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#separate-general-purpose-and-special-purpose-code","title":"Separate general-purpose and special-purpose code","text":"<p>If a module contains a mechanism that can be used for several different purposes, then it should provide just that one general-purpose mechanism.</p> <p>Special-purpose code associated with a general-purpose mechanism should normally go in a different module Example:</p> <pre><code>App -&gt; GUI text editor\ntext class -&gt; provide general purpose operations like delete() and insert()\nuser interface class -&gt; provide special purpose operations like delete the selection\n</code></pre> <p>Conclusion:</p> <ul> <li>the lower layers of a system tend to be more general-purpose and the upper layers more special-purpose.</li> <li>When you encounter a class that includes both general purpose and special purpose features for the same abstraction, see if the class can be separated into two classes.</li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#special-general-mixture","title":"Special-General Mixture","text":"<p>This red flag occurs when a general-purpose mechanism also contains code specialized for a particular use of that mechanism. This makes the mechanism more complicated and creates information leakage between the mechanism and the particular use case: future modifications to the use case are likely to require changes to the underlying mechanism as well.</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#splitting-and-joining-methods","title":"Splitting and joining methods","text":"<p>It is better to divide an existing method into multiple smaller methods? Or, should two smaller methods be combined into one larger one?</p> <p>Each method should do one thing and do it completely. The method should have a clean and simple interface, so that users don't need to have much information in their heads in order to use it correctly. The method should be deep: its interface should be much simpler than its implementation.</p> <ul> <li>Splitting up a method only makes sense if it results in cleaner abstractions.</li> </ul> <p></p> <ul> <li> <p>figure b: factoring out a subtask into a separate method</p> <p>makes sense if there is a subtask that is cleanly separable from the rest of the original method, which means someone reading the child method doesn't need to know anything about the parent method and vice versa.</p> <p>If you make a split of this form and then find yourself flipping back and forth between the parent and child to understand how they work together, that is a red flag indicating that the split was probably a bad idea.</p> </li> <li> <p>figure c: split a method into two separate methods, each visible to callers of the original method.</p> <p>not make sense very often -&gt; result in callers having to deal with multiple methods instead of one. run the risk of ending up with several shallow methods(figure d).</p> </li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#conjoined-methods","title":"Conjoined Methods","text":"<p>It should be possible to understand each method independently. If you can\u2019t understand the implementation of one method without also understanding the implementation of another, that\u2019s a red flag. This red flag can occur in other contexts as well: if two pieces of code are physically separated, but each can only be understood by looking at the other, that is a red flag.</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#define-errors-out-of-existence","title":"Define Errors Out Of Existence","text":"<p>Code that deals with special conditions is inherently harder to write than code that deals with normal cases, and developers often define exceptions without considering how they will be handled.</p> <ul> <li>Why exceptions contribute disproportionately to complexity?</li> <li>How to simplify exception handling?</li> </ul> <p>Key: Reduce the number of places where exceptions must be handled</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#why-exceptions-add-complexity","title":"Why exceptions add complexity","text":"<p>When exception occurs:</p> <ul> <li> <p>Approach 1: move forward and complete the work in progress in spite of the exception.</p> </li> <li> <p>Approach 2: abort the operation in progress and report the exception upwards.</p> </li> <li> <p>BUT: the exception handling code might need to restore consistency in distributed system</p> </li> <li> <p>BUT: cascade of exceptions -&gt; handle exceptions of exception handling code</p> </li> <li> <p>Try catch boilerplate</p> </li> <li>Untested error handling code: <code>\u201ccode  that    hasn\u2019t  been    executed    doesn\u2019t work\u201d</code></li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#too-many-exceptions","title":"Too many exceptions","text":"<ul> <li> <p>The exceptions thrown by a class are part of its interface; classes with lots of exceptions have complex interfaces, and they are shallower than classes with fewer exceptions.</p> </li> <li> <p>The complexity of exceptions comes from the exception handling code. The best way to reduce the complexity damage caused by exception handling is to reduce the number of places where exceptions have to be handled.</p> </li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#solution1-define-errors-out-of-existence","title":"Solution1: Define errors out of existence","text":"<p>Examples:</p> <ul> <li>Unset a non-exists variable</li> </ul> <p>I made this mistake myself in the design of the Tcl scripting language. Tcl contains an unset command that can be used to remove a variable. I defined unset so that it throws an error if the variable doesn\u2019t exist. At the time I thought that it must be a bug if someone tries to delete a variable that doesn\u2019t exist, so Tcl should report it. However, one of the most common uses of unset is to clean up temporary state created by some previous operation. It\u2019s often hard to predict exactly what state was created, particularly if the operation aborted partway through. Thus, the simplest thing is to delete all of the variables that might possibly have been created. The definition of unset makes this awkward: developers end up enclosing calls to unset in catch statements to catch and ignore errors thrown by unset. In retrospect, the definition of the unset command is one of the biggest mistakes I made in the design of Tcl.</p> <ul> <li>Java substring</li> </ul> <p>if either index is outside the range of the string, then substring throws IndexOutOfBoundsException. This exception is unnecessary and complicates the use of this method. The Java substring method would be easier to use if it performed this adjustment automatically, so that it implemented the following API: \u201creturns the characters of the string (if any) with index greater than or equal to beginIndex and less than endIndex.\u201d This is a simple and natural API, and it defines the IndexOutOfBoundsException exception out of existence.</p> <ul> <li>Argue: If errors are defined out of existence, won't that result in buggier software?</li> </ul> <p>BUT: error-ful approach may catch some bugs but increase complexity, which results in other bugs. Developers must write additional code to avoid or ignore the errors.</p> <p>The best way to reduce bugs is to make software simpler</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#solution2-mask-exceptions","title":"Solution2: Mask exceptions","text":"<p>An exceptional condition is detected and handled at a low level in the system, so that higher levels of software need not be aware of the condition.</p> <p>Example:</p> <p>For instance, in a network transport protocol such as TCP, packets can be dropped for various reasons such as corruption and congestion. TCP masks packet loss by resending lost packets within its implementation, so all data eventually gets through and clients are unaware of the dropped packets</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#solution3-exception-aggregation","title":"Solution3: Exception aggregation","text":"<p>The idea behind exception aggregation is to handle many exceptions with a single piece of code; rather than writing distinct handlers for many individual exceptions, handle them all in one place with a single handler.</p> <p>Examples:</p> <p>Consider how to handle missing parameters in a Web server. A Web server implements a collection of URLs. When the server receives an incoming URL, it dispatches to a URL-specific service method to process that URL and generate a response. The URL contains various parameters that are used to generate the response. Each service method will call a lower-level method (let\u2019s call it getParameter) to extract the parameters that it needs from the URL. If the URL does not contain the desired parameter, getParameter throws an exception.</p> <p>Design 1: catch the problem in each handle function </p> <p>Design 2: aggregate the catch clause to the higher dispatcher class </p> <ul> <li> <p>Encapsulation and Information Hiding:</p> </li> <li> <p>the top-level exception handler encapsulated knowledge about how to generate error response, but know nothing about specific errors</p> </li> <li> <p>the <code>getParameter</code> encapsulates knowledge about how to extract a parameter from a URL, and it also knows how to describe extraction errors in a human readable form, but know nothing about the syntax of HTTP error response.</p> </li> </ul> <p>NOTE: Exception aggregation works best if an exception propagates several levels up the stack before it is handled; this allows more exceptions from more methods to be handled in the same place.</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#solution4-just-crash","title":"Solution4: Just Crash?","text":"<p>In most applications there will be certain errors that it's not worth trying to handle. Typically, these errors are difficult or impossible to handle and don't occur very often. The simplest thing to do in response to these errors is to print diagnostic information and then abort the application.</p> <ul> <li>Out of Memory</li> <li>I/O Error</li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#design-special-cases-out-of-existence","title":"Design special cases out of existence","text":"<p>Special cases can result in code that is riddled with if statements, which make the code hard to understand and lead to bugs. Thus, special cases should be eliminated wherever possible. The best way to do this is by designing the normal case in a way that automatically handles the special cases without any extra code.</p> <p>Example: Text Editor -&gt; How to represent selection?</p> <p>Approach1: startIdx, endIdx, no_selection_flag -&gt; result in numerous checks to detect the no selection condition and handle it specially.</p> <p>Approach2: startIdx, endIdx -&gt; startIdx == endIdx means a empty selection. No need to define a special case!!!</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#design-it-twice","title":"Design it Twice","text":"<p>Designing software is hard, so it\u2019s unlikely that your first thoughts about how to structure a module or system will produce the best design. You\u2019ll end up with a much better result if you consider multiple options for each major design decision: design it twice.</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#why-write-comments-the-four-excuses","title":"Why Write Comments? The Four Excuses","text":"<ul> <li> <p>Good code is self-documenting -&gt; BUT: If users must read the code of a method in order to use it, then there is no abstraction</p> </li> <li> <p>I don't have time to write comments -&gt; BUT: Comments will pay for themselves, good trade off</p> </li> <li> <p>Comments get out of date and become misleading -&gt; BUT: Keep them up-to-date</p> </li> <li> <p>All the comments I have seen are worthless</p> </li> </ul> <p>The overall idea behind comments is to capture information that was in the mind of the designer but couldn't be represented in the code.</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#comments-should-describe-things-that-arent-obvious-from-the-code","title":"Comments Should Describe Things that Aren't Obvious from the Code","text":"<p>Developers should be able to understand the abstraction provided by a module without reading any code other than its externally visible declarations.</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#pick-conventions","title":"Pick conventions","text":"<ul> <li> <p>Interface: a <code>comment block</code> that immediately precedes the declaration of a   module such as a class, data structure, function, or method. The comment   describe\u2019s the module\u2019s interface.</p> </li> <li> <p>For a class, the comment describes the overall abstraction provided by the class.</p> </li> <li> <p>For a method or function, the comment describes its overall behavior, its arguments and return value, if any, any side effects or exceptions that it generates, and any other requirements the caller must satisfy before invoking the method.</p> </li> <li> <p>Data structure member: a comment <code>next to the declaration of a field</code> in a data   structure, such as an instance variable or static variable for a class.</p> </li> <li> <p>Implementation comment: a comment <code>inside</code> the code of a method or   function, which describes how the code works internally.</p> </li> <li> <p>Cross-module comment: a comment describing dependencies that cross   module boundaries.</p> </li> </ul>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#dont-repeat-the-code","title":"Don't repeat the code","text":"<ul> <li>Mistake 1:</li> </ul> <p>After write a comment, ask yourself: could someone who has never seen the code write the comment just by looking at the code next to the comment -&gt; If YES: the comments are worthless</p> <p>Example:</p> <pre><code>//Add a horizontal scroll bar\nhScrollBar = new JScrollBar(JScrollBar.HORIZONTAL);\nadd(hScrollBar, BorderLayout.SOUTH);\n// Add a vertical scroll bar\nvScrollBar = new JScrollBar(JScrollBar.VERTICAL);\nadd(vScrollBar, BorderLayout.EAST);\n// Initialize the caret-position related values\ncaretX     = 0;\ncaretY     = 0;\ncaretMemX  = null;\n</code></pre> <ul> <li>Mistake 2:</li> </ul> <p>Use the same words in the comments that appear in the name of the entity being documented</p> <p>Example:</p> <pre><code>/*\n * Obtain a normalized resource name from REQ.\n */\n private static String[] getNormalizedResourceNames(HTTPRequest req) ...\n /*\n * Downcast PARAMETER to TYPE.\n */\n private static Object downCastParameter(String parameter, String type)\n ...\n /*\n * The horizontal padding of each line in the text.\n */\n private static final int textHorizontalPadding = 4;\n</code></pre> <p> Use different words in the comments form those in the name of the entity being described</p> <p>Example:</p> <pre><code> /*\n * The amount of blank space to leave on the left and\n * right sides of each line of text, in pixels.\n */\n private static final int textHorizontalPadding = 4;\n</code></pre>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#comment-repeats-code","title":"Comment Repeats Code","text":"<p>If the information in a comment is already obvious from the code next to the comment, then the comment isn\u2019t helpful. One example of this is when the comment uses the same words that make up the name of the thing it is describing</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#lower-level-comments-add-precision","title":"Lower-level comments add precision","text":"<p>Comments augment the code by providing information at a different level of detail</p> <ul> <li>lower, more detailed, level than the code -&gt; Add precision by clarifying the exact meaning of the code</li> <li>higher, more abstract, level than the code -&gt; offer intuition, reasoning behind the code, simpler and more abstract way of thinking about the code</li> </ul> <p>Precision is most useful when commenting variable declarations such as class interface variables, method arguments, and return values.</p> <ul> <li>Problem: Comments are too vague</li> </ul> <p>Example:</p> <pre><code> //Current offset in resp Buffer\n uint32_t offset;\n // Contains all line-widths inside the document and\n // number of appearances.\n private TreeMap&lt;Integer, Integer&gt; lineWidths;\n</code></pre> <ul> <li>What does current mean?</li> <li>Are widths measured in pixels or characters?</li> </ul> <p>Better version:</p> <pre><code> //  Position in this buffer of the first object that hasn't\n //  been returned to the client.\n uint32_t offset;\n //  Holds statistics about line lengths of the form &lt;length, count&gt;\n //  where length is the number of characters in a line (including\n //  the newline), and count is the number of lines with\n //  exactly that many characters. If there are no lines with\n //  a particular length, then there is no entry for that length.\n private TreeMap&lt;Integer, Integer&gt; numLinesWithLength;\n</code></pre> <ul> <li>Document variable: think <code>nouns</code>, not <code>verbs</code></li> </ul> <p>Focus on what the variable represents, not how it is manipulated</p> <p>Example:</p> <pre><code> /* FOLLOWER VARIABLE: indicator variable that allows the Receiver and the\n * PeriodicTasks thread to communicate about whether a heartbeat has been\n * received within the follower's election timeout window.\n * Toggled to TRUE when a valid heartbeat is received.\n * Toggled to FALSE when the election timeout window is reset.  */\n private boolean receivedValidHeartbeat;\n</code></pre> <p>Better Version</p> <pre><code> /* True means that a heartbeat has been received since the last time\n * the election timer was reset. Used for communication between the\n * Receiver and PeriodicTasks threads.  */\n private boolean receivedValidHeartbeat;\n</code></pre>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#higher-level-comments-enhance-intuition","title":"Higher-level comments enhance intuition","text":"<p>Omit details and help reader to understand the overall intent and structure of the code. This approach is commonly used for comments inside methods, and for interface comments.</p> <p>Examples</p> <pre><code> // If there is a LOADING readRpc using the same session\n // as PKHash pointed to by assignPos, and the last PKHash\n // in that readRPC is smaller than current assigning\n // PKHash, then we put assigning PKHash into that readRPC.\n int readActiveRpcId = RPC_ID_NOT_ASSIGNED;\n for (int i = 0; i &lt; NUM_READ_RPC; i++) {\n      if (session == readRpc[i].session\n                 &amp;&amp; readRpc[i].status == LOADING\n                 &amp;&amp; readRpc[i].maxPos &lt; assignPos\n                 &amp;&amp; readRpc[i].numHashes &lt; MAX_PKHASHES_PERRPC) {\n          readActiveRpcId = i;\n          break;\n      }\n }\n</code></pre> <ul> <li>Too low-level and detailed</li> <li>Partially repeat the code</li> <li>does not explain the overall purpose of the code</li> </ul> <p>Better version:</p> <pre><code> // Try to append the current key hash onto an existing\n // RPC to the desired server that hasn't been sent yet.\n</code></pre> <ul> <li>No details But describes the code's overall function at higher level</li> <li>With the high-level info, a reader can explain almost everything that happens in the code</li> <li>provides a basis for readers to judge the code</li> </ul> <p>But, great software designers can also step back from the details and think about a system at a higher level. This means deciding which aspects of the system are most important, and being able to ignore the low-level details and think about the system only in terms of its most fundamental characteristics. This is the essence of abstraction (finding a simple way to think about a complex entity), and it\u2019s also what you must do when writing higher-level comments.</p>","tags":["Software Design"]},{"location":"blog/2024/01/07/philosophy-of-software-design/#interface-documentation","title":"Interface documentation","text":"<ul> <li> <p>If you want code that presents good abstractions, you must document those abstractions with comments.</p> </li> <li> <p>If interface comments must also describe the implementation, then the class or method is shalow.</p> </li> </ul>","tags":["Software Design"]},{"location":"blog/2023/06/27/syllogisms-in-ordinary-language/","title":"Syllogisms in Ordinary Language","text":""},{"location":"blog/2023/06/27/syllogisms-in-ordinary-language/#syllogistic-arguments","title":"Syllogistic Arguments","text":"<p>Daily language has three kinds of deviations</p> <ul> <li> <p>First deviation: The premises and conclusion of an argument in ordinary   language may appear in an order that is not the order of the standard-form   syllogism.</p> </li> <li> <p>Second deviation: The premises of an argument in ordinary language may appear   to involve more than three terms, but can be reduced to three without loss   of meaning.</p> </li> <li> <p>Third deviation: The component propositions of a syllogistic argument in   ordinary language may not all be standard-form propositions.</p> </li> </ul>"},{"location":"blog/2023/06/27/syllogisms-in-ordinary-language/#translating-categorical-propositions-into-standard-form","title":"Translating Categorical Propositions into Standard Form","text":""},{"location":"blog/2023/06/27/syllogisms-in-ordinary-language/#singular-propositions","title":"Singular Propositions","text":"<p>Propositions affirm or deny that a specific individual or object belongs to a given class.</p> <pre><code>Socrates is a philosopher.\nThis table is not an antique.\n</code></pre> <ul> <li> <p>To every individual object there corresponds a unique unit class(one   membered class) whose only member is that object itself.</p> </li> <li> <p>So, we can say \\(\\text{S is P}\\) is logically equivalent to \\(\\text{All S is P}\\)</p> </li> <li> <p>However, Singular Propositions have more meanings. If we just translate it   to A or E proposition, the existential import of \\(\\text{S is P}\\) is omitted.</p> </li> <li> <p> Therefore, an affirmative proposition is equivalent to the conjunction of   the related A and I categorical proposition. A negative one is equivalent   to the conjunction of E and O.</p> </li> </ul> <pre><code>S is P == All S is P and Some S is P\nS is not P == No S is P and Some S is not P\n</code></pre> <ul> <li>In this way, the distribution and existential import of Singular   Propositions are fulfilled.</li> </ul>"},{"location":"blog/2023/06/27/syllogisms-in-ordinary-language/#categorical-propositions-that-have-adjectives-or-adjectival-phrases-as-predicates-rather-than-substantives-or-class-terms","title":"Categorical Propositions That have Adjectives or Adjectival Phrases as Predicates, Rather than Substantives or Class Terms.","text":"<pre><code>Some flowers are beautiful.\nNo warships are available for active duty.\n\nSome flowers are beautiful things.\nNo warships are things available for active duty\n</code></pre>"},{"location":"blog/2023/06/27/syllogisms-in-ordinary-language/#categorical-propositions-whose-main-verbs-are-other-than-the-standard-form-copula-to-be","title":"Categorical Propositions Whose Main Verbs Are Other than the Standard-Form Copula \"To Be\"","text":"<pre><code>All people seek recogniton.\nSome people drink Greek wine.\n\nAll people are seekers fo recogniton.\nSome people are Greek-wine drinkers\n</code></pre>"},{"location":"blog/2023/06/27/syllogisms-in-ordinary-language/#statements-in-which-the-standard-form-ingredients-are-all-present-but-not-arranged-in-standard-form-order","title":"Statements in Which the Standard-Form Ingredients Are All Present But Not Arranged in Standard-Form Order","text":"<pre><code>Racehorses are all thoroughbreds.\nAll is well that ends well.\n\nAll Racehorses are thoroughbreds.\nAll things that ends well are things that are well.\n</code></pre>"},{"location":"blog/2022/07/01/notes---xv6/","title":"Notes - Xv6","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#chapter1-operating-systems-interfaces","title":"Chapter1. Operating Systems Interfaces","text":"<p>When a process needs to invoke a kernel service, it invokes a system call, one of the calls in the operating system\u2019s interface. The system call enters the kernel; the kernel performs the service and returns. Thus a process alternates between executing in user space and kernel space.</p> <p>The kernel uses the hardware protection mechanisms provided by a CPU to ensure that each process executing in user space can access only its own memory. The kernel executes with the hardware privileges required to implement these protections; user programs execute without those privileges.</p> <p>When a user program invokes a system call, the hardware raises the privilege level and starts executing a pre-arranged function in the kernel.</p> <p></p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#11-process-and-memory","title":"1.1 Process and Memory","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#xv6-system-calls-table","title":"Xv6 System Calls Table","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#system-call-example-fork","title":"System Call Example : fork()","text":"<p><code>fork</code> creates a new process, called the child process, with exactly the same memory contents as the calling process, called the parent process. Fork returns in both the parent and the child.</p> <p>In the <code>parent</code>, fork returns the child\u2019s PID;</p> <p>in the <code>child</code>, fork returns zero.</p> <p><code>exit</code> system call causes the calling process to stop executing and to release resources such as memory and open files. Exit takes an integer status argument, conventionally 0 to indicate success and 1 to indicate failure.</p> <p><code>wait</code> system call returns the PID of an exited (or killed) child of the current process and copies the exit status of the child to the address <code>(int *)0</code> passed to wait;</p> <p>if none of the caller\u2019s children has exited, wait waits for one to do so.</p> <p>If the caller has no children, wait immediately returns -1.</p> <p>If the parent doesn\u2019t care about the exit status of a child, it can pass a 0 address to wait.</p> <pre><code>##include &lt;stdio.h&gt;\n##include &lt;stdlib.h&gt;\n\nint main(int argc, char const *argv[])\n{\n    int pid = fork();\n\n    if (pid &gt; 0)\n    {\n        printf(\"parent: child=%d\\n\", pid);\n        pid = wait((int *)0);\n        printf(\"child %d is done\\n\", pid);\n    }\n    else if (pid == 0)\n    {\n        printf(\"child: exiting\\n\");\n        exit(0);\n    }\n    else\n    {\n        printf(\"fork error\\n\");\n    }\n\n    return 0;\n}\n\n//Output:\n//parent: child=4821\n//child: exiting\n//child 4821 is done\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#system-call-example-shell","title":"System Call Example: shell","text":"<p>When <code>exec</code> succeeds, it does not return to the calling program; instead, the instructions loaded from the file start executing at the entry point declared in the ELF header.</p> <pre><code>// Read and run input commands.\n  while(getcmd(buf, sizeof(buf)) &gt;= 0){\n    if(buf[0] == 'c' &amp;&amp; buf[1] == 'd' &amp;&amp; buf[2] == ' '){\n      // Chdir must be called by the parent, not the child.\n      buf[strlen(buf)-1] = 0;  // chop \\n\n      if(chdir(buf+3) &lt; 0)\n        fprintf(2, \"cannot cd %s\\n\", buf+3);\n      continue;\n    }\n    //shell\u521b\u5efa\u5b50\u8fdb\u7a0b\u53bbruncmd\uff0cshell\uff08\u7236\u8fdb\u7a0b\uff09\u8fdb\u5165\u7b49\u5f85\u72b6\u6001\n    //shell\u7ed9runcmd\u8ba9\u51faCPU\n    if(fork1() == 0)\n      runcmd(parsecmd(buf));\n    wait(0);\n  }\n  exit(0);\n}\n\nint\nfork1(void)\n{\n  int pid;\n\n  pid = fork();\n  if(pid == -1)\n    panic(\"fork\");\n  return pid;\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#how-does-system-calls-shown-above-allocate-memory","title":"How does system calls shown above allocate memory","text":"<p>Xv6 allocates most user-space memory implicitly: fork allocates the memory required for the child\u2019s copy of the parent\u2019s memory, and exec allocates enough memory to hold the executable file. A process that needs more memory at run-time (perhaps for malloc) can call <code>sbrk(n)</code> to grow its data memory by n bytes; <code>sbrk</code> returns the location of the new memory.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#12-io-and-file-descriptors","title":"1.2 I/O and File descriptors","text":"<p>A <code>file descriptor</code> is a small integer representing a kernel-managed object that a process may read from or write to.</p> <p>A process may obtain a file descriptor by opening a file, directory, or device, or by creating a pipe, or by duplicating an existing descriptor. For simplicity we\u2019ll often refer to the object a file descriptor refers to as a \u201cfile\u201d; the file descriptor interface abstracts away the differences between files, pipes, and devices, making them all look like streams of bytes.</p> <p>Internally, the xv6 kernel uses the file descriptor as an index into a <code>per-process table</code>, so that every process has a private space of file descriptors starting at zero. By convention, a process</p> <p>reads from file descriptor 0 (standard input),</p> <p>writes output to file descriptor 1 (standard output),</p> <p>writes error messages to file descriptor 2 (standard error).</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#read-write-close","title":"read(), write(), close()","text":"<p><code>Each file descriptor that refers to a file has an offset associated with it</code></p> <p>call <code>read(fd, buf, n)</code> reads at most n bytes from the file descriptor <code>fd</code>, copies them into <code>buf</code>, and returns the number of bytes read.</p> <p>call <code>write(fd, buf, n)</code> writes n bytes from <code>buf</code> to the file descriptor <code>fd</code> and returns the number of bytes written.</p> <p>The <code>close</code> system call releases a file descriptor, making it free for reuse by a future open, pipe, or dup system call (see below). A newly allocated file descriptor is always the lowest numbered unused descriptor of the current process.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#cat-source-code","title":"<code>cat</code> source code","text":"<pre><code>##include \"kernel/types.h\"\n##include \"kernel/stat.h\"\n##include \"user/user.h\"\n\nchar buf[512];\n\nvoid\ncat(int fd)\n{\n  int n;\n\n  while((n = read(fd, buf, sizeof(buf))) &gt; 0) {\n    if (write(1, buf, n) != n) {\n      fprintf(2, \"cat: write error\\n\");\n      exit(1);\n    }\n  }\n  if(n &lt; 0){\n    fprintf(2, \"cat: read error\\n\");\n    exit(1);\n  }\n}\n\nint\nmain(int argc, char *argv[])\n{\n  int fd, i;\n  //\u672a\u7ed9\u51fa\u6587\u4ef6\u540d\uff0c\u8f93\u5165\u6d41\u9ed8\u8ba4\u4e3a0\uff08\u6807\u51c6\u8f93\u5165\u6d41\uff09\n  if(argc &lt;= 1){\n    cat(0);\n    exit(0);\n  }\n//\u6709\u6587\u4ef6\u540d\uff0c\u7528open\u6253\u5f00\uff0c\u83b7\u5f97kernel\u7ed9\u8be5\u6587\u4ef6\u5206\u914d\u7684\u5177\u6709\u6700\u5c0f\u503c\u7684fd\n  for(i = 1; i &lt; argc; i++){\n    if((fd = open(argv[i], 0)) &lt; 0){\n      fprintf(2, \"cat: cannot open %s\\n\", argv[i]);\n      exit(1);\n    }\n    cat(fd);\n    close(fd);\n  }\n  exit(0);\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#io-redirection","title":"I/O Redirection","text":"<p><code>Fork</code> copies the parent\u2019s file descriptor table along with its memory, so that the child starts with exactly the same open files as the parent.</p> <p>system call <code>exec</code> replaces the calling process\u2019s memory but preserves its file table</p> <p><code>shell$ cat &lt; input.txt</code>: \u5c06file descriptor 0 \u91cd\u5b9a\u5411\u5230\u4e86<code>input.txt</code>\uff0c\u4ece\u800c<code>cat</code>\u63a5\u6536\u5230\u7684\u8f93\u5165\u4e0d\u518d\u4ece\u952e\u76d8\u6765\u3002</p> <pre><code>char *argv[2];\nargv[0] = \"cat\";\nargv[1] = 0;\n//shell\u8fdb\u7a0bwait\uff0c\u5b50\u8fdb\u7a0b\u6267\u884ccat\n//\u5b50\u8fdb\u7a0b release 0\uff08standard input\uff09\n//\u4ece\u800cinput.txt\u4e00\u5b9a\u80fd\u62ff\u52300\u4f5c\u4e3afd\n//\u5b50\u8fdb\u7a0bcat\u7684\u8f93\u5165\u6d41\u5c31\u4ece\u952e\u76d8\u53d8\u4e3a\u4e86input.txt\nif(fork() == 0) {\nclose(0);\nopen(\"input.txt\", O_RDONLY);\nexec(\"cat\", argv);\n}\n</code></pre> <p>The parent process\u2019s file descriptors are not changed by this sequence, since it modifies only the child\u2019s descriptors.</p> <p>\u8fd9\u6837\u505a\uff0cshell\u7684file descriptor(\u6307\u5411\u663e\u5b58)\u4f9d\u7136\u88abshell\u8fdb\u7a0b\u4fdd\u5b58\u7740\uff0c\u4f46\u662fcat\u8fdb\u7a0b\u7684file descriptor\u5df2\u7ecf\u88ab\u6539\u53d8\u4e86\uff08\u6307\u5411\u6587\u4ef6\uff09\u3002\u4f46**\u4e24\u4e2a\u8fdb\u7a0b\u5e76\u6ca1\u6709\u53d7\u5230\u8be5\u503c\u6539\u53d8\u7684\u5f71\u54cd\uff0c\u8fd9\u4e5f\u662f\u4e3a\u4ec0\u4e48fork\u548cexecute\u8981\u5206\u5f00\u5199\u7684\u539f\u56e0**\u3002</p> <p>Now it should be clear why it is helpful that fork and exec are separate calls: between the two, the shell has a chance to redirect the child\u2019s I/O without disturbing the I/O setup of the main shell.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#shared-file-offset","title":"Shared file offset(?)","text":"<pre><code>My Question\nfile\u7684offset\u88ab\u5171\u4eab\u7684\u8bdd\uff0c\u5982\u679c\u7236\u8fdb\u7a0bfp\u6307\u5411\u663e\u5b58\uff0c\u5b50\u8fdb\u7a0bfp\u6307\u5411\u4e86\u4e00\u4e2a\u6587\u4ef6\uff0c\u5b50\u8fdb\u7a0b\u6539\u53d8\u4e86\u504f\u79fb\u91cf\uff0c\u5f53\u8f6c\u5230\u7236\u8fdb\u7a0b\u7684\u65f6\u5019\uff0c\u7236\u8fdb\u7a0b\u4f1a\u7a7a\u51fa\u4e00\u5b9a\u91cf\u7684offset\u7ee7\u7eed\u8f93\u51fa\u561b\uff1f\u9700\u8981\u77e5\u9053file descriptors table\u7a76\u7adf\u662f\u548b\u56de\u4e8b\u3002\n</code></pre> <p>Although fork copies the file descriptor table, each underlying file offset is shared between parent and child. Two file descriptors share an offset if they were derived from the same original file descriptor by a sequence of fork and dup calls.</p> <pre><code>if(fork() == 0) {\nwrite(1, \"hello \", 6);\nexit(0);\n} else {\nwait(0);\nwrite(1, \"world\\n\", 6);\n}\n//Output\n//Hello World\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#13-pipes","title":"1.3 Pipes(*)","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#definition","title":"Definition","text":"<p>A pipe is a small kernel buffer exposed to processes as a pair of file descriptors, one for reading and one for writing. Writing data to one end of the pipe makes that data available for reading from the other end of the pipe. Pipes provide a way for processes to communicate.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#example","title":"Example","text":"<p>pipe()\u51fd\u6570\u7531\u5185\u6838\u63d0\u4f9b\u3002</p> <p>The following example code runs the program <code>wc</code> with <code>standard input</code> connected to the read end of a pipe.</p> <pre><code>int p[2];\nchar *argv[2];\nargv[0] = \"wc\";\nargv[1] = 0;\npipe(p);//\u521b\u5efa\u4e00\u4e2apipe\uff0c\u7528p\u6765\u8bb0\u5f55read\u548cwrite\u7aef\u53e3\nif(fork() == 0) {\nclose(0);\ndup(p[0]);//standard input\u73b0\u5728\u548cp[0]\uff08read\u7aef\u53e3\u8fde\u63a5\uff09\nclose(p[0]);\nclose(p[1]);\nexec(\"/bin/wc\", argv);\n} else {\nclose(p[0]);\nwrite(p[1], \"hello world\\n\", 12);\nclose(p[1]);\n}\n</code></pre> <p>\u4e0b\u56fe\u548c\u4e0a\u8ff0\u4e3e\u4f8b\u65e0\u5173\u3002</p> <p></p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#14-file-system","title":"1.4 File system","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#chdir","title":"<code>chdir()</code>","text":"<pre><code>//The first fragment changes the process\u2019s current directory to /a/b;\nchdir(\"/a\");\nchdir(\"b\");\nopen(\"c\", O_RDONLY);\n//the second neither refers to nor changes the process\u2019s current directory.\nopen(\"/a/b/c\", O_RDONLY);\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#mknod","title":"<code>mknod</code>","text":"<pre><code>mkdir(\"/dir\");\nfd = open(\"/dir/file\", O_CREATE|O_WRONLY);\nclose(fd);\n\nmknod(\"/console\", 1, 1);\n</code></pre> <p><code>Mknod</code> creates a special file that refers to a device. Associated with a device file are the major and minor device numbers (the two arguments to <code>mknod</code>), which uniquely identify a kernel device. When a process later opens a device file, t**he kernel diverts read and write system calls to the kernel device implementation** instead of passing them to the file system</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#chapter2-operating-system-organization","title":"Chapter2. Operating system organization","text":"<p>An operating system must fulfill three requirements: multiplexing, isolation, and interaction</p> <ul> <li> <p>For example, even if there are more processes than there are hardware CPUs, the operating system must ensure that a**ll of the processes get a chance to execute**.</p> </li> <li> <p>The operating system must also arrange for isolation between the processes. That is, if one process has a bug and malfunctions, it shouldn\u2019t affect processes that don\u2019t depend on the buggy process.</p> </li> <li> <p>Complete isolation, however, is too strong, since it should be possible for processes to intentionally interact;</p> </li> </ul>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#21-abstracting-physical-resources","title":"2.1 Abstracting physical resources","text":"<p>It\u2019s more typical for applications to not trust each other, and to have bugs, so one often wants stronger isolation than a cooperative scheme provides. To achieve strong isolation it\u2019s helpful to forbid applications from directly accessing sensitive hardware resources, and instead to abstract the resources into services.</p> <p>For example, Unix applications interact with storage only through the file system\u2019s open, read, write, and close system calls, instead of reading and writing the disk directly.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#22-user-mode-supervisor-mode-and-system-calls","title":"2.2 User mode, supervisor mode, and system calls","text":"<p>To achieve strong isolation, the operating system must arrange that applications cannot modify (or even read) the operating system\u2019s data structures and instructions and that applications cannot access other processes\u2019 memory.</p> <p>CPUs provide hardware support for strong isolation. For example, RISC-V has three modes in which the CPU can execute instructions: machine mode, supervisor mode, and user mode.</p> <ul> <li>a CPU starts in machine mode. Machine mode is mostly intended for configuring a computer. Xv6 executes a few lines in machine mode and then changes to supervisor mode.</li> <li>In supervisor mode the CPU is allowed to execute privileged instructions: for example, enabling and disabling interrupts, reading and writing the register that holds the address of a page table.</li> <li>An application can execute only user-mode instructions (e.g., adding numbers, etc.) and is said to be running in user space, while the software in supervisor mode can also execute privileged instruction**s and is said to be **running in kernel space. The software running in kernel space (or in supervisor mode) is called the <code>kernel</code>.</li> </ul> <p>CPUs provide a special instruction that switches the CPU from user mode to supervisor mode and enters the kernel at an entry point specified by the kernel. (RISC-V provides the <code>ecall</code> instruction for this purpose.)</p> <p>Once the CPU has switched to supervisor mode, the kernel can then validate the arguments of the system call, decide whether the application is allowed to perform the requested operation, and then deny it or execute it. It is important that the kernel control the entry point for transitions to supervisor mode; if the application could decide the kernel entry point, a malicious application could, for example, enter the kernel at a point where the validation of arguments is skipped.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#23-kernel-organization","title":"2.3 Kernel organization","text":"<p><code>monolithic kernel</code>. the entire operating system resides in the kernel, so that the implementations of all system calls run in supervisor mode.</p> <ol> <li> <p>This organization is convenient because</p> </li> <li> <p>the OS designer doesn\u2019t have to decide which part of the operating system doesn\u2019t need full hardware privilege.</p> </li> <li> <p>Furthermore, it is easier for different parts of the operating system to cooperate. For example, an operating system might have a buffer cache that can be shared both by the file system and the virtual memory system.</p> </li> <li> <p>A downside of the monolithic organization is that</p> </li> <li> <p>the interfaces between different parts of the operating system are often complex, and therefore it is easy for an operating system developer to make a mistake.</p> </li> <li>In a monolithic kernel, a mistake is fatal, because an error in supervisor mode will often cause the kernel to fail. If the kernel fails,the computer stops working, and thus all applications fail too. The computer must reboot to start again.</li> </ol> <p><code>microkernel</code>. To reduce the risk of mistakes in the kernel, OS designers can minimize the amount of operating system code that runs in supervisor mode, and execute the bulk of the operating system in user mode.</p> <p></p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#25-process-overview","title":"2.5 Process overview","text":"<p>The unit of isolation in xv6 (as in other Unix operating systems) is a process.</p> <ul> <li>The process abstraction prevents one process from wrecking or spying on another process\u2019s memory, CPU, file descriptors, etc.</li> <li>It also prevents a process from wrecking the kernel itself, so that a process can\u2019t subvert the kernel\u2019s isolation mechanisms.</li> </ul> <p>The mechanisms used by the kernel to implement processes include the user/supervisor mode flag, address spaces, and time-slicing of threads. To help enforce isolation, the process abstraction provides the illusion to a program that it has its own private machine. A process provides a program with what appears to be a private memory system, or address space, which other processes cannot read or write. A process also provides the program with what appears to be its own CPU to execute the program\u2019s instructions.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#page-tables-brief-introduction","title":"Page Tables Brief Introduction","text":"<p>Xv6 uses page tables (which are implemented by hardware) to give each process its own address space. The RISC-V page table translates (or \u201cmaps\u201d) a virtual address (the address that an RISC-V instruction manipulates) to a physical address (an address that the CPU chip sends to main memory).</p> <p></p> <p>an address space includes the process\u2019s user memory starting at virtual address zero. Instructions come first, followed by global variables, then the stack, and finally a \u201cheap\u201d area (for malloc) that the process can expand as needed.</p> <p>There are a number of factors that limit the maximum size of a process\u2019s address space: pointers on the RISC-V are 64 bits wide; the hardware only uses the low 39 bits when looking up virtual addresses in page tables; and xv6 only uses 38 of those 39 bits. Thus, the maximum address is <code>2^38 \u2212 1 = 0x3fffffffff</code>, which is MAXVA.</p> <p>At the top of the address space xv6 reserves a page for a trampoline and a page mapping the process\u2019s trapframe to switch to the kernel, as we will explain in Chapter 4.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#thread-brief-introduction","title":"Thread Brief Introduction","text":"<p>Each process has a thread of execution (or thread for short) that executes the process\u2019s instructions. A thread can be suspended and later resumed. To switch transparently between processes, the kernel suspends the currently running thread and resumes another process\u2019s thread. Much of the state of a thread (local variables, function call return addresses) is stored on the thread\u2019s stacks.</p> <p>Each process has two stacks: a user stack and a kernel stack (p-&gt;kstack).</p> <ul> <li>When the process is executing user instructions, only its user stack is in use, and its kernel stack is empty.</li> <li>When the process enters the kernel (for a system call or interrupt), the kernel code executes on the process\u2019s kernel stack;</li> <li>A process\u2019s thread alternates between actively using its user stack and its kernel stack.</li> </ul>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#system-call-start-and-end","title":"System Call Start and End","text":"<p>A process can make a system call by executing the RISC-V <code>ecall</code> instruction.</p> <p>This instruction</p> <ul> <li> <p>raises the hardware privilege level and</p> </li> <li> <p>changes the program counter to a kernel-defined entry point.</p> </li> </ul> <p>The code at the entry point switches to a kernel stack and executes the kernel instructions that implement the system call.</p> <p>When the system call completes, the kernel switches back to the user stack and returns to user space by calling the <code>sret</code> instruction,</p> <ul> <li>which lowers the hardware privilege level and resumes executing user instructions just after the system call instruction.</li> <li>A process\u2019s thread can \u201cblock\u201d in the kernel to wait for I/O, and resume where it left off when the I/O has finished.</li> </ul>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#26-code-starting-xv6-and-the-first-process","title":"2.6 Code: starting xv6 and the first process","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#machine-mode","title":"Machine Mode","text":"<p>The loader loads the xv6 kernel into memory at physical address 0x80000000. The reason it places the kernel at 0x80000000 rather than 0x0 is because the address range 0x0:0x80000000 contains I/O devices.</p> <p><code>entry.S</code></p> <p>The instructions at _entry set up a stack so that xv6 can run C code. Xv6 declares space for an initial stack, stack0, in the file <code>start.c</code> (<code>kernel/start.c:11</code>). The code at _entry loads the stack pointer register sp with the address stack0+4096, the top of the stack, because the stack on RISC-V grows down. Now that the kernel has a stack, _entry calls into C code at start (kernel/start.c:21).</p> <pre><code>## qemu -kernel loads the kernel at 0x80000000\n        # and causes each CPU to jump there.\n        # kernel.ld causes the following code to\n        # be placed at 0x80000000.\n.section .text\n_entry:\n    # set up a stack for C.\n        # stack0 is declared in start.c,\n        # with a 4096-byte stack per CPU.\n        # sp = stack0 + (hartid * 4096)\n        la sp, stack0\n        li a0, 1024*4\n        csrr a1, mhartid\n        addi a1, a1, 1\n        mul a0, a0, a1\n        add sp, sp, a0\n    # jump to start() in start.c\n        call start\nspin:\n        j spin\n</code></pre> <p><code>start.c</code></p> <p>The function start performs some configuration that is only allowed in machine mode, and then switches to supervisor mode.</p> <p>To enter supervisor mode, RISC-V provides the instruction <code>mret</code>. This instruction is most often used to return from a previous call from supervisor mode to machine mode.</p> <p>start isn\u2019t returning from such a call, and instead sets things up as if there had been one(<code>mret</code>\u672c\u8d28\u4e0a\u662f\u4ecesupervisor mode\u8df3\u8f6c\u56demachine mode\uff0c\u4e3a\u4e86\u80fd\u591f\u8ba9<code>mret</code>\u6307\u4ee4\u4f7f\u6211\u4eec\u8df3\u8f6c\u5230supervisor mode\uff0c\u9700\u8981\u505a\u5982\u4e0b\u4e8b\u60c5):</p> <p>it sets the previous privilege mode to supervisor in the register <code>mstatus</code>, it sets the return address to main by writing main\u2019s address into the register <code>mepc</code>, disables virtual address translation in supervisor mode by writing 0 into the page-table register <code>satp</code>, and delegates all interrupts and exceptions to supervisor mode. Before jumping into supervisor mode, start performs one more task: it programs the clock chip to generate timer interrupts. With this housekeeping out of the way, start \u201creturns\u201d to supervisor mode by calling <code>mret</code>. This causes the program counter to change to main (kernel/main.c:11).</p> <pre><code>// entry.S needs one stack per CPU.\n__attribute__ ((aligned (16))) char stack0[4096 * NCPU];\n\n// scratch area for timer interrupt, one per CPU.\nuint64 mscratch0[NCPU * 32];\n\n// assembly code in kernelvec.S for machine-mode timer interrupt.\nextern void timervec();\n\n// entry.S jumps here in machine mode on stack0.\nvoid\nstart()\n{\n  // set M Previous Privilege mode to Supervisor, for mret.\n  unsigned long x = r_mstatus();\n  x &amp;= ~MSTATUS_MPP_MASK;\n  x |= MSTATUS_MPP_S;\n  w_mstatus(x);\n\n  // set M Exception Program Counter to main, for mret.\n  // requires gcc -mcmodel=medany\n  w_mepc((uint64)main);\n\n  // disable paging for now.\n  w_satp(0);\n\n  // delegate all interrupts and exceptions to supervisor mode.\n  w_medeleg(0xffff);\n  w_mideleg(0xffff);\n  w_sie(r_sie() | SIE_SEIE | SIE_STIE | SIE_SSIE);\n\n  // ask for clock interrupts.\n  timerinit();\n\n  // keep each CPU's hartid in its tp register, for cpuid().\n  int id = r_mhartid();\n  w_tp(id);\n\n  // switch to supervisor mode and jump to main().\n  asm volatile(\"mret\");\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#supervisor-mode","title":"Supervisor Mode","text":"<p><code>main.c</code></p> <p><code>main</code> (kernel/main.c:11) initializes several devices and subsystems, it creates the first process by calling <code>userinit</code> (kernel/proc.c:212).</p> <p>The first process executes a small program written in RISC-V assembly, <code>initcode.S</code> (user/initcode.S:1), which re-enters the kernel by invoking the exec system call(\u7cfb\u7edf\u5f00\u542f\u540e\u7684\u7b2c\u4e00\u6b21system call).</p> <pre><code>## Initial process that execs /init.\n## This code runs in user space.\n\n##include \"syscall.h\"\n\n## exec(init, argv)\n.globl start\nstart:\n        la a0, init\n        la a1, argv\n        li a7, SYS_exec\n        ecall\n\n## for(;;) exit();\nexit:\n        li a7, SYS_exit\n        ecall\n        jal exit\n\n## char init[] = \"/init\\0\";\ninit:\n  .string \"/init\\0\"\n\n## char *argv[] = { init, 0 };\n.p2align 2\nargv:\n  .long init\n  .long 0\n</code></pre> <p><code>initcode.S</code>\u672c\u8d28\u4e0a\u5c31\u662f<code>exec(init, argv)</code>, \u56e0\u4e3a\u6b64\u65f6\u6ca1\u6709\u6587\u4ef6\u7cfb\u7edf\uff0c\u6240\u4ee5\u53ea\u80fd\u7528\u8fd9\u79cd\u65b9\u5f0f\u8fd0\u884c<code>user/init.c</code>.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#user-mode","title":"User Mode","text":"<p><code>Init</code>(user/init.c:15) creates a new console device file if needed and then opens it as file descriptors 0, 1, and 2. Then it starts a shell on the console. The system is up.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#chapter3-page-tables","title":"Chapter3. Page tables","text":"<p>Page tables are the mechanism through which the operating system provides each process with its own private address space and memory.</p> <p>Page tables determine what memory addresses mean, and what parts of physical memory can be accessed.</p> <p>They allow xv6 to isolate different process\u2019s address spaces and to multiplex them onto a single physical memory.</p> <p>Page tables also provide a level of indirection that allows xv6 to perform a few tricks:</p> <ul> <li>mapping the same memory (a trampoline page) in several address spaces,</li> <li>guarding kernel and user stacks with an unmapped page.</li> </ul>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#31-paging-hardware","title":"3.1 Paging hardware","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#terminology","title":"Terminology","text":"<ul> <li>PTE: page table entry</li> <li>PPN: physical page number</li> </ul> <p>As a reminder, RISC-V instructions (both user and kernel) manipulate virtual addresses.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#logical-page-table","title":"Logical Page Table","text":"<p>The RISC-V page table hardware connects these two kinds of addresses, by mapping each virtual address to a physical address.</p> <p>xv6 runs on Sv39 RISC-V, which means that only the bottom 39 bits of a 64-bit virtual address are used; the top 25 bits are not used.</p> <p>In this Sv39 configuration, a RISC-V page table is logically an array of <code>2^27</code> (134,217,728) page table entries (PTEs). Each PTE contains a 44-bit physical page number (PPN) and some flags.</p> <p>The paging hardware translates a virtual address by using the top 27 bits of the 39 bits to index into the page table to find a PTE, and making a 56-bit physical address whose top 44 bits come from the PPN in the PTE and whose bottom 12 bits are copied from the original virtual address.</p> <p>A Page: A page table gives the operating system control over virtual-to-physical address translations at the granularity of aligned chunks of 4096 (<code>2^12</code>) bytes. \u64cd\u4f5c\u7cfb\u7edf\u53ef\u63a7\u7684\u662f\u865a\u62df\u5730\u5740\u91cc\u768412\u4f4d\u7684offset\u3002</p> <p>In Sv39 RISC-V, the top 25 bits of a virtual address are not used for translation; in the future, RISC-V may use those bits to define more levels of translation. The physical address also has room for growth: there is room in the PTE format for the physical page number to grow by another 10 bits.\uff0864 - 44 - 10 = 10\uff09</p> <p></p> <p>\u5982\u679c\u6bcf\u4e2a\u8fdb\u7a0b\u90fd\u6709\u81ea\u5df1\u7684page table\uff0c\u90a3\u4e48\u6bcf\u4e2apage table\u8868\u4f1a\u6709\u591a\u5927\u5462\uff1f</p> <p>\u8fd9\u4e2apage table\u6700\u591a\u4f1a\u67092^27\u4e2a\u6761\u76ee\uff08\u865a\u62df\u5185\u5b58\u5730\u5740\u4e2d\u7684index\u957f\u5ea6\u4e3a27\uff09\u3002\u5982\u679c\u6bcf\u4e2a\u8fdb\u7a0b\u90fd\u4f7f\u7528\u8fd9\u4e48\u5927\u7684page table\uff0c\u8fdb\u7a0b\u9700\u8981\u4e3apage table\u6d88\u8017\u5927\u91cf\u7684\u5185\u5b58\uff0c\u5e76\u4e14\u5f88\u5feb\u7269\u7406\u5185\u5b58\u5c31\u4f1a\u8017\u5c3d\u3002</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#actual-translation","title":"Actual Translation","text":"<p>The actual translation happens in three steps.</p> <p>A page table is stored in physical memory as a three-level tree.</p> <p>The root of the tree is a 4096-byte(516 * 64bit=4096B) page-table page that contains 512 PTEs, which contain the physical addresses for page-table pages in the next level of the tree. Each of those pages contains 512 PTEs for the final level in the tree. The paging hardware uses the top 9 bits of the 27 bits to select a PTE in the root page-table page, the middle 9 bits to select a PTE in a page-table page in the next level of the tree, and the bottom 9 bits to select the final PTE.</p> <p>This three-level structure allows a page table to omit entire page table pages in the common case in which large ranges of virtual addresses have no mappings.</p> <p>To tell the hardware to use a page table, t**he kernel must write the physical address of the root page-table page into the <code>satp</code> register**. Each CPU has its own <code>satp</code>. A CPU will translate all addresses generated by subsequent instructions using the page table pointed to by its own <code>satp</code>. Each CPU has its own <code>satp</code> so that different CPUs can run different processes, each with a private address space described by its own page table.</p> <p></p> <p>\u8fd9\u79cd\u65b9\u5f0f\u7684\u4e3b\u8981\u4f18\u70b9\u662f\uff0c\u5982\u679c\u5730\u5740\u7a7a\u95f4\u4e2d\u5927\u90e8\u5206\u5730\u5740\u90fd\u6ca1\u6709\u4f7f\u7528\uff0c\u4f60\u4e0d\u5fc5\u4e3a\u6bcf\u4e00\u4e2aindex\u51c6\u5907\u4e00\u4e2a\u6761\u76ee\u3002</p> <p>\u5728\u524d\u4e00\u4e2a\u65b9\u6848\u4e2d\uff0c\u867d\u7136\u6211\u4eec\u53ea\u4f7f\u7528\u4e86\u4e00\u4e2apage\uff0c\u8fd8\u662f\u9700\u8981<code>2^27</code>\u4e2aPTE\u3002\u8fd9\u4e2a\u65b9\u6848\u4e2d\uff0c\u6211\u4eec\u53ea\u9700\u8981<code>3 * 512</code>\u4e2aPTE\u3002\u6240\u9700\u7684\u7a7a\u95f4\u5927\u5927\u51cf\u5c11\u4e86\u3002\u8fd9\u662f\u5b9e\u9645\u4e0a\u786c\u4ef6\u91c7\u7528\u8fd9\u79cd\u5c42\u6b21\u5316\u76843\u7ea7page directory\u7ed3\u6784\u7684\u4e3b\u8981\u539f\u56e0\u3002</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#ppnflags","title":"PPN+Flags","text":"<p>Each PTE contains flag bits that tell the paging hardware how the associated virtual address is allowed to be used.</p> <ul> <li> <p>PTE_V indicates whether the PTE is present: if it is not set, a reference to the page causes an exception.</p> </li> <li> <p>PTE_R controls whether instructions are allowed to read to the page.</p> </li> <li> <p>PTE_W controls whether instructions are allowed to write to the page.</p> </li> <li> <p>PTE_X controls whether the CPU may interpret the content of the page as instructions and execute them.</p> </li> <li> <p>PTE_U controls whether instructions in user mode are allowed to access the page; if PTE_U is not set, the PTE can be used only in supervisor mode.</p> </li> </ul> <p></p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#32-kernel-address-space","title":"3.2 Kernel address space","text":"<p>Xv6 maintains one page table per process, describing each process\u2019s user address space, plus a single page table that describes the kernel\u2019s address space.</p> <p>The kernel configures the layout of its address space to give itself access to physical memory and various hardware resources at predictable virtual addresses.</p> <p>QEMU simulates a computer that includes RAM (physical memory) starting at physical address 0x80000000 and continuing through at least 0x86400000, which xv6 calls PHYSTOP. The QEMU simulation also includes I/O devices such as a disk interface.</p> <p>QEMU exposes the device interfaces to software as memory-mapped control registers that sit below 0x80000000 in the physical address space. The kernel can interact with the devices by reading/writing these special physical addresses; such reads and writes communicate with the device hardware rather than with RAM.</p> <p>The kernel gets at RAM and memory-mapped device registers using \u201cdirect mapping;\u201d that is, mapping the resources at virtual addresses that are equal to the physical address.</p> <p></p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#kernel-virtual-addresses-that-arent-direct-mapped","title":"kernel virtual addresses that aren\u2019t direct-mapped","text":"<p>There are a couple of kernel virtual addresses that aren\u2019t direct-mapped:</p> <ul> <li> <p>The trampoline page. It is mapped at the top of the virtual address space; user page tables have this same mapping. we see here an interesting use case of page tables; a physical page (holding the trampoline code) is mapped twice in the virtual address space of the kernel: once at top of the virtual address space and once with a direct mapping.</p> </li> <li> <p>The kernel stack pages. Each process has its own kernel stack, which is mapped high so that below it xv6 can leave an unmapped guard page.</p> </li> </ul> <p>The guard page\u2019s PTE is invalid (PTE_V is not set), so that if the kernel overflows a kernel stack, it will likely cause an exception and the kernel will panic.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#33-code-creating-an-address-space","title":"3.3 Code: creating an address space","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#what-is-in-kernelvmc","title":"What is in <code>kernel/vm.c</code>","text":"<ul> <li>The central data structure is <code>pagetable_t</code>, which is really a pointer to a RISC-V root page-table page;</li> </ul> <pre><code>typedef uint64 *pagetable_t; // 512 PTEs\n</code></pre> <p>a <code>pagetable_t</code> may be either the kernel page table, or one of the per-process page tables.</p> <ul> <li> <p>The central functions are\uff1a</p> </li> <li> <p><code>walk</code>, which finds the PTE for a virtual address.</p> </li> <li><code>mappages</code>, which installs PTEs for new mappings.</li> <li>Functions starting with <code>kvm</code> manipulate the kernel page table;</li> <li>functions starting with <code>uvm</code> manipulate a user page table;</li> <li>other functions are used for both.</li> <li><code>copyout</code> and <code>copyin</code> copy data to and from user virtual addresses provided as system call arguments; they are in <code>vm.c</code> because they need to explicitly translate those addresses in order to find the corresponding physical memory. (\u5185\u6838\u6001\u548c\u7528\u6237\u6001\u6570\u636e\u4ea4\u4e92\u7684\u539f\u7406)</li> </ul>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#kernel-page-table-initialization","title":"Kernel Page Table Initialization","text":"<ul> <li> <p>Early in the boot sequence, <code>main</code> calls <code>kvminit</code> (kernel/vm.c:22) to create the kernel\u2019s page table. This call occurs before xv6 has enabled paging on the RISC-V, so addresses refer directly to physical memory.</p> </li> <li> <p><code>Kvminit</code> first allocates a page of physical memory to hold the root page-table page.</p> </li> <li> <p>Then it calls <code>kvmmap</code> to install the translations that the kernel needs. The translations include the kernel\u2019s instructions and data, physical memory up to PHYSTOP, and memory ranges which are actually devices.</p> <pre><code>/*\n * create a direct-map page table for the kernel.\n */\nvoid\nkvminit()\n{\n  kernel_pagetable = (pagetable_t) kalloc();\n  memset(kernel_pagetable, 0, PGSIZE);\n\n  // uart registers\n  kvmmap(UART0, UART0, PGSIZE, PTE_R | PTE_W);\n\n  // virtio mmio disk interface\n  kvmmap(VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W);\n\n  // CLINT\n  kvmmap(CLINT, CLINT, 0x10000, PTE_R | PTE_W);\n\n  // PLIC\n  kvmmap(PLIC, PLIC, 0x400000, PTE_R | PTE_W);\n\n  // map kernel text executable and read-only.\n  kvmmap(KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X);\n\n  // map kernel data and the physical RAM we'll make use of.\n  kvmmap((uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W);\n\n  // map the trampoline for trap entry/exit to\n  // the highest virtual address in the kernel.\n  kvmmap(TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X);\n}\n</code></pre> </li> <li> <p><code>kvmmap</code> (kernel/vm.c:118) calls <code>mappages</code> (kernel/vm.c:149), which installs mappings into a page table for a range of virtual addresses to a corresponding range of physical addresses.</p> </li> <li> <p>It does this separately for each virtual address in the range, at page intervals.</p> <p>For each virtual address to be mapped, <code>mappages</code> calls <code>walk</code> to find the address of the PTE for that address. It then initializes the PTE to hold the relevant physical page number, the desired permissions (PTE_W, PTE_X, and/or PTE_R), and PTE_V to mark the PTE as valid (kernel/vm.c:161).</p> <pre><code>// add a mapping to the kernel page table.\n// only used when booting.\n// does not flush TLB or enable paging.\nvoid\nkvmmap(uint64 va, uint64 pa, uint64 sz, int perm)\n{\n  if(mappages(kernel_pagetable, va, sz, pa, perm) != 0)\n    panic(\"kvmmap\");\n}\n\n// Create PTEs for virtual addresses starting at va that refer to\n// physical addresses starting at pa. va and size might not\n// be page-aligned. Returns 0 on success, -1 if walk() couldn't\n// allocate a needed page-table page.\nint\nmappages(pagetable_t pagetable, uint64 va, uint64 size, uint64 pa, int perm)\n{\n  uint64 a, last;\n  pte_t *pte;\n\n  a = PGROUNDDOWN(va);\n  last = PGROUNDDOWN(va + size - 1);\n  for(;;){\n    if((pte = walk(pagetable, a, 1)) == 0)\n      return -1;\n    if(*pte &amp; PTE_V)\n      panic(\"remap\");\n    *pte = PA2PTE(pa) | perm | PTE_V;\n    if(a == last)\n      break;\n    a += PGSIZE;\n    pa += PGSIZE;\n  }\n  return 0;\n}\n</code></pre> </li> <li> <p><code>walk</code> (kernel/vm.c:72) mimics the RISC-V paging hardware as it looks up the PTE for a virtual address (see Figure 3.2). <code>walk</code> descends the 3-level page table 9 bits at the time.</p> </li> <li> <p>It uses each level\u2019s 9 bits of virtual address to find the PTE of either the next-level page table or the final page(kernel/vm.c:78). If the PTE isn\u2019t valid, then the required page hasn\u2019t yet been allocated;</p> </li> <li>if the <code>alloc</code> argument is set, <code>walk</code> allocates a new page-table page and puts its physical address in the PTE.</li> <li>It returns the address of the PTE in the lowest layer in the tree (kernel/vm.c:88).</li> </ul> <pre><code>// Return the address of the PTE in page table pagetable\n// that corresponds to virtual address va.  If alloc!=0,\n// create any required page-table pages.\n//\n// The risc-v Sv39 scheme has three levels of page-table\n// pages. A page-table page contains 512 64-bit PTEs.\n// A 64-bit virtual address is split into five fields:\n//   39..63 -- must be zero.\n//   30..38 -- 9 bits of level-2 index.\n//   21..29 -- 9 bits of level-1 index.\n//   12..20 -- 9 bits of level-0 index.\n//    0..11 -- 12 bits of byte offset within the page.\npte_t *\nwalk(pagetable_t pagetable, uint64 va, int alloc)\n{\n  if(va &gt;= MAXVA)\n    panic(\"walk\");\n\n  for(int level = 2; level &gt; 0; level--) {\n    pte_t *pte = &amp;pagetable[PX(level, va)];\n    if(*pte &amp; PTE_V) {\n      pagetable = (pagetable_t)PTE2PA(*pte);\n    } else {\n      if(!alloc || (pagetable = (pde_t*)kalloc()) == 0)\n        return 0;\n      memset(pagetable, 0, PGSIZE);\n      *pte = PA2PTE(pagetable) | PTE_V;\n    }\n  }\n  return &amp;pagetable[PX(0, va)];\n}\n</code></pre> <p>The above code depends on physical memory being direct-mapped into the kernel virtual address space. For example, as walk descends levels of the page table, it pulls the (physical) address of the next-level-down page table from a PTE (kernel/vm.c:80), and then uses that address as a virtual address to fetch the PTE at the next level down (kernel/vm.c:78).</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#user-page-table-initialization","title":"User Page Table Initialization","text":"<ul> <li>main calls <code>kvminithart</code> (kernel/vm.c:53) to install the kernel page table. It writes the physical address of the root page-table page into the register <code>satp</code>. After this the CPU will translate addresses using the kernel page table. Since the kernel uses an identity mapping, the now virtual address of the next instruction will map to the right physical memory address.</li> </ul> <p>Each RISC-V CPU caches page table entries in a Translation Look-aside Buffer (TLB), and when xv6 changes a page table, it must tell the CPU to invalidate corresponding cached TLB entries. If it didn\u2019t, then at some point later the TLB might use an old cached mapping, pointing to a physical page that in the meantime has been allocated to another process, and as a result, a process might be able to scribble(\u4e71\u6d82) on some other process\u2019s memory. The RISC-V has an instruction <code>sfence.vma</code> that flushes the current CPU\u2019s TLB. xv6 executes <code>sfence.vma</code> in <code>kvminithart</code> after reloading the <code>satp</code> register, and in the trampoline code that switches to a user page table before returning to user space.</p> <pre><code>// Switch h/w page table register to the kernel's page table,\n// and enable paging.\nvoid\nkvminithart()\n{\n  w_satp(MAKE_SATP(kernel_pagetable));\n  sfence_vma();\n}\n</code></pre> <ul> <li><code>procinit</code> (kernel/proc.c:26), which is called from main, allocates a kernel stack for each process. It maps each stack at the virtual address generated by KSTACK, which leaves room for the invalid stack-guard pages. <code>kvmmap</code> adds the mapping PTEs to the kernel page table, and the call to <code>kvminithart</code> reloads the kernel page table into <code>satp</code> so that the hardware knows about the new PTEs.</li> </ul> <pre><code>// initialize the proc table at boot time.\nvoid\nprocinit(void)\n{\n  struct proc *p;\n\n  initlock(&amp;pid_lock, \"nextpid\");\n  for(p = proc; p &lt; &amp;proc[NPROC]; p++) {\n      initlock(&amp;p-&gt;lock, \"proc\");\n\n      // Allocate a page for the process's kernel stack.\n      // Map it high in memory, followed by an invalid\n      // guard page.\n      char *pa = kalloc();\n      if(pa == 0)\n        panic(\"kalloc\");\n      uint64 va = KSTACK((int) (p - proc));\n      kvmmap(va, (uint64)pa, PGSIZE, PTE_R | PTE_W);\n      p-&gt;kstack = va;\n  }\n  kvminithart();\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#34-physical-memory-allocation","title":"3.4 Physical memory allocation","text":"<p>The kernel must allocate and free physical memory at run-time for page tables, user memory, kernel stacks, and pipe buffers. xv6 uses the physical memory between the end of the kernel and PHYSTOP for run-time allocation. It allocates and frees whole 4096-byte pages at a time. It keeps track of which pages are free by threading a linked list through the pages themselves. Allocation consists of removing a page from the linked list; freeing consists of adding the freed page to the list.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#35-code-physical-memory-allocator","title":"3.5 Code: Physical memory allocator","text":"<ul> <li> <p>The allocator resides in <code>kalloc.c</code> (kernel/kalloc.c:1).</p> </li> <li> <p>The allocator\u2019s data structure is a free list of physical memory pages that are available for allocation. Each free page\u2019s list element is a struct run (kernel/kalloc.c:17).</p> <pre><code>struct run {\n  struct run *next;\n};\n</code></pre> </li> <li> <p>Where does the allocator get the memory to hold that data structure? It store each free page\u2019s run structure in the free page itself, since there\u2019s nothing else stored there.</p> </li> <li> <p>The function main calls <code>kinit</code> to initialize the allocator (kernel/kalloc.c:27). kinit initializes the free list to hold every page between the end of the kernel and <code>PHYSTOP</code>. xv6 ought to determine how much physical memory is available by parsing configuration information provided by the hardware. Instead xv6 assumes that the machine has 128 megabytes of RAM.</p> <pre><code>void\nkinit()\n{\n  initlock(&amp;kmem.lock, \"kmem\");\n  freerange(end, (void*)PHYSTOP);\n}\n</code></pre> </li> <li> <p>kinit calls <code>freerange</code> to add memory to the free list via per-page calls to <code>kfree</code>. A PTE can only refer to a physical address that is aligned on a 4096-byte boundary (is a multiple of 4096), so <code>freerange</code> uses <code>PGROUNDUP</code> to ensure that it frees only aligned physical addresses.</p> <pre><code>void\nfreerange(void *pa_start, void *pa_end)\n{\n  char *p;\n  p = (char*)PGROUNDUP((uint64)pa_start);\n  for(; p + PGSIZE &lt;= (char*)pa_end; p += PGSIZE)\n    kfree(p);\n}\n</code></pre> </li> <li> <p>The function <code>kfree</code> (kernel/kalloc.c:47) begins by setting every byte in the memory being freed to the value 1. This will cause code that uses memory after freeing it (uses \u201cdangling references\u201d) to read garbage instead of the old valid contents; hopefully that will cause such code to break faster. Then <code>kfree</code> prepends the page to the free list: it casts pa to a pointer to struct run, records the old start of the free list in r-&gt;next, and sets the free list equal to r. <code>kalloc</code> removes and returns the first element in the free list.</p> <pre><code>// Free the page of physical memory pointed at by v,\n// which normally should have been returned by a\n// call to kalloc().  (The exception is when\n// initializing the allocator; see kinit above.)\nvoid\nkfree(void *pa)\n{\n  struct run *r;\n\n  if(((uint64)pa % PGSIZE) != 0 || (char*)pa &lt; end || (uint64)pa &gt;= PHYSTOP)\n    panic(\"kfree\");\n\n  // Fill with junk to catch dangling refs.\n  memset(pa, 1, PGSIZE);\n\n  r = (struct run*)pa;\n\n  acquire(&amp;kmem.lock);\n  r-&gt;next = kmem.freelist;\n  kmem.freelist = r;\n  release(&amp;kmem.lock);\n}\n</code></pre> </li> </ul>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#36-process-address-space","title":"3.6 Process address space","text":"<p>Each process has a separate page table, and when xv6 switches between processes, it also changes page tables. As Figure 2.3 shows, a process\u2019s user memory starts at virtual address zero and can grow up to MAXVA (kernel/riscv.h:348), allowing a process to address in principle 256 Gigabytes of memory (<code>#define MAXVA (1L &lt;&lt; (9 + 9 + 9 + 12 - 1))</code>).</p> <p></p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#how-does-a-process-obtain-memory","title":"How Does a Process Obtain Memory","text":"<p>When a process asks xv6 for more user memory,</p> <ol> <li>xv6 first uses <code>kalloc</code> to allocate physical pages.</li> <li>It then adds PTEs to the process\u2019s page table that point to the new physical pages. Xv6 sets the PTE_W, PTE_X, PTE_R, PTE_U, and PTE_V flags in these PTEs. Most processes do not use the entire user address space; xv6 leaves PTE_V clear in unused PTEs.</li> </ol>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#use-of-page-tables","title":"Use of Page Tables","text":"<p>We see here a few nice examples of use of page tables.</p> <ol> <li>First, different processes\u2019 page tables translate user addresses to different pages of physical memory, so that each process has private user memory.</li> <li>Second, each process sees its memory as having contiguous virtual addresses starting at zero, while the process\u2019s physical memory can be non-contiguous.</li> <li>Third, the kernel maps a page with trampoline code at the top of the user address space, thus a single page of physical memory shows up in all address spaces.</li> </ol>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#layout-of-the-user-memory-of-an-executing-process","title":"Layout of the User Memory of an Executing Process","text":"<p>Figure 3.4 shows the layout of the user memory of an executing process in xv6 in more detail. The stack is a single page, and is shown with the initial contents as created by exec. Strings containing the command-line arguments, as well as an array of pointers to them, are at the very top of the stack. Just under that are values that allow a program to start at main as if the function <code>main(argc, argv)</code> had just been called.</p> <p></p> <p>To detect a user stack overflowing the allocated stack memory, xv6 places an invalid guard page right below the stack. If the user stack overflows and the process tries to use an address below the stack, the hardware will generate a page-fault exception because the mapping is not valid. A real-world operating system might instead automatically allocate more memory for the user stack when it overflows.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#37-code-sbrk","title":"3.7 Code: <code>sbrk</code>","text":"<p><code>Sbrk</code> is the system call for a process to shrink or grow its memory. <code>sbrk()</code> change the location of the program break, which defines the end of the process's data segment (i.e., the program break is the first location after the end of the uninitialized data segment).</p> <p>The system call is implemented by the function <code>growproc</code> (kernel/proc.c:239). <code>growproc</code> calls <code>uvmalloc</code> or <code>uvmdealloc</code>, depending on whether n is positive or negative.</p> <pre><code>// Grow or shrink user memory by n bytes.\n// Return 0 on success, -1 on failure.\nint\ngrowproc(int n)\n{\n  uint sz;\n  struct proc *p = myproc();\n\n  sz = p-&gt;sz;\n  if(n &gt; 0){\n    if((sz = uvmalloc(p-&gt;pagetable, sz, sz + n)) == 0) {\n      return -1;\n    }\n  } else if(n &lt; 0){\n    sz = uvmdealloc(p-&gt;pagetable, sz, sz + n);\n  }\n  p-&gt;sz = sz;\n  return 0;\n}\n</code></pre> <p><code>uvmalloc</code> (kernel/vm.c:229) allocates physical memory with <code>kalloc</code>, and adds PTEs to the user page table with <code>mappages</code>.</p> <pre><code>// Allocate PTEs and physical memory to grow process from oldsz to\n// newsz, which need not be page aligned.  Returns new size or 0 on error.\nuint64\nuvmalloc(pagetable_t pagetable, uint64 oldsz, uint64 newsz)\n{\n  char *mem;\n  uint64 a;\n\n  if(newsz &lt; oldsz)\n    return oldsz;\n\n  oldsz = PGROUNDUP(oldsz);\n  for(a = oldsz; a &lt; newsz; a += PGSIZE){\n    mem = kalloc();\n    if(mem == 0){\n      uvmdealloc(pagetable, a, oldsz);\n      return 0;\n    }\n    memset(mem, 0, PGSIZE);\n    if(mappages(pagetable, a, PGSIZE, (uint64)mem, PTE_W|PTE_X|PTE_R|PTE_U) != 0){\n      kfree(mem);\n      uvmdealloc(pagetable, a, oldsz);\n      return 0;\n    }\n  }\n  return newsz;\n}\n</code></pre> <p><code>uvmdealloc</code> calls <code>uvmunmap</code> (kernel/vm.c:174), which uses <code>walk</code> to find PTEs and <code>kfree</code> to free the physical memory they refer to.</p> <pre><code>// Deallocate user pages to bring the process size from oldsz to\n// newsz.  oldsz and newsz need not be page-aligned, nor does newsz\n// need to be less than oldsz.  oldsz can be larger than the actual\n// process size.  Returns the new process size.\nuint64\nuvmdealloc(pagetable_t pagetable, uint64 oldsz, uint64 newsz)\n{\n  if(newsz &gt;= oldsz)\n    return oldsz;\n\n  if(PGROUNDUP(newsz) &lt; PGROUNDUP(oldsz)){\n    int npages = (PGROUNDUP(oldsz) - PGROUNDUP(newsz)) / PGSIZE;\n    uvmunmap(pagetable, PGROUNDUP(newsz), npages, 1);\n  }\n\n  return newsz;\n}\n\n// Remove npages of mappings starting from va. va must be\n// page-aligned. The mappings must exist.\n// Optionally free the physical memory.\nvoid\nuvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free)\n{\n  uint64 a;\n  pte_t *pte;\n\n  if((va % PGSIZE) != 0)\n    panic(\"uvmunmap: not aligned\");\n\n  for(a = va; a &lt; va + npages*PGSIZE; a += PGSIZE){\n    if((pte = walk(pagetable, a, 0)) == 0)\n      panic(\"uvmunmap: walk\");\n    if((*pte &amp; PTE_V) == 0)\n      panic(\"uvmunmap: not mapped\");\n    if(PTE_FLAGS(*pte) == PTE_V)\n      panic(\"uvmunmap: not a leaf\");\n    if(do_free){\n      uint64 pa = PTE2PA(*pte);\n      kfree((void*)pa);\n    }\n    *pte = 0;\n  }\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#why-use-page-table","title":"Why use page table","text":"<p>xv6 uses a process\u2019s page table</p> <ol> <li>tell the hardware how to map user virtual addresses,</li> <li>the only record of which physical memory pages are allocated to that process. That is the reason why freeing user memory (in <code>uvmunmap</code>) requires examination of the user page table.</li> </ol>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#38-code-exec","title":"3.8 Code: <code>exec</code>","text":"<p><code>Exec</code> is the system call that creates the user part of an address space.</p> <ol> <li>It initializes the user part of an address space from a file stored in the file system.</li> <li><code>Exec</code> (kernel/exec.c:13) opens the named binary path using <code>namei</code> (kernel/exec.c:26), which is explained in Chapter 8. Then, it reads the ELF header.</li> </ol>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#elf-format","title":"ELF format","text":"<p>Xv6 applications are described in the widely-used ELF format, defined in (<code>kernel/elf.h</code>).</p> <p>An ELF binary consists of an ELF header, struct <code>elfhdr</code> **(kernel/elf.h:6), **followed by a sequence of program section headers, struct <code>proghdr</code> (kernel/elf.h:25).</p> <p>Each <code>proghdr</code> describes a section of the application that must be loaded into memory;</p> <p>xv6 programs have only one program section header, but other systems might have separate sections for instructions and data.</p> <pre><code>// File header\nstruct elfhdr {\n  uint magic;  // must equal ELF_MAGIC\n  uchar elf[12];\n  ushort type;\n  ushort machine;\n  uint version;\n  uint64 entry;\n  uint64 phoff;\n  uint64 shoff;\n  uint flags;\n  ushort ehsize;\n  ushort phentsize;\n  ushort phnum;\n  ushort shentsize;\n  ushort shnum;\n  ushort shstrndx;\n};\n\n// Program section header\nstruct proghdr {\n  uint32 type;\n  uint32 flags;\n  uint64 off;\n  uint64 vaddr;\n  uint64 paddr;\n  uint64 filesz;\n  uint64 memsz;\n  uint64 align;\n};\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#how-to-check-the-file-probably-contains-an-elf-binary","title":"How to check the file probably contains an ELF binary","text":"<p>An ELF binary starts with the four-byte \u201cmagic number\u201d 0x7F, \u2018E\u2019, \u2018L\u2019, \u2018F\u2019, or ELF_MAGIC (kernel/elf.h:3). If the ELF header has the right magic number, exec assumes that the binary is well-formed.</p> <pre><code>##define ELF_MAGIC 0x464C457FU  // \"\\x7FELF\" in little endian\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#execc","title":"<code>exec.c</code>","text":"<p><code>exec(char *path, char **argv)</code></p> <ul> <li> <p>allocates a new page table with no user mappings with <code>proc_pagetable</code> (kernel/exec.c:38),</p> </li> <li> <p>allocates memory for each ELF segment with <code>uvmalloc</code> (kernel/exec.c:52), and</p> </li> <li> <p>loads each segment into memory with <code>loadseg</code> (kernel/exec.c:10). <code>loadseg</code> uses <code>walkaddr</code> to find the physical address of the allocated memory at which to write each page of the ELF segment, and <code>readi</code> to read from the file.</p> </li> </ul>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#example-of-execinit-argv","title":"Example of <code>exec(\"/init\", argv)</code>","text":"<p>The program section header for <code>/init</code>, the first user program created with exec, looks like this:</p> <p></p> <ul> <li> <p>The program section header\u2019s <code>filesz</code> may be less than the <code>memsz</code>, indicating that the gap between them should be filled with zeroes (for C global variables) rather than read from the file. For <code>/init</code>, <code>filesz</code> is 2112 bytes and <code>memsz</code> is 2136 bytes, and thus <code>uvmalloc</code> allocates enough physical memory to hold 2136 bytes, but reads only 2112 bytes from the file<code>/init</code>.</p> </li> <li> <p>Now <code>exec</code> allocates and initializes the user stack. It allocates just one stack page. <code>Exec</code> copies the argument strings to the top of the stack one at a time, recording the pointers to them in <code>ustack</code>. It places a null pointer at the end of what will be the <code>argv</code> list passed to main. The first three entries in <code>ustack</code> are the fake return program counter, <code>argc</code>, and <code>argv</code> pointer.</p> </li> <li> <p><code>Exec</code> places an inaccessible page just below the stack page, so that programs that try to use more than one page will fault. This inaccessible page also allows exec to deal with arguments that are too large; in that situation, the <code>copyout</code> (kernel/vm.c:355) function that exec uses to copy arguments to the stack will notice that the destination page is not accessible, and will return -1.</p> </li> </ul>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#error-handling","title":"Error handling","text":"<p>During the preparation of the new memory image,</p> <p>if exec detects an error like an invalid program segment, it jumps to the label bad, frees the new image, and returns -1.</p> <p>Exec must wait to free the old image until it is sure that the system call will succeed: if the old image is gone, the system call cannot return -1 to it.</p> <p>The only error cases in exec happen during the creation of the image. Once the image is complete, exec can commit to the new page table (kernel/exec.c:113) and free the old one (kernel/exec.c:117).</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#risk-of-exec","title":"Risk of <code>exec()</code>","text":"<p>Exec loads bytes from the ELF file into memory at addresses specified by the ELF file. Users or processes can place whatever addresses they want into an ELF file. Thus exec is risky, because the addresses in the ELF file may refer to the kernel, accidentally or on purpose. The consequences for an unwary kernel could range from a crash to a malicious subversion of the kernel\u2019s isolation mechanisms (i.e., a security exploit). xv6 performs a number of checks to avoid these risks. For example <code>if (ph.vaddr + ph.memsz &lt; ph.vaddr)</code> checks for whether the sum overflows a 64-bit integer. The danger is that a user could construct an ELF binary with a <code>ph.vaddr</code> that points to a user-chosen address, and <code>ph.memsz</code> large enough that the sum overflows to 0x1000, which will look like a valid value. In an older version of xv6 in which the user address space also contained the kernel (but not readable/writable in user mode), the user could choose an address that corresponded to kernel memory and would thus copy data from the ELF binary into the kernel. In the RISC-V version of xv6 this cannot happen, because the kernel has its own separate page table; <code>loadseg</code> loads into the process\u2019s page table, not in the kernel\u2019s page table.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#chapter4-traps-and-system-calls","title":"Chapter4. Traps and system calls","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#trap","title":"Trap","text":"<p>There are three kinds of event which cause the CPU to set aside ordinary execution of instructions and force a transfer of control to special code that handles the event.</p> <ul> <li>One situation is a system call, when a user program executes the <code>ecall</code> instruction to ask the kernel to do something for it.</li> <li>Another situation is an exception: an instruction (user or kernel) does something illegal, such as divide by zero or use an invalid virtual address.</li> <li>The third situation is a device interrupt, when a device signals that it needs attention, for example when the disk hardware finishes a read or write request.</li> </ul> <p>This book uses <code>trap</code> as a generic term for these situations.</p> <p>Typically whatever code was executing at the time of the trap will later need to resume, and shouldn\u2019t need to be aware that anything special happened. That is, we often want traps to be transparent; this is particularly important for interrupts, which the interrupted code typically doesn\u2019t expect.</p> <p>The usual sequence is that</p> <ul> <li>a trap forces a transfer of control into the kernel;</li> <li>the kernel saves registers and other state so that execution can be resumed;</li> <li>the kernel executes appropriate handler code (e.g., a system call implementation or device driver);</li> <li>the kernel restores the saved state and returns from the trap; and the original code resumes where it left off.</li> </ul>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#41-risc-v-trap-machinery","title":"4.1 RISC-V trap machinery","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#registers-for-trap","title":"Registers for Trap","text":"<p>Each RISC-V CPU has a set of control registers that the kernel writes to tell the CPU how to handle traps, and that the kernel can read to find out about a trap that has occurred. The RISC-V documents contain the full story. <code>riscv.h</code> (kernel/riscv.h:1) contains definitions that xv6 uses. Here\u2019s an outline of the most important registers:</p> <ul> <li> <p><code>stvec</code>: The kernel writes the address of its trap handler here; the RISC-V jumps here to handle a trap.</p> </li> <li> <p><code>sepc</code>: When a trap occurs, RISC-V saves the program counter here (since the pc is then overwritten with <code>stvec</code>). The <code>sret</code> (return from trap) instruction copies <code>sepc</code> to the pc. The kernel can write to <code>sepc</code> to control where <code>sret</code> goes.</p> </li> <li> <p><code>scause</code>: The RISC-V puts a number here that describes the reason for the trap.</p> </li> <li> <p><code>sscratch</code>: The kernel places a value here that comes in handy at the very start of a trap handler.</p> </li> <li> <p><code>sstatus</code>: The SIE bit in <code>sstatus</code> controls whether device interrupts are enabled. If the kernel clears SIE, the RISC-V will defer device interrupts until the kernel sets SIE. The SPP bit indicates whether a trap came from user mode or supervisor mode, and controls to what mode <code>sret</code> returns.</p> </li> </ul> <p>The above registers relate to traps handled in supervisor mode, and they cannot be read or written in user mode. There is an equivalent set of control registers for traps handled in machine mode; xv6 uses them only for the special case of timer interrupts. Each CPU on a multi-core chip has its own set of these registers, and more than one CPU may be handling a trap at any given time.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#cpu-hardwares-trap-handling-sequence","title":"CPU hardware\u2019s trap handling sequence","text":"<p>When it needs to force a trap, the RISC-V hardware does the following for all trap types (other than timer interrupts):</p> <ol> <li>If the trap is a device interrupt, and the sstatus SIE bit is clear, don\u2019t do any of the following.</li> <li>Disable interrupts by clearing SIE.</li> <li>Copy the pc to <code>sepc</code>.</li> <li>Save the current mode (user or supervisor) in the SPP bit in sstatus.</li> <li>Set <code>scause</code> to reflect the trap\u2019s cause.</li> <li>Set the mode to supervisor.</li> <li>Copy <code>stvec</code> to the pc.</li> <li>Start executing at the new pc.</li> </ol> <p>Note that the CPU doesn\u2019t switch to the kernel page table, doesn\u2019t switch to a stack in the kernel, and doesn\u2019t save any registers other than the pc.</p> <p>Kernel software must perform these tasks.</p> <p>One reason that the CPU does minimal work during a trap is to provide flexibility to software; for example, some operating systems don\u2019t require a page table switch in some situations, which can increase performance.</p> <p>You might wonder whether the CPU hardware\u2019s trap handling sequence could be further simplified. For example, suppose that the CPU didn\u2019t switch program counters. Then a trap could switch to supervisor mode while still running user instructions. Those user instructions could break the user/kernel isolation, for example by modifying the <code>satp</code> register to point to a page table that allowed accessing all of physical memory. It is thus important that the CPU switch to a kernel specified instruction address, namely <code>stvec</code>.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#42-traps-from-user-space","title":"4.2 Traps from user space","text":"<p>CPU\u5bf9\u4e8etrap\u6240\u505a\u7684\u4e8b\u5176\u5b9e\u5f88\u5c11\uff0c\u4ed6\u53ea\u8bbe\u7f6e\u4e86\u4e00\u4e9bflag\u5e76\u4fdd\u5b58\u4e86pc\u503c\uff0c\u7136\u540e\u8ba9pc\u6307\u5411\u4e86\u672c\u7ae0\u5185\u5bb9\u7684\u5f00\u7aef<code>uservec</code>\u3002<code>uservec</code>\u5c31\u8981\u60f3\u529e\u6cd5\u5207\u6362\u9875\u8868\u5e76\u4fdd\u5b58\u7528\u6237\u6001\u5360\u6709\u7684\u5bc4\u5b58\u5668\u3002\u4ece\u800c\u4e3a\u6267\u884ctrap\u7684handler\u4ee3\u7801\u63d0\u4f9b\u8fd0\u884c\u73af\u5883\u3002</p> <p>A trap may occur while executing in user space if the user program makes a system call (<code>ecall</code> instruction), or does something illegal, or if a device interrupts. The high-level path of a trap from user space is <code>uservec</code> (kernel/trampoline.S:16), then <code>usertrap</code> (kernel/trap.c:37); and when returning, <code>usertrapret</code> (kernel/trap.c:90) and then <code>userret</code> (kernel/trampoline.S:16).</p> <p>Traps from user code are more challenging than from the kernel, since <code>satp</code> points to a user page table that doesn\u2019t map the kernel, and the stack pointer may contain an invalid or even malicious value.</p> <p>Because the RISC-V hardware doesn\u2019t switch page tables during a trap, the user page table must include a mapping for <code>uservec</code>, the trap vector instructions that <code>stvec</code> points to. <code>uservec</code> must switch <code>satp</code> to point to the kernel page table;</p> <p>in order to continue executing instructions after the switch, <code>uservec</code> must be mapped at the same address in the kernel page table as in the user page table.</p> <p>\u56e0\u4e3a<code>uservec</code>\u4f7f\u547d\u662f\u8981\u505aCPU\u6ca1\u6709\u505a\u7684\u4e8b\uff0c\u6700\u91cd\u8981\u7684\u5c31\u662f\u9875\u8868\u7684\u5207\u6362\u3002\u90a3\u4e48\u518d\u5207\u6362\u4e86\u9875\u8868\u4e4b\u540e\uff0c\u4e3a\u4e86\u8ba9\u7528\u6237\u9875\u8868\u91cc\u7684\u4ee3\u7801\u5728\u5207\u6362\u5230\u5185\u6838\u9875\u8868\u540e\u4e5f\u80fd\u8fd0\u884c\uff0c\u6211\u4eec\u5728\u4e24\u8005\u76f8\u540c\u7684\u865a\u62df\u5730\u5740\u5904\u9884\u5148\u653e\u5165\u4e86\u4e00\u6837\u7684\u4ee3\u7801\u3002\u8fd9\u4e2a\u76f8\u540c\u7684\u5730\u5740\u533a\u57df\u5982\u4e0b\u6240\u8ff0\u3002</p> <p>Xv6 satisfies these constraints with a trampoline page that contains <code>uservec</code>. Xv6 maps the trampoline page at the same virtual address in the kernel page table and in every user page table. This virtual address is <code>TRAMPOLINE</code> (as we saw in Figure 2.3 and in Figure 3.3). The trampoline contents are set in <code>trampoline.S</code>, and (when executing user code) <code>stvec</code> is set to <code>uservec</code> (kernel/trampoline.S:16).</p> <pre><code>uservec:\n    #\n        # trap.c sets stvec to point here, so\n        # traps from user space start here,\n        # in supervisor mode, but with a\n        # user page table.\n        #\n        # sscratch points to where the process's p-&gt;trapframe is\n        # mapped into user space, at TRAPFRAME.\n        #\n\n    # swap a0 and sscratch\n        # so that a0 is TRAPFRAME\n        csrrw a0, sscratch, a0\n\n        # save the user registers in TRAPFRAME\n        sd ra, 40(a0)\n        sd sp, 48(a0)\n        sd gp, 56(a0)\n        sd tp, 64(a0)\n        sd t0, 72(a0)\n        sd t1, 80(a0)\n        .\n        .\n        .\n</code></pre> <p>When <code>uservec</code> starts, all 32 registers contain values owned by the interrupted code. But <code>uservec</code> needs to be able to modify some registers in order to set <code>satp</code> and generate addresses at which to save the registers. RISC-V provides a helping hand in the form of the <code>sscratch</code> register. The <code>csrrw</code> instruction at the start of <code>uservec</code> swaps the contents of a0 and <code>sscratch</code>. Now the user code\u2019s a0 is saved; <code>uservec</code> has one register (a0) to play with; and a0 contains the value the kernel previously placed in <code>sscratch</code>.</p> <p>\u4e0a\u9762\u8bb2\u7684\u662f\u5f53\u7528\u6237\u6001\u7a0b\u5e8f\u89e6\u53d1\u4e2d\u65ad\u65f6\uff0c\u5f53\u524d\u768432\u4e2a\u5bc4\u5b58\u5668\u90fd\u88ab\u7528\u6237\u5360\u6709\uff0c\u6240\u4ee5\u4e00\u5f00\u59cb\u7528\u4e86<code>sscratch</code>\u5bc4\u5b58\u5668\u5148\u5c06<code>a0</code>\u4fdd\u5b58\u4e0b\u6765\uff0c\u8ba9<code>a0</code>\u6307\u5411<code>trapframe</code>\uff0c\u8fd9\u6837\u5c31\u53ef\u4ee5\u628a\u5f53\u524d\u7528\u6237\u6001\u6240\u5360\u6709\u7684\u6240\u6709\u5bc4\u5b58\u5668\u4f9d\u6b21\u4fdd\u5b58\u4e0b\u6765\u3002</p> <p><code>uservec</code>\u2019s next task is to save the user registers. Before entering user space, the kernel previously set <code>sscratch</code> to point to a per-process <code>trapframe</code> that (among other things) has space to save all the user registers (kernel/proc.h:44). Because <code>satp</code> still refers to the user page table, <code>uservec</code> needs the <code>trapframe</code> to be mapped in the user address space. When creating each process, xv6 allocates a page for the process\u2019s <code>trapframe</code>, and arranges for it always to be mapped at user virtual address TRAPFRAME, which is just below TRAMPOLINE. The process\u2019s <code>p-&gt;trapframe</code> also points to the <code>trapframe</code>, though at its physical address so the kernel can use it through the kernel page table.</p> <p><code>sscratch</code>\u5728\u5185\u6838\u6001\u4e2d\u9884\u5148\u88ab\u8bbe\u7f6e\u7684\u5e94\u8be5\u662f\u7528\u6237\u6001\u4e0b<code>trapframe</code>\u7684\u7edf\u4e00\u865a\u62df\u5730\u5740\uff0c\u6bcf\u4e2aprocess\u5185\u90e8\u5b58\u50a8\u4e86\u4e00\u4e2a\u4ed6\u6240\u62e5\u6709\u7684<code>trapframe</code>\u7684\u7269\u7406\u5730\u5740\u3002\u5f53\u7136\uff0c\u8fd9\u4e2a\u7269\u7406\u5730\u5740\u548c\u7edf\u4e00\u865a\u62df\u5730\u5740\u7684\u6620\u5c04\u88ab\u8bb0\u5f55\u5728process\u7684\u7528\u6237\u9875\u8868\u4e4b\u4e2d\u3002</p> <pre><code>static struct proc*\nallocproc(void)\n{\n  struct proc *p;\n\n ................................\n\nfound:\n  p-&gt;pid = allocpid();\n\n  // Allocate a trapframe page.\n  if((p-&gt;trapframe = (struct trapframe *)kalloc()) == 0){\n    release(&amp;p-&gt;lock);\n    return 0;\n  }\n</code></pre> <p></p> <p>Thus after swapping a0 and <code>sscratch</code>, a0 holds a pointer to the current process\u2019s <code>trapframe</code>. <code>uservec</code> now saves all user registers there, including the user\u2019s a0, read from <code>sscratch</code>. The <code>trapframe</code> contains pointers to the current process\u2019s kernel stack, the current CPU\u2019s <code>hartid</code>, the address of <code>usertrap</code>, and the address of the kernel page table. <code>uservec</code> retrieves these values, switches <code>satp</code> to the kernel page table, and calls <code>usertrap</code>\u3002</p> <pre><code>struct trapframe {\n  /*   0 */ uint64 kernel_satp;   // kernel page table\n  /*   8 */ uint64 kernel_sp;     // top of process's kernel stack\n  /*  16 */ uint64 kernel_trap;   // usertrap()\n  /*  24 */ uint64 epc;           // saved user program counter\n  /*  32 */ uint64 kernel_hartid; // saved kernel tp\n    ...............\n}\n</code></pre> <pre><code>uservec:\n    #\n        # trap.c sets stvec to point here, so\n        # traps from user space start here,\n        # in supervisor mode, but with a\n        # user page table.\n        #\n        # sscratch points to where the process's p-&gt;trapframe is\n        # mapped into user space, at TRAPFRAME.\n        #\n\n    # swap a0 and sscratch\n        # so that a0 is TRAPFRAME\n        csrrw a0, sscratch, a0\n\n        # save the user registers in TRAPFRAME\n        sd ra, 40(a0)\n        sd sp, 48(a0)\n        sd gp, 56(a0)\n        sd tp, 64(a0)\n        sd t0, 72(a0)\n        sd t1, 80(a0)\n        .\n        .\n        .\n        # save the user a0 in p-&gt;trapframe-&gt;a0\n        csrr t0, sscratch\n        sd t0, 112(a0)\n\n        # restore kernel stack pointer from p-&gt;trapframe-&gt;kernel_sp\n        ld sp, 8(a0)\n\n        # make tp hold the current hartid, from p-&gt;trapframe-&gt;kernel_hartid\n        ld tp, 32(a0)\n\n        # load the address of usertrap(), p-&gt;trapframe-&gt;kernel_trap\n        ld t0, 16(a0)\n\n        # restore kernel page table from p-&gt;trapframe-&gt;kernel_satp\n        ld t1, 0(a0)\n        csrw satp, t1\n        sfence.vma zero, zero\n\n        # a0 is no longer valid, since the kernel page\n        # table does not specially map p-&gt;tf.\n\n        # jump to usertrap(), which does not return\n        jr t0\n</code></pre> <p>\u4fdd\u5b58\u5b8c\u4e86\u7528\u6237\u6001\u5360\u6709\u7684\u6240\u6709\u5bc4\u5b58\u5668\uff0c<code>uservec</code>\u6700\u540e\u901a\u8fc7<code>a0</code>\uff08\u6b64\u65f6\u6307\u5411\u7684\u662f<code>trapframe</code>\uff09,\u5c06\u5176\u4e2d\u7684\u91cd\u8981\u6570\u636e\u4f9d\u6b21\u53d6\u51fa\u5e76\u8986\u76d6\u76f8\u5e94\u7684\u5bc4\u5b58\u5668\uff0c\u5207\u6362\u5230\u5185\u6838\u9875\u8868\uff0c\u6b64\u65f6\uff0ctrap handler\u4ee3\u7801\u7684\u8fd0\u884c\u73af\u5883\u5c31\u5df2\u7ecf\u51c6\u5907\u597d\u4e86\u3002\u63a5\u4e0b\u6765\uff0cpc\u6307\u5411<code>usertrap()</code>.</p> <p>The job of <code>usertrap</code> is to determine the cause of the trap, process it, and return (kernel/- trap.c:37).</p> <p>As mentioned above, it first changes <code>stvec</code> so that a trap while in the kernel will be handled by <code>kernelvec</code>. It saves the <code>sepc</code> (the saved user program counter), again because there might be a process switch in <code>usertrap</code> that could cause <code>sepc</code> to be overwritten.</p> <p>If the trap is a system call, <code>syscall</code> handles it;</p> <p>if a device interrupt, <code>devintr</code>;</p> <p>otherwise it\u2019s an exception, and the kernel kills the faulting process.</p> <p>The system call path adds four to the saved user pc because RISC-V, in the case of a system call, leaves the program pointer pointing to the <code>ecall</code> instruction. On the way out, <code>usertrap</code> checks if the process has been killed or should yield the CPU (if this trap is a timer interrupt).</p> <pre><code>//\n// handle an interrupt, exception, or system call from user space.\n// called from trampoline.S\n//\nvoid\nusertrap(void)\n{\n  int which_dev = 0;\n\n  if((r_sstatus() &amp; SSTATUS_SPP) != 0)\n    panic(\"usertrap: not from user mode\");\n\n  // send interrupts and exceptions to kerneltrap(),\n  // since we're now in the kernel.\n  w_stvec((uint64)kernelvec);\n\n  struct proc *p = myproc();\n\n  // save user program counter.\n  p-&gt;trapframe-&gt;epc = r_sepc();\n\n  if(r_scause() == 8){\n    // system call\n\n    if(p-&gt;killed)\n      exit(-1);\n\n    // sepc points to the ecall instruction,\n    // but we want to return to the next instruction.\n    p-&gt;trapframe-&gt;epc += 4;\n\n    // an interrupt will change sstatus &amp;c registers,\n    // so don't enable until done with those registers.\n    intr_on();\n\n    syscall();\n  } else if((which_dev = devintr()) != 0){\n    // ok\n  } else {\n    printf(\"usertrap(): unexpected scause %p pid=%d\\n\", r_scause(), p-&gt;pid);\n    printf(\"            sepc=%p stval=%p\\n\", r_sepc(), r_stval());\n    p-&gt;killed = 1;\n  }\n\n  if(p-&gt;killed)\n    exit(-1);\n\n  // give up the CPU if this is a timer interrupt.\n  if(which_dev == 2)\n    yield();\n\n  usertrapret();\n}\n</code></pre> <p>\u8fd9\u4e00\u90e8\u5206\u5c31\u662f\u5185\u6838\u6001\u5982\u4f55\u5904\u7406trap\u7684\u4ee3\u7801\u4e86\uff0c\u8fd9\u91cc\u5b58\u6709\u4e00\u4e2a\u6ca1\u6709\u7406\u89e3\u7684\u5730\u65b9\uff1a\u4e3a\u4ec0\u4e48pc\u8981\u52a04\uff1f(\u56e0\u4e3a<code>ecall</code>\u7684\u673a\u5668\u6307\u4ee4\u662f4\u5b57\u8282\uff0c\u52a04\u5c31\u4f1a\u8df3\u5230<code>ecall</code>\u7684\u4e0b\u4e00\u4e2a\u6307\u4ee4\u53bb)</p> <p>\u63a5\u4e0b\u6765\u5f53trap\u5904\u7406\u5b8c\u6bd5\uff0c\u5c31\u8981\u7740\u624b\u56de\u5230\u7528\u6237\u6001\u4e86\u3002</p> <p>The first step in returning to user space is the call to <code>usertrapret</code> (kernel/trap.c:90). This function sets up the RISC-V control registers to prepare for a future trap from user space.</p> <p>This involves changing <code>stvec</code> to refer to <code>uservec</code>,</p> <p>preparing the <code>trapframe</code> fields that <code>uservec</code> relies on, and</p> <p>setting <code>sepc</code> to the previously saved user program counter. At the end,</p> <p><code>usertrapret</code> calls <code>userret</code> on the trampoline page that is mapped in both user and kernel page tables; the reason is that assembly code in <code>userret</code> will switch page tables.</p> <p><code>stvec</code>\u4fdd\u5b58\u7740\u89e3\u51b3trap\u7684\u4ee3\u7801\u4f4d\u7f6e\uff0c\u6b64\u65f6\u5c06\u4ed6\u6062\u590d\u5230<code>uservec</code>, \u4e3a\u4e0b\u4e00\u6b21\u7528\u6237\u6001\u4e2d\u65ad\u505a\u597d\u51c6\u5907</p> <p>\u6062\u590d<code>trapframe</code>\u4fdd\u5b58\u7684\u4e0ekernel\u76f8\u5173\u7684\u7279\u6b8a\u6570\u636e\uff0c\u8fd9\u4e9b\u6570\u636e\u5728\u5904\u7406\u4e2d\u65ad\u7684\u8fc7\u7a0b\u4e2d(\u5207\u6362\u5185\u6838\u9875\u8868\uff0c\u5185\u6838\u6808\u7b49)\u90fd\u88ab<code>trampoline.S</code>\u7528\u5230\u3002</p> <pre><code>//\n// return to user space\n//\nvoid\nusertrapret(void)\n{\n  struct proc *p = myproc();\n\n  // we're about to switch the destination of traps from\n  // kerneltrap() to usertrap(), so turn off interrupts until\n  // we're back in user space, where usertrap() is correct.\n  intr_off();\n\n  // send syscalls, interrupts, and exceptions to trampoline.S\n  w_stvec(TRAMPOLINE + (uservec - trampoline));\n\n  // set up trapframe values that uservec will need when\n  // the process next re-enters the kernel.\n  p-&gt;trapframe-&gt;kernel_satp = r_satp();         // kernel page table\n  p-&gt;trapframe-&gt;kernel_sp = p-&gt;kstack + PGSIZE; // process's kernel stack\n  p-&gt;trapframe-&gt;kernel_trap = (uint64)usertrap;\n  p-&gt;trapframe-&gt;kernel_hartid = r_tp();         // hartid for cpuid()\n\n  // set up the registers that trampoline.S's sret will use\n  // to get to user space.\n\n  // set S Previous Privilege mode to User.\n  unsigned long x = r_sstatus();\n  x &amp;= ~SSTATUS_SPP; // clear SPP to 0 for user mode\n  x |= SSTATUS_SPIE; // enable interrupts in user mode\n  w_sstatus(x);\n\n  // set S Exception Program Counter to the saved user pc.\n  w_sepc(p-&gt;trapframe-&gt;epc);\n\n  // tell trampoline.S the user page table to switch to.\n  uint64 satp = MAKE_SATP(p-&gt;pagetable);\n\n  // jump to trampoline.S at the top of memory, which\n  // switches to the user page table, restores user registers,\n  // and switches to user mode with sret.\n  uint64 fn = TRAMPOLINE + (userret - trampoline);\n  ((void (*)(uint64,uint64))fn)(TRAPFRAME, satp);\n}\n</code></pre> <p><code>usertrapret</code>\u2019s call to <code>userret</code> passes a pointer to the process\u2019s user page table in <code>a0</code> and TRAPFRAME in <code>a1</code> (kernel/trampoline.S:88).</p> <p><code>userret</code> switches <code>satp</code> to the process\u2019s user page table. Recall that the user page table maps both the trampoline page and TRAPFRAME, but nothing else from the kernel. Again, the fact that the trampoline page is mapped at the same virtual address in user and kernel page tables is what allows <code>uservec</code> to keep executing after changing <code>satp</code>.</p> <p><code>userret</code> copies the <code>trapframe</code>\u2019s saved user a0 to <code>sscratch</code> in preparation for a later swap with TRAPFRAME. From this point on, the only data <code>userret</code> can use is the register contents and the content of the <code>trapframe</code>. Next <code>userret</code> restores saved user registers from the <code>trapframe</code>, does a final swap of a0 and <code>sscratch</code> to restore the user a0 and save TRAPFRAME for the next trap, and uses <code>sret</code> to return to user space.</p> <p>\u8fd9\u91cc\u6211\u4eec\u5c31\u53c8\u56de\u5230\u4e86TRAMPOLINE.S\u6c47\u7f16\u4ee3\u7801\u90e8\u5206\u4e86\uff0c\u8fd9\u91cc\u603b\u7ed3\u4e00\u4e0b4.2\u8282\u7684\u6574\u4e2a\u8c03\u7528\u8fc7\u7a0b</p> <p>\u5f53trap\u53d1\u751f\u540e\uff0cCPU\u4f1a\u5c06pc\u6307\u5411<code>trampoline.S</code>\u7684<code>uservec</code>\u90e8\u5206, \u63a5\u7740</p> <p><code>uservec</code> -&gt; <code>usertrap</code> -&gt; <code>usertrapret</code> -&gt; <code>userret</code></p> <p><code>userret</code>\u4e3b\u8981\u505a\u7684\u4e8b\u5c31\u662f\u5c06\u9875\u8868\u5207\u6362\u4e3a\u7528\u6237\u9875\u8868\uff0c\u6062\u590d\u4e4b\u524d\u4fdd\u5b58\u7684\u7528\u6237\u6001\u5bc4\u5b58\u5668\u7684\u503c\uff0c\u6062\u590d\u7528\u6237\u6001\u7684\u8fd0\u884c\u73af\u5883\u3002\u8fd9\u91cc\u8fb9\u9700\u8981\u8bf4\u660e\u7684\u662f\uff0c\u6b64\u65f6<code>p-&gt;trapframe-&gt;a0</code>\u5b58\u50a8\u7740trap handler\u8fd0\u884c\u540e\u7684\u8fd4\u56de\u503c\uff0c\u6240\u4ee5\u5148\u7528<code>sscrach</code>\u5c06\u5176\u4fdd\u5b58\uff0c\u7136\u540e<code>a0</code>\u7ee7\u7eed\u5145\u5f53TRAPFRAME\u6765\u9010\u4e00\u6062\u590d\u7528\u6237\u6001trap\u524d\u7684\u5bc4\u5b58\u5668\u503c\u3002\u6700\u540e\u518d\u5c06trap\u540e\u7684\u8fd4\u56de\u503c\u7ed9<code>a0</code>\u3002</p> <pre><code>.globl userret\nuserret:\n        # userret(TRAPFRAME, pagetable)\n        # switch from kernel to user.\n        # usertrapret() calls here.\n        # a0: TRAPFRAME, in user page table.\n        # a1: user page table, for satp.\n\n        # switch to the user page table.\n        csrw satp, a1\n        sfence.vma zero, zero\n\n        # put the saved user a0 in sscratch, so we\n        # can swap it with our a0 (TRAPFRAME) in the last step.\n        ld t0, 112(a0)\n        csrw sscratch, t0\n\n        # restore all but a0 from TRAPFRAME\n        ld ra, 40(a0)\n        ld sp, 48(a0)\n        ld gp, 56(a0)\n        ld tp, 64(a0)\n        ld t0, 72(a0)\n    ...................................\n\n    # restore user a0, and save TRAPFRAME in sscratch\n        csrrw a0, sscratch, a0\n\n        # return to user mode and user pc.\n        # usertrapret() set up sstatus and sepc.\n        sret\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#43-code-calling-system-calls","title":"4.3 Code: Calling system calls","text":"<p>Chapter 2 ended with <code>initcode.S</code> invoking the exec system call (user/initcode.S:11).</p> <pre><code>##include \"syscall.h\"\n\n## exec(init, argv)\n.globl start\nstart:\n        la a0, init\n        la a1, argv\n        li a7, SYS_exec\n        ecall\n\n## for(;;) exit();\nexit:\n        li a7, SYS_exit\n        ecall\n        jal exit\n\n## char init[] = \"/init\\0\";\ninit:\n  .string \"/init\\0\"\n\n## char *argv[] = { init, 0 };\n.p2align 2\nargv:\n  .long init\n  .long 0\n</code></pre> <p>Let\u2019s look at how the user call makes its way to the exec system call\u2019s implementation in the kernel. The user code places the arguments for exec in registers <code>a0</code> and <code>a1</code>, and puts the system call number in <code>a7</code>.</p> <p>System call numbers match the entries in the <code>syscalls</code> array, a table of function pointers (kernel/syscall.c:108).</p> <pre><code>static uint64 (*syscalls[])(void) = {\n[SYS_fork]    sys_fork,\n[SYS_exit]    sys_exit,\n[SYS_wait]    sys_wait,\n[SYS_pipe]    sys_pipe,\n[SYS_read]    sys_read,\n[SYS_kill]    sys_kill,\n[SYS_exec]    sys_exec,\n..........................\n};\n</code></pre> <p>The <code>ecall</code> instruction traps into the kernel and executes <code>uservec</code>, <code>usertrap</code>, and then <code>syscall</code>, as we saw above. <code>syscall</code>(kernel/syscall.c:133) retrieves the system call number from the saved a7 in the <code>trapframe</code> and uses it to index into <code>syscalls</code>.</p> <pre><code>void\nsyscall(void)\n{\n  int num;\n  struct proc *p = myproc();\n\n  num = p-&gt;trapframe-&gt;a7;\n  if(num &gt; 0 &amp;&amp; num &lt; NELEM(syscalls) &amp;&amp; syscalls[num]) {\n    p-&gt;trapframe-&gt;a0 = syscalls[num]();\n  } else {\n    printf(\"%d %s: unknown sys call %d\\n\",\n            p-&gt;pid, p-&gt;name, num);\n    p-&gt;trapframe-&gt;a0 = -1;\n  }\n}\n</code></pre> <p>For the first system call, a7 contains SYS_exec (kernel/syscall.h:8), resulting in a call to the system call implementation function sys_exec. When the system call implementation function returns, <code>syscall</code> records its return value in <code>p-&gt;trapframe-&gt;a0</code>. This will cause the original user-space call to exec() to return that value, since the C calling convention on RISC-V places return values in a0. System calls conventionally return negative numbers to indicate errors, and zero or positive numbers for success. If the system call number is invalid, <code>syscall</code> prints an error and returns \u22121.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#44-code-system-call-arguments","title":"4.4 Code: System call arguments","text":"<p>\u7cfb\u7edf\u8c03\u7528\u7684\u53c2\u6570\u5728\u54ea\u91cc\u5462\uff1f\u5f53\u7136\u662f\u5b58\u5728\u5bc4\u5b58\u5668\u91cc\uff0c\u7136\u800c\uff0c\u5728\u6211\u4eec\u8fdb\u5165trap handler\u4e4b\u524d\uff0c\u6211\u4eec\u7528<code>trapframe</code>\u4fdd\u5b58\u4e86\u6240\u6709\u7684\u7528\u6237\u6001\u7684\u5bc4\u5b58\u5668\uff0c\u4ece\u800c\uff0c\u7cfb\u7edf\u8c03\u7528\u51fd\u6570\u9700\u8981\u5728<code>p-&gt;trapframe</code>\u4e2d\u83b7\u53d6\u81ea\u5df1\u9700\u8981\u7684\u53c2\u6570\u3002</p> <p>System call implementations in the kernel need to find the arguments passed by user code. Because user code calls system call wrapper functions, the arguments are initially where the RISC-V C calling convention places them: in registers. The kernel trap code saves user registers to the current process\u2019s trap frame, where kernel code can find them. The functions <code>argint</code>, <code>argaddr</code>, and <code>argfd</code> retrieve the <code>n\u2019th</code> system call argument from the trap frame as an integer, pointer, or a file descriptor. They all call <code>argraw</code> to retrieve the appropriate saved user register (kernel/syscall.c:35)</p> <pre><code>static uint64\nargraw(int n)\n{\n  struct proc *p = myproc();\n  switch (n) {\n  case 0:\n    return p-&gt;trapframe-&gt;a0;\n  case 1:\n    return p-&gt;trapframe-&gt;a1;\n  case 2:\n    return p-&gt;trapframe-&gt;a2;\n  case 3:\n    return p-&gt;trapframe-&gt;a3;\n  case 4:\n    return p-&gt;trapframe-&gt;a4;\n  case 5:\n    return p-&gt;trapframe-&gt;a5;\n  }\n  panic(\"argraw\");\n  return -1;\n}\n\n// Fetch the nth 32-bit system call argument.\nint\nargint(int n, int *ip)\n{\n  *ip = argraw(n);\n  return 0;\n}\n\n// Retrieve an argument as a pointer.\n// Doesn't check for legality, since\n// copyin/copyout will do that.\nint\nargaddr(int n, uint64 *ip)\n{\n  *ip = argraw(n);\n  return 0;\n}\n</code></pre> <p>\u6211\u4eec\u5728\u4f7f\u7528\u547d\u4ee4\u884c\u65f6\uff0c\u5411<code>exec()</code>\u7cfb\u7edf\u8c03\u7528\u8f93\u5165\u7684\u662f\u4e00\u7ec4\u6307\u5411\u5b57\u7b26\u4e32\u7684\u6307\u9488\u3002\u8fd9\u91cc\u6700\u6838\u5fc3\u7684\u96be\u70b9\u5c31\u662f\u7528\u6237\u6001\u7684\u6307\u9488\u5730\u5740\u53ea\u80fd\u88ab\u7528\u6237\u9875\u8868\u89e3\u6790\uff0c\u5982\u4f55\u8ba9\u5185\u6838\u9875\u8868\u77e5\u9053\u8fd9\u4e2a\u6307\u9488\u6307\u5411\u54ea\u4e00\u5757\u7269\u7406\u5185\u5b58\u5462\uff1f</p> <p>\u9875\u8868\u7ae0\u8282\u7684\u5b9e\u9a8c\u505a\u5230\u4e86\u8fd9\u4e00\u70b9\uff0c\u6bcf\u4e2a\u8fdb\u7a0b\u90fd\u62e5\u6709\u4e00\u5f20\u5185\u6838\u9875\u8868\u548c\u4e00\u5f20\u7528\u6237\u9875\u8868\uff0c\u7528\u6237\u9875\u8868\u7684\u6620\u5c04\u4f1a\u540c\u65f6\u5b58\u50a8\u5728\u5185\u6838\u9875\u8868\u4e0a\uff0c\u4ece\u800c\u7528\u6237\u4f20\u6765\u7684\u6307\u9488\u53ef\u4ee5\u76f4\u63a5\u88ab\u5185\u6838\u6001\u4f7f\u7528\u3002</p> <p>Some system calls pass pointers as arguments, and the kernel must use those pointers to read or write user memory. The <code>exec</code>system call, for example, passes the kernel an array of pointers referring to string arguments in user space. These pointers pose two challenges.</p> <p>First, the user program may be buggy or malicious, and may pass the kernel an invalid pointer or a pointer intended to trick the kernel into accessing kernel memory instead of user memory. Second, the xv6 kernel page table mappings are not the same as the user page table mappings, so the kernel cannot use ordinary instructions to load or store from user-supplied addresses.</p> <p>The kernel implements functions that safely transfer data to and from user-supplied addresses. <code>fetchstr</code> is an example (kernel/syscall.c:25). File system calls such as exec use <code>fetchstr</code> to retrieve string file-name arguments from user space. <code>fetchstr</code> calls <code>copyinstr</code> to do the hard work.</p> <pre><code>// Fetch the nul-terminated string at addr from the current process.\n// Returns length of string, not including nul, or -1 for error.\nint\nfetchstr(uint64 addr, char *buf, int max)\n{\n  struct proc *p = myproc();\n  int err = copyinstr(p-&gt;pagetable, buf, addr, max);\n  if(err &lt; 0)\n    return err;\n  return strlen(buf);\n}\n</code></pre> <p>\u8fd9\u91cc\u6211\u4eec\u9762\u5bf9\u7684\u662f\u4e00\u4e2a\u6bcf\u4e2a\u8fdb\u7a0b\u5171\u4eab\u5185\u6838\u9875\u8868\u7684\u64cd\u4f5c\u7cfb\u7edf\uff0c\u8fd9\u91cc\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\u7684\u65b9\u6cd5\u5c31\u662f\u4f9d\u9760\u4ee3\u7801\u800c\u4e0d\u662fCPU\u7684\u7269\u7406\u673a\u5236\u53bb\u627e\u5230\u7528\u6237\u5730\u5740\u6240\u5bf9\u5e94\u7684\u7269\u7406\u5730\u5740\u3002</p> <p><code>copyinstr</code> (kernel/vm.c:406) copies up to max bytes to <code>dst</code> from virtual address <code>srcva</code> in the user page table <code>pagetable</code>. It uses <code>walkaddr</code> (which calls walk) to walk the page table in software to determine the physical address pa0 for <code>srcva</code>. Since the kernel maps all physical RAM addresses to the same kernel virtual address, <code>copyinstr</code> can directly copy string bytes from <code>pa0</code> to <code>dst</code>. <code>walkaddr</code> (kernel/vm.c:95) checks that the user-supplied virtual address is part of the process\u2019s user address space, so programs cannot trick the kernel into reading other memory. A similar function, <code>copyout</code>, copies data from the kernel to a user-supplied address.</p> <pre><code>// Copy a null-terminated string from user to kernel.\n// Copy bytes to dst from virtual address srcva in a given page table,\n// until a '\\0', or max.\n// Return 0 on success, -1 on error.\nint\ncopyinstr(pagetable_t pagetable, char *dst, uint64 srcva, uint64 max)\n{\n  uint64 n, va0, pa0;\n  int got_null = 0;\n\n  while(got_null == 0 &amp;&amp; max &gt; 0){\n    va0 = PGROUNDDOWN(srcva);\n    pa0 = walkaddr(pagetable, va0);\n    if(pa0 == 0)\n      return -1;\n    n = PGSIZE - (srcva - va0);\n    if(n &gt; max)\n      n = max;\n\n    char *p = (char *) (pa0 + (srcva - va0));\n    while(n &gt; 0){\n      if(*p == '\\0'){\n        *dst = '\\0';\n        got_null = 1;\n        break;\n      } else {\n        *dst = *p;\n      }\n      --n;\n      --max;\n      p++;\n      dst++;\n    }\n\n    srcva = va0 + PGSIZE;\n  }\n  if(got_null){\n    return 0;\n  } else {\n    return -1;\n  }\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#45-traps-from-kernel-space","title":"4.5 Traps from kernel space","text":"<p>Xv6 configures the CPU trap registers somewhat differently depending on whether user or kernel code is executing. When the kernel is executing on a CPU, the kernel points <code>stvec</code> to the assembly code at <code>kernelvec</code> (kernel/kernelvec.S:10). Since xv6 is already in the kernel, <code>kernelvec</code> can rely on <code>satp</code> being set to the kernel page table, and on the stack pointer referring to a valid kernel stack. <code>kernelvec</code> saves all registers so that the interrupted code can eventually resume without disturbance.</p> <p><code>kernelvec</code> saves the registers on the stack of the interrupted kernel thread, which makes sense because the register values belong to that thread. This is particularly important if the trap causes a switch to a different thread \u2013 in that case the trap will actually return on the stack of the new thread, leaving the interrupted thread\u2019s saved registers safely on its stack.</p> <pre><code>    #\n        # interrupts and exceptions while in supervisor\n        # mode come here.\n        #\n        # push all registers, call kerneltrap(), restore, return.\n        #\n.globl kerneltrap\n.globl kernelvec\n.align 4\nkernelvec:\n        // make room to save registers.\n        addi sp, sp, -256\n\n        // save the registers.\n        sd ra, 0(sp)\n        sd sp, 8(sp)\n        sd gp, 16(sp)\n        sd tp, 24(sp)\n        sd t0, 32(sp)\n        sd t1, 40(sp)\n      ....................................\n\n    // call the C trap handler in trap.c\n        call kerneltrap\n</code></pre> <p><code>kernelvec</code> jumps to <code>kerneltrap</code> (kernel/trap.c:134) after saving registers. <code>kerneltrap</code> is prepared for two types of traps: <code>device interrupts</code> and <code>exceptions</code>. It calls <code>devintr</code> (kernel/- trap.c:177) to check for and handle the former. If the trap isn\u2019t a device interrupt, it must be an exception, and that is always a fatal error if it occurs in the xv6 kernel; the kernel calls panic and stops executing.</p> <pre><code>// interrupts and exceptions from kernel code go here via kernelvec,\n// on whatever the current kernel stack is.\nvoid\nkerneltrap()\n{\n  int which_dev = 0;\n  uint64 sepc = r_sepc();\n  uint64 sstatus = r_sstatus();\n  uint64 scause = r_scause();\n\n  if((sstatus &amp; SSTATUS_SPP) == 0)\n    panic(\"kerneltrap: not from supervisor mode\");\n  if(intr_get() != 0)\n    panic(\"kerneltrap: interrupts enabled\");\n\n  if((which_dev = devintr()) == 0){\n    printf(\"scause %p\\n\", scause);\n    printf(\"sepc=%p stval=%p\\n\", r_sepc(), r_stval());\n    panic(\"kerneltrap\");\n  }\n\n  // give up the CPU if this is a timer interrupt.\n  if(which_dev == 2 &amp;&amp; myproc() != 0 &amp;&amp; myproc()-&gt;state == RUNNING)\n    yield();\n\n  // the yield() may have caused some traps to occur,\n  // so restore trap registers for use by kernelvec.S's sepc instruction.\n  w_sepc(sepc);\n  w_sstatus(sstatus);\n}\n</code></pre> <p>\u8fd9\u91cc\u8ba8\u8bba\u4e86\u7ebf\u7a0b\u548ctrap\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u9700\u8981\u5728\u5b66\u5b8c\u7b2c\u4e03\u7ae0\u540e\u6765\u8fd9\u91cc\u8865\u5145</p> <p>If <code>kerneltrap</code> was called due to a timer interrupt, and a process\u2019s kernel thread is running (rather than a scheduler thread), <code>kerneltrap</code> calls yield to give other threads a chance to run. At some point one of those threads will yield, and let our thread and its <code>kerneltrap</code> resume again. Chapter 7 explains what happens in yield.</p> <p>When <code>kerneltrap</code>\u2019s work is done, it needs to return to whatever code was interrupted by the trap. Because a yield may have disturbed the saved <code>sepc</code> and the saved previous mode in <code>sstatus</code>, <code>kerneltrap</code> saves them when it starts. It now restores those control registers and returns to <code>kernelvec</code> (kernel/kernelvec.S:48). <code>kernelvec</code> pops the saved registers from the stack and executes <code>sret</code>, which copies <code>sepc</code> to pc and resumes the interrupted kernel code.</p> <p>It\u2019s worth thinking through how the trap return happens if <code>kerneltrap</code> called yield due to a timer interrupt.</p> <pre><code>// call the C trap handler in trap.c\n        call kerneltrap\n\n        // restore registers.\n        ld ra, 0(sp)\n        ld sp, 8(sp)\n        ld gp, 16(sp)\n        // not this, in case we moved CPUs: ld tp, 24(sp)\n        ld t0, 32(sp)\n        ld t1, 40(sp)\n        ld t2, 48(sp)\n        ld s0, 56(sp)\n        ld s1, 64(sp)\n       ..........................................\n\n        addi sp, sp, 256\n\n        // return to whatever we were doing in the kernel.\n        sret\n</code></pre> <p>Xv6 sets a CPU\u2019s <code>stvec</code> to <code>kernelvec</code> when that CPU enters the kernel from user space; you can see this in <code>usertrap</code> (kernel/trap.c:29). There\u2019s a window of time when the kernel is executing but <code>stvec</code> is set to <code>uservec</code>, and it\u2019s crucial that device interrupts be disabled during that window. Luckily the RISC-V always disables interrupts when it starts to take a trap, and xv6 doesn\u2019t enable them again until after it sets <code>stvec</code>.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#46-page-fault-exceptions","title":"4.6 Page-fault exceptions","text":"<p>Xv6\u2019s response to exceptions is quite boring: if an exception happens in user space, the kernel kills the faulting process. If an exception happens in the kernel, the kernel panics. Real operating systems often respond in much more interesting ways.</p> <p>As an example, many kernels use page faults to implement <code>copy-on-write (COW) fork</code>. To explain copy-on-write fork, consider xv6\u2019s fork, described in Chapter 3. fork causes the child to have the same memory content as the parent, by calling <code>uvmcopy</code> (kernel/vm.c:309) to allocate physical memory for the child and copy the parent\u2019s memory into it. It would be more efficient if the child and parent could share the parent\u2019s physical memory. A straightforward implementation of this would not work, however, since it would cause the parent and child to disrupt each other\u2019s execution with their writes to the shared stack and heap.</p> <p>Parent and child can safely share <code>phyical</code> memory using copy-on-write fork, driven by page faults. When a CPU cannot translate a virtual address to a physical address, the CPU generates a page-fault exception. RISC-V has three different kinds of page fault: <code>load page faults</code> (when a load instruction cannot translate its virtual address), <code>store page faults</code> (when a store instruction cannot translate its virtual address), and <code>instruction page faults</code> (when the address for an instruction doesn\u2019t translate). The value in the <code>scause</code> register indicates the type of the page fault and the <code>stval</code> register contains the address that couldn\u2019t be translated.</p> <p>The basic plan in COW fork is for the parent and child to initially share all physical pages, but to map them read-only. Thus, when the child or parent executes a store instruction, the RISC-V CPU raises a page-fault exception. In response to this exception, the kernel makes a copy of the page that contains the faulted address. It maps one copy read/write in the child\u2019s address space and the other copy read/write in the parent\u2019s address space. After updating the page tables, the kernel resumes the faulting process at the instruction that caused the fault. Because the kernel has updated the relevant PTE to allow writes, the faulting instruction will now execute without a fault.</p> <p>This COW plan works well for fork, because often the child calls <code>exec</code> immediately after the fork, replacing its address space with a new address space. In that common case, the child will experience only a few page faults, and the kernel can avoid making a complete copy. Furthermore, COW fork is transparent: no modifications to applications are necessary for them to benefit.</p> <p>The combination of page tables and page faults opens up a wide-range of interesting possibilities other than COW fork. Another widely-used feature is called <code>lazy allocation</code>, which has two parts. First, when an application calls <code>sbrk</code>, the kernel grows the address space, but marks the new addresses as not valid in the page table. Second, on a page fault on one of those new addresses, the kernel allocates physical memory and maps it into the page table. Since applications often ask for more memory than they need, lazy allocation is a win: the kernel allocates memory only when the application actually uses it. Like COW fork, the kernel can implement this feature transparently to applications.</p> <p>Yet another widely-used feature that exploits page faults is <code>paging from disk</code>. If applications need more memory than the available physical RAM, the kernel can evict some pages: write them to a storage device such as a disk and mark their PTEs as not valid. If an application reads or writes an evicted page, the CPU will experience a page fault. The kernel can then inspect the faulting address. If the address belongs to a page that is on disk, the kernel allocates a page of physical memory, reads the page from disk to that memory, updates the PTE to be valid and refer to that memory, and resumes the application. To make room for the page, the kernel may have to evict another page. This feature requires no changes to applications, and works well if applications have locality of reference (i.e., they use only a subset of their memory at any given time).</p> <p>Other features that combine paging and page-fault exceptions include automatically extending stacks and memory-mapped files.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#chapter5-interrupts-and-device-drivers","title":"Chapter5. Interrupts and device drivers","text":"<p>A driver is the code in an operating system that manages a particular device: it configures the device hardware, tells the device to perform operations, handles the resulting interrupts, and interacts with processes that may be waiting for I/O from the device. Driver code can be tricky because a driver executes concurrently with the device that it manages. In addition, the driver must understand the device\u2019s hardware interface, which can be complex and poorly documented. Devices that need attention from the operating system can usually be configured to generate interrupts, which are one type of trap. The kernel trap handling code recognizes when a device has raised an interrupt and calls the driver\u2019s interrupt handler; in xv6, this dispatch happens in <code>devintr</code> (kernel/trap.c:177).</p> <p>Many device drivers execute code in two contexts: a top half that runs in a process\u2019s kernel thread, and a bottom half that executes at interrupt time.</p> <ul> <li> <p>The top half is called via system calls such as read and write that want the device to perform I/O. This code may ask the hardware to start an operation (e.g., ask the disk to read a block); then the code waits for the operation to complete. Eventually the device completes the operation and raises an interrupt.</p> </li> <li> <p>The driver\u2019s interrupt handler, acting as the bottom half, figures out what operation has completed, wakes up a waiting process if appropriate, and tells the hardware to start work on any waiting next operation.</p> </li> </ul> <pre><code>// check if it's an external interrupt or software interrupt,\n// and handle it.\n// returns 2 if timer interrupt,\n// 1 if other device,\n// 0 if not recognized.\nint\ndevintr()\n{\n  uint64 scause = r_scause();\n\n  if((scause &amp; 0x8000000000000000L) &amp;&amp;\n     (scause &amp; 0xff) == 9){\n    // this is a supervisor external interrupt, via PLIC.\n\n    // irq indicates which device interrupted.\n    int irq = plic_claim();\n\n    if(irq == UART0_IRQ){\n      uartintr();\n    } else if(irq == VIRTIO0_IRQ){\n      virtio_disk_intr();\n    } else if(irq){\n      printf(\"unexpected interrupt irq=%d\\n\", irq);\n    }\n\n    // the PLIC allows each device to raise at most one\n    // interrupt at a time; tell the PLIC the device is\n    // now allowed to interrupt again.\n    if(irq)\n      plic_complete(irq);\n\n    return 1;\n  } else if(scause == 0x8000000000000001L){\n    // software interrupt from a machine-mode timer interrupt,\n    // forwarded by timervec in kernelvec.S.\n\n    if(cpuid() == 0){\n      clockintr();\n    }\n\n    // acknowledge the software interrupt by clearing\n    // the SSIP bit in sip.\n    w_sip(r_sip() &amp; ~2);\n\n    return 2;\n  } else {\n    return 0;\n  }\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#51-code-console-input","title":"5.1 Code: Console input","text":"<p>The console driver (<code>console.c</code>) is a simple illustration of driver structure.</p> <p>The console driver accepts characters typed by a human, via the UART serial-port hardware attached to the RISC-V. The console driver accumulates a line of input at a time, processing special input characters such as backspace and control-u.</p> <p>User processes, such as the shell, use the read system call to fetch lines of input from the console. When you type input to xv6 in QEMU, your keystrokes are delivered to xv6 by way of QEMU\u2019s simulated UART hardware. The UART hardware that the driver talks to is a 16550 chip [11] emulated by QEMU. On a real computer, a 16550 would manage an RS232 serial link connecting to a terminal or other computer. When running QEMU, it\u2019s connected to your keyboard and display.</p> <p>The UART hardware appears to software as a set of memory-mapped control registers. That is, there are some physical addresses that RISC-V hardware connects to the UART device, so that loads and stores interact with the device hardware rather than RAM. The memory-mapped addresses for the UART start at 0x10000000, or UART0 (kernel/memlayout.h:21). There are a handful of UART control registers, each the width of a byte. Their offsets from UART0 are defined in (kernel/uart.c:22). For example, the LSR register contain bits that indicate whether input characters are waiting to be read by the software. These characters (if any) are available for reading from the RHR register. Each time one is read, the UART hardware deletes it from an internal FIFO of waiting characters, and clears the \u201cready\u201d bit in LSR when the FIFO is empty. The UART transmit hardware is largely independent of the receive hardware; if software writes a byte to the THR, the UART transmit that byte.</p> <pre><code>// the UART control registers.\n// some have different meanings for\n// read vs write.\n// see http://byterunner.com/16550.html\n##define RHR 0                 // receive holding register (for input bytes)\n##define THR 0                 // transmit holding register (for output bytes)\n##define IER 1                 // interrupt enable register\n##define IER_RX_ENABLE (1&lt;&lt;0)\n##define IER_TX_ENABLE (1&lt;&lt;1)\n##define FCR 2                 // FIFO control register\n##define FCR_FIFO_ENABLE (1&lt;&lt;0)\n##define FCR_FIFO_CLEAR (3&lt;&lt;1) // clear the content of the two FIFOs\n##define ISR 2                 // interrupt status register\n##define LCR 3                 // line control register\n##define LCR_EIGHT_BITS (3&lt;&lt;0)\n##define LCR_BAUD_LATCH (1&lt;&lt;7) // special mode to set baud rate\n##define LSR 5                 // line status register\n##define LSR_RX_READY (1&lt;&lt;0)   // input is waiting to be read from RHR\n##define LSR_TX_IDLE (1&lt;&lt;5)    // THR can accept another character to send\n</code></pre> <p>Xv6\u2019s main calls <code>consoleinit</code> (kernel/console.c:184) to initialize the UART hardware. This code configures the UART to</p> <ul> <li>generate a receive interrupt when the UART receives each byte of input, and</li> <li>a transmit complete interrupt each time the UART finishes sending a byte of output (kernel/uart.c:53).</li> </ul> <p>UART\u662fdevice\u548cconsole\u4e4b\u95f4\u4ea4\u4e92\u7684\u6865\u6881\uff0c\u8fd9\u91cc\u4e3b\u8981\u8bf4\u660e\u4e86UART\u548cdevice\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u6bcf\u5f53\u6211\u4eec\u4f7f\u7528keyboard\u6309\u4e0b\u4e00\u4e2a\u6309\u952e\u65f6\uff0cUART\u5c31\u4f1a\u89e6\u53d1\u4e00\u4e2a\u63a5\u6536\u4e2d\u65ad\uff1b\u6bcf\u5f53UART\u8fdb\u884c\u4e86\u4e00\u6b21\u4f20\u8f93\u65f6\uff0c\u5c31\u4f1a\u89e6\u53d1\u4e00\u6b21\u4f20\u8f93\u5b8c\u6210\u7684\u4e2d\u65ad\u3002</p> <pre><code>void\nconsoleinit(void)\n{\n  initlock(&amp;cons.lock, \"cons\");\n\n  uartinit();\n\n  // connect read and write system calls\n  // to consoleread and consolewrite.\n  devsw[CONSOLE].read = consoleread;\n  devsw[CONSOLE].write = consolewrite;\n}\n\nvoid\nuartinit(void)\n{\n  // disable interrupts.\n  WriteReg(IER, 0x00);\n\n  // special mode to set baud rate.\n  WriteReg(LCR, LCR_BAUD_LATCH);\n\n  // LSB for baud rate of 38.4K.\n  WriteReg(0, 0x03);\n\n  // MSB for baud rate of 38.4K.\n  WriteReg(1, 0x00);\n\n  // leave set-baud mode,\n  // and set word length to 8 bits, no parity.\n  WriteReg(LCR, LCR_EIGHT_BITS);\n\n  // reset and enable FIFOs.\n  WriteReg(FCR, FCR_FIFO_ENABLE | FCR_FIFO_CLEAR);\n\n  // enable transmit and receive interrupts.\n  WriteReg(IER, IER_TX_ENABLE | IER_RX_ENABLE);\n\n  initlock(&amp;uart_tx_lock, \"uart\");\n}\n</code></pre> <p>The xv6 shell reads from the console by way of a file descriptor opened by <code>init.c</code> (user/init.c:19). Calls to the read system call make their way through the kernel to <code>consoleread</code> (kernel/console.c:82). <code>consoleread</code> waits for input to arrive (via interrupts) and be buffered in <code>cons.buf</code>, copies the input to user space, and (after a whole line has arrived) returns to the user process. If the user hasn\u2019t typed a full line yet, any reading processes will wait in the sleep call (kernel/console.c:98) (Chapter 7 explains the details of sleep).</p> <p>\u7cfb\u7edf\u8c03\u7528<code>read()</code>\u6700\u540e\u7684\u771f\u6b63\u5b9e\u73b0\u662f<code>consoleread()</code>. console\u662f\u8fde\u63a5\u7528\u6237\u548cUART\u7684\u6865\u6881\u3002</p> <pre><code>// user/init.c:19\nint\nmain(void)\n{\n  int pid, wpid;\n\n  if(open(\"console\", O_RDWR) &lt; 0){\n    mknod(\"console\", CONSOLE, 0);\n    open(\"console\", O_RDWR);\n  }\n  ...........\n}\n\n// kernel/console.c:82\n// user read()s from the console go here.\n// copy (up to) a whole input line to dst.\n// user_dist indicates whether dst is a user\n// or kernel address.\n//\nint\nconsoleread(int user_dst, uint64 dst, int n)\n{\n  uint target;\n  int c;\n  char cbuf;\n\n  target = n;\n  acquire(&amp;cons.lock);\n  while(n &gt; 0){\n    // wait until interrupt handler has put some\n    // input into cons.buffer.\n    while(cons.r == cons.w){\n      if(myproc()-&gt;killed){\n        release(&amp;cons.lock);\n        return -1;\n      }\n      sleep(&amp;cons.r, &amp;cons.lock);\n    }\n\n    c = cons.buf[cons.r++ % INPUT_BUF];\n      .......\n\n  release(&amp;cons.lock);\n\n  return target - n;\n}\n</code></pre> <p>When the user types a character, the UART hardware asks the RISC-V to raise an interrupt, which activates xv6\u2019s trap handler. The trap handler calls <code>devintr</code> (kernel/trap.c:177), which looks at the RISC-V <code>scause</code> register to discover that the interrupt is from an external device. Then it asks a hardware unit called the PLIC [1] to tell it which device interrupted (kernel/trap.c:186). If it was the UART, <code>devintr</code> calls <code>uartintr</code>.</p> <p>\u8fd9\u91cc\u5bf9device \u2192 UART\u4e4b\u95f4\u7684\u5173\u7cfb\u4f5c\u4e86\u8bf4\u660e\u3002\u7528\u6237\u952e\u5165\u4e00\u4e2a\u5b57\u7b26\uff0cUART\u89e6\u53d1\u63a5\u6536\u4e2d\u65ad\u4ece\u800c\u89e6\u53d1trap handler\u3002\u8fd9\u7c7b\u5916\u90e8device\u4e2d\u65ad\u90fd\u4f1a\u88ab\u4ea4\u7ed9<code>devintr()</code>\u5904\u7406\uff0c\u5b83\u4f1a\u8be2\u95eePLIC\u662f\u54ea\u4e00\u4e2a\u5916\u90e8device\u505a\u51fa\u4e86\u8fd9\u4e2a\u4e2d\u65ad\u3002</p> <pre><code>// irq indicates which device interrupted.\n    int irq = plic_claim();\n\n    if(irq == UART0_IRQ){\n      uartintr();\n    } else if(irq == VIRTIO0_IRQ){\n      virtio_disk_intr();\n    } else if(irq){\n      printf(\"unexpected interrupt irq=%d\\n\", irq);\n    }\n</code></pre> <p><code>uartintr</code> (kernel/uart.c:180) reads any waiting input characters from the UART hardware and hands them to <code>consoleintr</code> (kernel/console.c:138); it doesn\u2019t wait for characters, since future input will raise a new interrupt. The job of <code>consoleintr</code> is to accumulate input characters in <code>cons.buf</code> until a whole line arrives. <code>consoleintr</code> treats backspace and a few other characters specially. When a newline arrives, <code>consoleintr</code> wakes up a waiting <code>consoleread</code> (if there is one).</p> <p>Once woken, <code>consoleread</code> will observe a full line in <code>cons.buf</code>, copy it to user space, and return (via the system call machinery) to user space.</p> <p>\u8fd9\u91cc\u5bf9UART\u2192console\u4e4b\u95f4\u7684\u5173\u7cfb\u4f5c\u4e86\u8bf4\u660e\u3002\u5728\u4e0a\u4e00\u6b65UART\u89e6\u53d1\u4e86\u63a5\u6536\u4e2d\u65ad\u540e\uff0c<code>trap.c</code>\u4e2d\u7684\u4ee3\u7801\u5c06\u4ed6\u5f15\u5165\u5230\u76f8\u5e94\u7684handler\u51fd\u6570\u4e2d\u3002<code>uartintr()</code>\u4e3aUART\u53d1\u8d77\u7684\u5916\u90e8\u4e2d\u65ad\u7684\u5904\u7406\u51fd\u6570, \u4ed6\u7684\u4e3b\u8981\u5de5\u4f5c\u5c31\u662f\u901a\u8fc7<code>uartgetc()</code>\u4ece\u76f8\u5e94\u7684\u5916\u90e8\u8bbe\u5907\u4e2d\u7684\u5bc4\u5b58\u5668\u4e2d\u8bfb\u53d6\u8f93\u5165\u7684\u5b57\u7b26\uff0c\u8bfb\u5230\u540e\u7acb\u523b\u4f20\u5165<code>consoleintr(c)</code>. <code>consoleintr()</code>\u4e2d\u7684\u4ee3\u7801\u4f1a\u5148\u5904\u7406\u4e00\u4e9b\u7279\u6b8a\u5b57\u7b26\u6307\u4ee4\uff0c\u4f46\u5176\u6838\u5fc3\u529f\u80fd\u5c31\u662f\u7ef4\u62a4<code>cons.buf</code>, \u8fd9\u4e2a\u7f13\u51b2\u533a\u5c31\u662f\u4e00\u4e2a\u79ef\u7d2f\u5b57\u7b26\u7684\u5730\u65b9\uff0c\u5f53\u5b83\u79ef\u7d2f\u4e86\u4e00\u884c\u65f6\uff0c\u5b83\u5c31\u9700\u8981\u5524\u9192<code>consoleread</code>\u6765\u6d88\u8d39\u4ed6\u5728buffer\u4e2d\u5df2\u7ecf\u5b58\u5165\u7684\u5185\u5bb9\u3002</p> <p>\u8fd9\u91cc\u7528buffer\u4f53\u73b0\u4e86\u4e00\u79cd\u751f\u4ea7\u8005-\u6d88\u8d39\u8005\u7684\u6a21\u5f0f</p> <p>\u4e3e\u4e2a\u4f8b\u5b50\uff1a</p> <p>\u8fd9\u91cc\u53ef\u4ee5\u60f3\u60f3<code>ls</code>\u6307\u4ee4\uff0c\u6211\u4eec\u5206\u522b\u8f93\u5165\u4e86<code>l,s</code>\u4e24\u4e2a\u5b57\u7b26\uff0c\u4ed6\u4eec\u89e6\u53d1\u4e86\u4e24\u6b21\u4e2d\u65ad\uff0c\u6bcf\u6b21\u4e2d\u65ad\u5206\u522b\u5c06<code>l</code>,<code>s</code>\u52a0\u5165\u5230console\u7684buffer\u4e4b\u4e2d\uff0c\u7136\u540e\u6211\u4eec\u6572\u51fb\u56de\u8f66\uff0c\u53c8\u5f15\u53d1\u4e86\u4e2d\u65ad\uff0c\u8fd9\u65f6console\u53d1\u73b0\u5b83\u83b7\u5f97\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u53e5\u5b50\uff0c\u4ed6\u5c31\u4f1a\u5524\u9192<code>consoleread()</code>\u628abuffer\u4e2d\u7684<code>ls</code>\u6307\u4ee4\u53d1\u7ed9\u4ed6\uff0c\u8fdb\u800c\u7cfb\u7edf\u8c03\u7528read\u4e5f\u5c31\u5f97\u5230\u4e86<code>ls</code>\uff0c\u63a5\u7740shell\u5c31\u53ef\u4ee5\u5f00\u542fls\u8fdb\u7a0b\u4e86\u3002</p> <pre><code>// handle a uart interrupt, raised because input has\n// arrived, or the uart is ready for more output, or\n// both. called from trap.c.\nvoid\nuartintr(void)\n{\n  // read and process incoming characters.\n  while(1){\n    int c = uartgetc();\n    if(c == -1)\n      break;\n    consoleintr(c);\n  }\n\n  // send buffered characters.\n  acquire(&amp;uart_tx_lock);\n  uartstart();\n  release(&amp;uart_tx_lock);\n}\n\n//\n// the console input interrupt handler.\n// uartintr() calls this for input character.\n// do erase/kill processing, append to cons.buf,\n// wake up consoleread() if a whole line has arrived.\n//\nvoid\nconsoleintr(int c)\n{\n  acquire(&amp;cons.lock);\n\n  switch(c){\n  case C('P'):  // Print process list.\n    procdump();\n    break;\n  case C('U'):  // Kill line.\n    while(cons.e != cons.w &amp;&amp;\n          cons.buf[(cons.e-1) % INPUT_BUF] != '\\n'){\n      cons.e--;\n      consputc(BACKSPACE);\n    }\n    break;\n  case C('H'): // Backspace\n  case '\\x7f':\n    if(cons.e != cons.w){\n      cons.e--;\n      consputc(BACKSPACE);\n    }\n    break;\n  default:\n    if(c != 0 &amp;&amp; cons.e-cons.r &lt; INPUT_BUF){\n      c = (c == '\\r') ? '\\n' : c;\n\n      // echo back to the user.\n      consputc(c);\n\n      // store for consumption by consoleread().\n      cons.buf[cons.e++ % INPUT_BUF] = c;\n\n      if(c == '\\n' || c == C('D') || cons.e == cons.r+INPUT_BUF){\n        // wake up consoleread() if a whole line (or end-of-file)\n        // has arrived.\n        cons.w = cons.e;\n        wakeup(&amp;cons.r);\n      }\n    }\n    break;\n  }\n\n  release(&amp;cons.lock);\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#52-code-console-output","title":"5.2 Code: Console output","text":"<p>\u4e0a\u4e00\u8282\u8bf4\u7684\u662f\u7cfb\u7edf\u8c03\u7528<code>read()</code>\u662f\u600e\u4e48\u8bfb\u5230\u7528\u6237\u8f93\u5165\u7684<code>ls</code>\u5e76\u8fd4\u56de\u7ed9\u5185\u6838\u7684\uff0c\u8fd9\u4e00\u8282\u8bf4\u7684\u662f\uff0c\u6211\u4eec\u5728shell\u547d\u4ee4\u884c\u8f93\u5165<code>l,s</code>\u65f6\uff0c\u4ed6\u662f\u5982\u4f55\u88ab\u4e00\u4e2a\u4e00\u4e2a\u7684\u6253\u5370\u5728\u547d\u4ee4\u884c\u4e2d\u7684\u3002\u8fd9\u91cc\u548c<code>console.c</code>\u6ca1\u6709\u4ec0\u4e48\u5173\u7cfb\uff0c\u8fd9\u91cc\u65f6UART\u4f1a\u5c06buffer\u4e2d\u7684\u5b57\u7b26\u53d1\u9001\u7ed9\u5176\u4ed6\u7684device\uff0c\u4f8b\u5982\u663e\u5b58\u3002</p> <p>A write system call on a file descriptor connected to the console eventually arrives at <code>uartputc</code> (kernel/uart.c:87). The device driver maintains an output buffer (<code>uart_tx_buf</code>) so that writing processes do not have to wait for the UART to finish sending; instead, <code>uartputc</code> appends each character to the buffer, calls <code>uartstart</code> to start the device transmitting (if it isn\u2019t already), and returns. The only situation in which <code>uartputc</code> waits is if the buffer is already full.</p> <p>\u53ef\u4ee5\u770b\u5230UART\u8fd9\u90e8\u5206\u7684\u4ee3\u7801\u4e5f\u7528\u5230\u4e86**\u6d88\u8d39\u8005-\u751f\u4ea7\u8005\u6a21\u5f0f**\uff0c\u4ed6\u4e5f\u7ef4\u62a4\u4e86\u4e00\u4e2abuffer\u7528\u6765\u6682\u5b58\u50cf<code>printf()</code>\u8fd9\u6837\u7684\u51fd\u6570\u53d1\u6765\u7684\u5b57\u7b26\u3002</p> <pre><code>// add a character to the output buffer and tell the\n// UART to start sending if it isn't already.\n// blocks if the output buffer is full.\n// because it may block, it can't be called\n// from interrupts; it's only suitable for use\n// by write().\n\n##define UART_TX_BUF_SIZE 32\nchar uart_tx_buf[UART_TX_BUF_SIZE];\nuint64 uart_tx_w; // write next to uart_tx_buf[uart_tx_w % UART_TX_BUF_SIZE]\nuint64 uart_tx_r; // read next from uart_tx_buf[uart_tx_r % UART_TX_BUF_SIZE]\n\nvoid\nuartputc(int c)\n{\n  acquire(&amp;uart_tx_lock);\n\n  if(panicked){\n    for(;;)\n      ;\n  }\n\n  while(1){\n    if(uart_tx_w == uart_tx_r + UART_TX_BUF_SIZE){\n      // buffer is full.\n      // wait for uartstart() to open up space in the buffer.\n      sleep(&amp;uart_tx_r, &amp;uart_tx_lock);\n    } else {\n      uart_tx_buf[uart_tx_w % UART_TX_BUF_SIZE] = c;\n      uart_tx_w += 1;\n      uartstart();\n      release(&amp;uart_tx_lock);\n      return;\n    }\n  }\n}\n</code></pre> <p>Each time the UART finishes sending a byte, it generates an interrupt. <code>uartintr</code> calls <code>uartstart</code>, which checks that the device really has finished sending, and hands the device the next buffered output character. Thus if a process writes multiple bytes to the console, typically the first byte will be sent by <code>uartputc\u2019s</code> call to <code>uartstart</code>, and the remaining buffered bytes will be sent by <code>uartstart</code> calls from <code>uartintr</code> as transmit complete interrupts arrive.</p> <p>\u4e0b\u9762\u8bf4\u660e\u4e86\u751f\u4ea7\u8005\u6d88\u8d39\u8005\u6a21\u578b\u7684\u91cd\u8981\u6027</p> <p>A general pattern to note is the decoupling of device activity from process activity via buffering and interrupts.</p> <p>The console driver can process input even when no process is waiting to read it; a subsequent read will see the input. Similarly, processes can send output without having to wait for the device.</p> <p>This decoupling can increase performance by allowing processes to execute concurrently with device I/O, and is particularly important when the device is slow (as with the UART) or needs immediate attention (as with echoing typed characters). This idea is sometimes called I/O concurrency.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#53-concurrency-in-drivers","title":"5.3 Concurrency in drivers","text":"<p>You may have noticed calls to acquire in <code>consoleread</code> and in <code>consoleintr</code>. These calls acquire a lock, which protects the console driver\u2019s data structures from concurrent access.</p> <p>There are three concurrency dangers here:</p> <ul> <li>two processes on different CPUs might call <code>consoleread</code> at the same time;</li> <li>the hardware might ask a CPU to deliver a console (really UART) interrupt while that CPU is already executing inside <code>consoleread</code>;</li> <li>the hardware might deliver a console interrupt on a different CPU while <code>consoleread</code> is executing.</li> </ul> <p>Another way in which concurrency requires care in drivers is that one process may be waiting for input from a device, but the interrupt signaling arrival of the input may arrive when a different process (or no process at all) is running. Thus interrupt handlers are not allowed to think about the process or code that they have interrupted. For example, an interrupt handler cannot safely call <code>copyout</code> with the current process\u2019s page table. Interrupt handlers typically do relatively little work (e.g., just copy the input data to a buffer), and wake up top-half code to do the rest.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#54-timer-interrupts","title":"5.4 Timer interrupts","text":"<p>Xv6 uses timer interrupts to maintain its clock and to enable it to switch among compute-bound processes; the yield calls in usertrap and kerneltrap cause this switching. Timer interrupts come from clock hardware attached to each RISC-V CPU. Xv6 programs this clock hardware to interrupt each CPU periodically.</p> <p>RISC-V requires that timer interrupts be taken in machine mode, not supervisor mode. RISCV machine mode executes without paging, and with a separate set of control registers, so it\u2019s not practical to run ordinary xv6 kernel code in machine mode. As a result, xv6 handles timer interrupts completely separately from the trap mechanism laid out above.</p> <p>Code executed in machine mode in <code>start.c</code>, before main, sets up to receive timer interrupts (kernel/start.c:57). Part of the job is to program the CLINT hardware (core-local <code>interruptor</code>) to generate an interrupt after a certain delay. Another part is to set up a <code>scratch area</code>, analogous to the <code>trapframe</code>, to help the timer interrupt handler save registers and the address of the CLINT registers. Finally, start sets <code>mtvec</code> to <code>timervec</code> and enables timer interrupts.</p> <p>A timer interrupt can occur at any point when user or kernel code is executing; there\u2019s no way for the kernel to disable timer interrupts during critical operations. Thus the timer interrupt handler must do its job in a way guaranteed not to disturb interrupted kernel code. The basic strategy is for the handler to ask the RISC-V to raise a \u201csoftware interrupt\u201d and immediately return. The RISC-V delivers software interrupts to the kernel with the ordinary trap mechanism, and allows the kernel to disable them. The code to handle the software interrupt generated by a timer interrupt can be seen in <code>devintr</code> (kernel/trap.c:204).</p> <p>The machine-mode timer interrupt vector is <code>timervec</code> (kernel/kernelvec.S:93). It saves a few registers in the scratch area prepared by start, tells the CLINT when to generate the next timer interrupt, asks the RISC-V to raise a software interrupt, restores registers, and returns. There\u2019s no C code in the timer interrupt handler.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#55-real-world","title":"5.5 Real world","text":"<ul> <li>DMA</li> </ul> <p>The UART driver retrieves data a byte at a time by reading the UART control registers; this pattern is called programmed I/O, since software is driving the data movement. Programmed I/O is simple, but too slow to be used at high data rates. Devices that need to move lots of data at high speed typically use direct memory access (DMA). DMA device hardware directly writes incoming data to RAM, and reads outgoing data from RAM. Modern disk and network devices use DMA. A driver for a DMA device would prepare data in RAM, and then use a single write to a control register to tell the device to process the prepared data.</p> <ul> <li>Polling</li> </ul> <p>Interrupts make sense when a device needs attention at unpredictable times, and not too often. But interrupts have high CPU overhead. Thus high speed devices, such networks and disk controllers, use tricks that reduce the need for interrupts.</p> <ul> <li>One trick is to raise a single interrupt for a whole batch of incoming or outgoing requests.</li> <li>Another trick is for the driver to disable interrupts entirely, and to check the device periodically to see if it needs attention. This technique is called <code>polling</code>. Polling makes sense if the device performs operations very quickly, but it wastes CPU time if the device is mostly idle. Some drivers dynamically switch between polling and interrupts depending on the current device load.</li> </ul>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#chapter6-locking","title":"Chapter6. Locking","text":"<p>Most kernels, including xv6, interleave the execution of multiple activities. One source of interleaving is multiprocessor hardware: computers with multiple CPUs executing independently, such as xv6\u2019s RISC-V. These multiple CPUs share physical RAM, and xv6 exploits the sharing to maintain data structures that all CPUs read and write. This sharing raises the possibility of one CPU reading a data structure while another CPU is mid-way through updating it, or even multiple CPUs updating the same data simultaneously; without careful design such parallel access is likely to yield incorrect results or a broken data structure. Even on a uniprocessor, the kernel may switch the CPU among a number of threads, causing their execution to be interleaved. Finally, a device interrupt handler that modifies the same data as some interruptible code could damage the data if the interrupt occurs at just the wrong time. The word concurrency refers to situations in which multiple instruction streams are interleaved, due to multiprocessor parallelism, thread switching, or interrupts.</p> <p>Kernels are full of concurrently-accessed data. For example, two CPUs could simultaneously call <code>kalloc</code>, thereby concurrently popping from the head of the free list. Kernel designers like to allow for lots of concurrency, since it can yield increased performance though parallelism, and increased responsiveness. However, as a result kernel designers spend a lot of effort convincing themselves of correctness despite such concurrency. There are many ways to arrive at correct code, some easier to reason about than others. Strategies aimed at correctness under concurrency, and abstractions that support them, are called concurrency control techniques.</p> <p>Xv6 uses a number of concurrency control techniques, depending on the situation; many more are possible. This chapter focuses on a widely used technique: the lock. A lock provides mutual exclusion, ensuring that only one CPU at a time can hold the lock. If the programmer associates a lock with each shared data item, and the code always holds the associated lock when using an item, then the item will be used by only one CPU at a time. In this situation, we say that the lock protects the data item. Although locks are an easy-to-understand concurrency control mechanism, the downside of locks is that they can kill performance, because they serialize concurrent operations.</p> <p>The rest of this chapter explains why xv6 needs locks, how xv6 implements them, and how it uses them.</p> <p></p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#61-race-conditions","title":"6.1 Race conditions","text":"<p>2\u4e2aCPU\u540c\u65f6\u5728\u8fdb\u884c\u5b50\u8fdb\u7a0b\u7684<code>kfree</code>, \u7136\u800ckernel\u7ef4\u62a4\u7684\u94fe\u8868\u53ea\u6709\u4e00\u4e2a\uff0c\u6b64\u65f6\u65e0\u6cd5\u5e76\u884c</p> <p>As an example of why we need locks, consider two processes calling wait on two different CPUs. wait frees the child\u2019s memory. Thus on each CPU, the kernel will call <code>kfree</code> to free the children\u2019s pages. The kernel allocator maintains a linked list: <code>kalloc()</code> (kernel/kalloc.c:69) pops a page of memory from a list of free pages, and <code>kfree()</code> (kernel/kalloc.c:47) pushes a page onto the free list. For best performance, we might hope that the <code>kfrees</code> of the two parent processes would execute in parallel without either having to wait for the other, but this would not be correct given xv6\u2019s <code>kfree</code> implementation.</p> <p>Figure 6.1 illustrates the setting in more detail: the linked list is in memory that is shared by the two CPUs, which manipulate the linked list using load and store instructions. (In reality, the processors have caches, but conceptually multiprocessor systems behave as if there were a single, shared memory.) If there were no concurrent requests, you might implement a list push operation as follows:</p> <pre><code>struct element {\n    int data;\n    struct element *next;\n};\n\nstruct element *list = 0;\n\nvoid\npush(int data)\n{\n    struct element *l;\n\n    l = malloc(sizeof *l);\n    l-&gt;data = data;\n    l-&gt;next = list;\n    list = l;\n}\n</code></pre> <p></p> <p>This implementation is correct if executed in isolation. However, the code is not correct if more than one copy executes concurrently. If two CPUs execute push at the same time, both might execute line 15 as shown in Fig 6.1, before either executes line 16, which results in an incorrect outcome as illustrated by Figure 6.2. There would then be two list elements with next set to the former value of list. When the two assignments to list happen at line 16, the second one will overwrite the first; the element involved in the first assignment will be lost.</p> <p>The lost update at line 16 is an example of a race condition.</p> <p>A race condition is a situation in which a memory location is accessed concurrently, and at least one access is a write. A race is often a sign of a bug, either a lost update (if the accesses are writes) or a read of an incompletely-updated data structure. The outcome of a race depends on the exact timing of the two CPUs involved and how their memory operations are ordered by the memory system, which can make race-induced errors difficult to reproduce and debug. For example, adding print statements while debugging push might change the timing of the execution enough to make the race disappear.</p> <p>The usual way to avoid races is to use a lock. Locks ensure mutual exclusion, so that only one CPU at a time can execute the sensitive lines of push; this makes the scenario above impossible. The correctly locked version of the above code adds just a few lines :</p> <pre><code>struct element *list = 0;\nstruct lock listlock;\n\nvoid\npush(int data)\n{\n    struct element *l;\n    l = malloc(sizeof *l);\n    l-&gt;data = data;\n\n    acquire(&amp;listlock);\n    l-&gt;next = list;\n    list = l;\n    release(&amp;listlock);\n}\n</code></pre> <p>The sequence of instructions between acquire and release is often called a critical section. The lock is typically said to be protecting list.</p> <p>When we say that a lock protects data, we really mean that the lock protects some collection of invariants that apply to the data. I**nvariants are properties of data structures that are maintained across operations**. Typically, an operation\u2019s correct behavior depends on the invariants being true when the operation begins. The operation may temporarily violate the invariants but must reestablish them before finishing. For example, in the linked list case, the invariant is that list points at the first element in the list and that each element\u2019s next field points at the next element. The implementation of push violates this invariant temporarily: in line 17, l points to the next list element, but list does not point at l yet (reestablished at line 18). The race condition we examined above happened because a second CPU executed code that depended on the list invariants while they were (temporarily) violated. Proper use of a lock ensures that only one CPU at a time can operate on the data structure in the critical section, so that no CPU will execute a data structure operation when the data structure\u2019s invariants do not hold.</p> <p>You can think of a lock as</p> <ul> <li>serializing concurrent critical sections so that they run one at a time, and thus preserve invariants (assuming the critical sections are correct in isolation). You can also think of critical sections guarded by the same lock as</li> <li>being atomic with respect to each other, so that each sees only the complete set of changes from earlier critical sections, and never sees partially-completed updates.</li> </ul> <p>Although correct use of locks can make incorrect code correct, locks limit performance.</p> <p>For example, if two processes call <code>kfree</code> concurrently, the locks will serialize the two calls, and we obtain no benefit from running them on different CPUs.</p> <p>We say that multiple processes conflict if they want the same lock at the same time, or that the lock experiences <code>contention</code>.</p> <p>A major challenge in kernel design is to avoid lock contention. Xv6 does little of that, but sophisticated kernels organize data structures and algorithms specifically to avoid lock contention. In the list example, a kernel may maintain a free list per CPU and only touch another CPU\u2019s free list if the CPU\u2019s list is empty and it must steal memory from another CPU. Other use cases may require more complicated designs.</p> <p>The placement of locks is also important for performance. For example, it would be correct to move acquire earlier in push: it is fine to move the call to acquire up to before line 13. This may reduce performance because then the calls to malloc are also serialized. The section \u201cUsing locks\u201d below provides some guidelines for where to insert acquire and release invocations.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#62-code-locks","title":"6.2 Code: Locks","text":"<p>Xv6 has two types of locks:</p> <p><code>spinlocks</code> and <code>sleep-locks</code></p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#spinlocks","title":"<code>Spinlocks</code>","text":"<p>We\u2019ll start with spinlocks. Xv6 represents a spinlock as a struct spinlock (kernel/spinlock.h:2). The important field in the structure is locked, a word that is zero when the lock is available and non-zero when it is held. Logically, xv6 should acquire a lock by executing code like</p> <pre><code>// Mutual exclusion lock.\nstruct spinlock {\n  uint locked;       // Is the lock held?\n\n  // For debugging:\n  char *name;        // Name of lock.\n  struct cpu *cpu;   // The cpu holding the lock.\n}\n\n21 void\n22 acquire(struct spinlock *lk) // does not work!\n23 {\n24      for(;;) {\n25          if(lk-&gt;locked == 0) {\n26              lk-&gt;locked = 1;\n27               break;\n28           }\n29      }\n30 }\n</code></pre> <p>Unfortunately, this implementation does not guarantee mutual exclusion on a multiprocessor. It could happen that two CPUs simultaneously reach line 25, see that <code>lk-&gt;locked</code> is zero, and then both grab the lock by executing line 26. At this point, two different CPUs hold the lock, which violates the mutual exclusion property. What we need is a way to make lines 25 and 26 execute as an atomic (i.e., indivisible) step.</p> <p>Because locks are widely used, multi-core processors usually provide instructions that implement an atomic version of lines 25 and 26. On the RISC-V this instruction is <code>amoswap r, a</code>.</p> <p><code>amoswap</code> reads the value at the memory address a, writes the contents of register r to that address, and puts the value it read into r. That is, it swaps the contents of the register and the memory address. It performs this sequence atomically, using special hardware to prevent any other CPU from using the memory address between the read and the write.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#acquire","title":"Acquire","text":"<p>\u9501\u4f9d\u9760\u7684\u662f\u786c\u4ef6\u7684\u6280\u672f\uff0c\u786c\u4ef6\u4f7f\u5f97\u6307\u4ee4\u53ef\u4ee5\u539f\u5b50\u7684\u6267\u884c\u3002\u4e0a\u9501\u7684\u8fc7\u7a0b\u5c31\u662f\u7528\u539f\u5b50\u6307\u4ee4<code>amoswap</code>\u4e0d\u65ad\u5730\u75281\u548c\u67d0\u4e2a\u5bc4\u5b58\u5668\u4e2d\u7684\u503c\u8fdb\u884c\u4ea4\u6362\uff0c\u82e5\u4ea4\u6362\u540e\u4e3a0\uff0c\u5219\u8bc1\u660e\u5176\u4ed6CPU\u5df2\u7ecf\u5f00\u4e86\u9501\uff0c\u5f53\u524dCPU\u4e5f\u628a1\u653e\u8fdb\u4e86\u8be5\u5bc4\u5b58\u5668\u4e2d\uff1b\u82e5\u4ea4\u6362\u540e\u4e3a1\uff0c\u8bf4\u660e\u6709\u5176\u4ed6CPU\u8fd8\u5728\u5360\u7528\uff0c\u4f46\u6211\u4eec\u662f\u75281\u6362\u4e861\uff0c\u6240\u4ee5\u5e76\u6ca1\u6709\u5bf9\u4e0a\u9501\u672c\u8eab\u9020\u6210\u5f71\u54cd\u3002</p> <p>Xv6\u2019s acquire (kernel/spinlock.c:22) uses the portable C library call <code>__sync_lock_test_and_set</code>, which boils down to(\u5f52\u7ed3\u4e3a) the <code>amoswap</code> instruction; the return value is the old (swapped) contents of <code>lk-&gt;locked</code>. The acquire function wraps the swap in a loop, retrying (spinning) until it has acquired the lock. Each iteration swaps one into <code>lk-&gt;locked</code> and checks the previous value; if the previous value is zero, then we\u2019ve acquired the lock, and the swap will have set <code>lk-&gt;locked</code> to one. If the previous value is one, then some other CPU holds the lock, and the fact that we atomically swapped one into <code>lk-&gt;locked</code> didn\u2019t change its value.</p> <pre><code>/ Acquire the lock.\n// Loops (spins) until the lock is acquired.\nvoid\nacquire(struct spinlock *lk)\n{\n  push_off(); // disable interrupts to avoid deadlock.\n  if(holding(lk))\n    panic(\"acquire\");\n\n  // On RISC-V, sync_lock_test_and_set turns into an atomic swap:\n  //   a5 = 1\n  //   s1 = &amp;lk-&gt;locked\n  //   amoswap.w.aq a5, a5, (s1)\n  while(__sync_lock_test_and_set(&amp;lk-&gt;locked, 1) != 0)\n    ;\n\n  // Tell the C compiler and the processor to not move loads or stores\n  // past this point, to ensure that the critical section's memory\n  // references happen strictly after the lock is acquired.\n  // On RISC-V, this emits a fence instruction.\n  __sync_synchronize();\n\n  // Record info about lock acquisition for holding() and debugging.\n  lk-&gt;cpu = mycpu();\n}\n</code></pre> <p>Once the lock is acquired, acquire records, for debugging, the CPU that acquired the lock. The <code>lk-&gt;cpu</code> field is protected by the lock and must only be changed while holding the lock.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#release","title":"Release","text":"<p>release\u5c31\u662facquire\u7684\u53cd\u9762\u4e86\uff0c\u5979\u5c31\u662f\u75280\u53bb\u63621\u3002</p> <p>The function release (kernel/spinlock.c:47) is the opposite of acquire: it clears the <code>lk-&gt;cpu</code> field and then releases the lock.</p> <p>Conceptually, the release just requires assigning zero to <code>lk-&gt;locked</code>. The C standard allows compilers to implement an assignment with multiple store instructions, so a C assignment might be non-atomic with respect to concurrent code. Instead, release uses the C library function <code>__sync_lock_release</code> that performs an atomic assignment. This function also boils down to a RISC-V <code>amoswap</code> instruction.</p> <pre><code>// Release the lock.\nvoid\nrelease(struct spinlock *lk)\n{\n  if(!holding(lk))\n    panic(\"release\");\n\n  lk-&gt;cpu = 0;\n\n  // Tell the C compiler and the CPU to not move loads or stores\n  // past this point, to ensure that all the stores in the critical\n  // section are visible to other CPUs before the lock is released,\n  // and that loads in the critical section occur strictly before\n  // the lock is released.\n  // On RISC-V, this emits a fence instruction.\n  __sync_synchronize();\n\n  // Release the lock, equivalent to lk-&gt;locked = 0.\n  // This code doesn't use a C assignment, since the C standard\n  // implies that an assignment might be implemented with\n  // multiple store instructions.\n  // On RISC-V, sync_lock_release turns into an atomic swap:\n  //   s1 = &amp;lk-&gt;locked\n  //   amoswap.w zero, zero, (s1)\n  __sync_lock_release(&amp;lk-&gt;locked);\n\n  pop_off();\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#63-code-using-locks","title":"6.3 Code: Using locks","text":"<p>Xv6 uses locks in many places to avoid race conditions. As described above, <code>kalloc</code> (kernel/kalloc.c:69) and <code>kfree</code> (kernel/kalloc.c:47) form a good example. Try Exercises 1 and 2 to see what happens if those functions omit the locks. You\u2019ll likely find that it\u2019s difficult to trigger incorrect behavior, suggesting that it\u2019s hard to reliably test whether code is free from locking errors and races. It is not unlikely that xv6 has some races.</p> <p>A hard part about using locks is deciding how many locks to use and which data and invariants each lock should protect.</p> <p>There are a few basic principles.</p> <ul> <li>First, any time a variable can be written by one CPU at the same time that another CPU can read or write it, a lock should be used to keep the two operations from overlapping.</li> <li>Second, remember that locks protect invariants: if an invariant involves multiple memory locations, typically all of them need to be protected by a single lock to ensure the invariant is maintained.</li> </ul> <p>The rules above say when locks are necessary but say nothing about when locks are unnecessary, and it is important for efficiency not to lock too much, because locks reduce parallelism. If parallelism isn\u2019t important, then one could arrange to have only a single thread and not worry about locks. A simple kernel can do this on a multiprocessor by having a single lock that must be acquired on entering the kernel and released on exiting the kernel (though system calls such as pipe reads or wait would pose a problem). Many uniprocessor operating systems have been converted to run on multiprocessors using this approach, sometimes called a \u201cbig kernel lock,\u201d but the approach sacrifices parallelism: only one CPU can execute in the kernel at a time. If the kernel does any heavy computation, it would be more efficient to use a larger set of more fine-grained locks, so that the kernel could execute on multiple CPUs simultaneously.</p> <p>Xv6\u5728\u7269\u7406\u5185\u5b58\u7ba1\u7406\u4e0a\u7528\u9501\u662f\u5f88\u7c97\u7c92\u5ea6\u7684\uff0c\u4e5f\u5c31\u662f\u53ea\u6709\u4e00\u4e2aCPU\u53ef\u4ee5\u53bb\u8bfb\u5199\u7269\u7406\u5185\u5b58\u7684\u94fe\u8868\u3002\u5176\u4ed6\u9700\u8981\u7269\u7406\u5185\u5b58\u64cd\u4f5cCPU\u5c31\u53ea\u80fd\u5728\u9501\u7684\u4ee3\u7801\u4e2d\u4e00\u76f4\u5faa\u73af\u3002</p> <p>As an example of coarse-grained(\u7c97\u7c92\u5ea6) locking, xv6\u2019s <code>kalloc.c</code> allocator has a single free list protected by a single lock. If multiple processes on different CPUs try to allocate pages at the same time, each will have to wait for its turn by spinning in acquire. Spinning reduces performance, since it\u2019s not useful work. If contention for the lock wasted a significant fraction of CPU time, perhaps performance could be improved by changing the allocator design to have multiple free lists, each with its own lock, to allow truly parallel allocation.</p> <p>As an example of fine-grained locking, xv6 has a separate lock for each file, so that processes that manipulate different files can often proceed without waiting for each other\u2019s locks. The file locking scheme could be made even more fine-grained if one wanted to allow processes to simultaneously write different areas of the same file. Ultimately lock granularity decisions need to be driven by performance measurements as well as complexity considerations.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#64-deadlock-and-lock-ordering","title":"6.4 Deadlock and lock ordering","text":"<p>If a code path through the kernel must hold several locks at the same time, it is important that all code paths acquire those locks in the same order. If they don\u2019t, there is a risk of deadlock.</p> <p>\u9501\u7684\u987a\u5e8f\u4e0e\u6b7b\u9501\u7684\u4f8b\u5b50</p> <p>\u7ebf\u7a0bT1\u6309\u987a\u5e8f\u8981\u4e24\u628a\u9501A\uff0cB\uff1b\u7ebf\u7a0bT2\u6309\u987a\u5e8f\u8981\u4e24\u628a\u9501B\uff0cA\u3002</p> <p>\u67d0\u79cd\u60c5\u5f62\u4e0b\uff0cT1\u62ff\u5230\u4e86A\u7684\u9501\uff0cT2\u62ff\u5230\u4e86B\u7684\u9501\u3002\u90a3\u4e48\u63a5\u4e0b\u6765\uff0cT1\u5c31\u4f1a\u7b49\u5f85\u9501B\u88abrelease\uff0cT2\u5c31\u4f1a\u7b49\u5f85\u9501A\u88abrelease\u3002\u8fd9\u6837\u7684\u60c5\u51b5\u4e0b\uff0cT1\u62ff\u4e0d\u5230\u9501B\u6240\u4ee5\u4e5f\u5c31\u4e0d\u53ef\u80fd\u6267\u884c\u5230\u91ca\u653eA\u7684\u4ee3\u7801\u3002T2\u4e5f\u662f\u540c\u7406\u3002</p> <p>\u89e3\u51b3\u7684\u65b9\u6848\u5c31\u662f\u8ba9\u6240\u6709path\u4f7f\u7528\u9501\u7684\u987a\u5e8f\u4e00\u81f4</p> <p>Let\u2019s say two code paths in xv6 need locks A and B, but code path 1 acquires locks in the order A then B, and the other path acquires them in the order B then A. Suppose thread T1 executes code path 1 and acquires lock A, and thread T2 executes code path 2 and acquires lock B. Next T1 will try to acquire lock B, and T2 will try to acquire lock A. Both acquires will block indefinitely, because in both cases the other thread holds the needed lock, and won\u2019t release it until its acquire returns. To avoid such deadlocks, all code paths must acquire locks in the same order. The need for a global lock acquisition order means that locks are effectively part of each function\u2019s specification: callers must invoke functions in a way that causes locks to be acquired in the agreed-on order.</p> <p>Xv6 has many lock-order chains of length two involving per-process locks (the lock in each struct proc) due to the way that sleep works (see Chapter 7).</p> <p><code>con.lock</code> \u2192 <code>p.lock</code></p> <p>For example, <code>consoleintr</code> (kernel/console.c:138) is the interrupt routine which handles typed characters. When a newline arrives, any process that is waiting for console input should be woken up. To do this,<code>consoleintr</code> holds <code>cons.lock</code> while calling wakeup, which acquires the waiting process\u2019s lock in order to wake it up. In consequence, the global deadlock-avoiding lock order includes the rule that <code>cons.lock</code> must be acquired before any process lock.</p> <p><code>ip.lock</code> \u2192 <code>buf.lock</code> \u2192<code>vdisk_lock</code>\u2192<code>p-&gt;lock</code></p> <p>The file-system code contains xv6\u2019s longest lock chains. For example, creating a file requires simultaneously holding a lock on the directory, a lock on the new file\u2019s <code>inode</code>, a lock on a disk block buffer, the disk driver\u2019s <code>vdisk_lock</code>, and the calling process\u2019s <code>p-&gt;lock</code>. To avoid deadlock, file-system code always acquires locks in the order mentioned in the previous sentence.</p> <p>Honoring a global deadlock-avoiding order can be surprisingly difficult.</p> <p>Sometimes the lock order conflicts with logical program structure, e.g., perhaps code module M1 calls module M2, but the lock order requires that a lock in M2 be acquired before a lock in M1. Sometimes the identities of locks aren\u2019t known in advance, perhaps because one lock must be held in order to discover the identity of the lock to be acquired next. This kind of situation arises in the file system as it looks up successive components in a path name, and in the code for wait and exit as they search the table of processes looking for child processes. Finally, the danger of deadlock is often a constraint on how fine-grained one can make a locking scheme, since more locks often means more opportunity for deadlock. The need to avoid deadlock is often a major factor in kernel implementation.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#65-locks-and-interrupt-handlers","title":"6.5 Locks and interrupt handlers","text":"<p>Some xv6 spinlocks protect data that is used by both threads and interrupt handlers. For example, the <code>clockintr</code> timer interrupt handler might increment ticks (kernel/trap.c:163) at about the same time that a kernel thread reads ticks in sys_sleep (kernel/sysproc.c:64). The lock <code>tickslock</code> serializes the two accesses.</p> <pre><code>void\nclockintr()\n{\n  acquire(&amp;tickslock);\n  ticks++;\n  wakeup(&amp;ticks);\n  release(&amp;tickslock);\n}\n\nuint64\nsys_sleep(void)\n{\n  int n;\n  uint ticks0;\n\n  if(argint(0, &amp;n) &lt; 0)\n    return -1;\n  acquire(&amp;tickslock);\n  ticks0 = ticks;\n  while(ticks - ticks0 &lt; n){\n    if(myproc()-&gt;killed){\n      release(&amp;tickslock);\n      return -1;\n    }\n    sleep(&amp;ticks, &amp;tickslock);\n  }\n  release(&amp;tickslock);\n  return 0;\n}\n</code></pre> <p>The interaction of spinlocks and interrupts raises a potential danger. Suppose sys_sleep holds <code>tickslock</code>, and its CPU is interrupted by a timer interrupt. <code>clockintr</code> would try to acquire <code>tickslock</code>, see it was held, and wait for it to be released. In this situation, <code>tickslock</code> will never be released: only sys_sleep can release it, but sys_sleep will not continue running until <code>clockintr</code> returns. So the CPU will deadlock, and any code that needs either lock will also freeze.</p> <p>\u8fd9\u91cc\u63cf\u8ff0\u4e86\u4e2d\u65ad\u53ef\u80fd\u5e26\u6765\u7684\u6b7b\u9501\u95ee\u9898\uff0c\u4e2d\u65ad\u53ef\u80fd\u4f1a\u5bfc\u81f4\u9884\u8bbe\u7684\u987a\u5e8f\u88ab\u6253\u4e71\u3002</p> <p>To avoid this situation, if a spinlock is used by an interrupt handler, a CPU must never hold that lock with interrupts enabled. Xv6 is more conservative: when a CPU acquires any lock, xv6 always disables interrupts on that CPU. Interrupts may still occur on other CPUs, so an interrupt\u2019s acquire can wait for a thread to release a spinlock; just not on the same CPU.</p> <p>xv6 re-enables interrupts when a CPU holds no spinlocks;</p> <p>it must do a little book-keeping to cope with nested critical sections. acquire calls <code>push_off</code> (kernel/spinlock.c:89) and release calls <code>pop_off</code> (kernel/spinlock.c:100) to track the nesting level of locks on the current CPU. When that count reaches zero, <code>pop_off</code> restores the interrupt enable state that existed at the start of the outermost critical section. The <code>intr_off</code>and <code>intr_on</code> functions execute RISC-V instructions to disable and enable interrupts, respectively.</p> <pre><code>// push_off/pop_off are like intr_off()/intr_on() except that they are matched:\n// it takes two pop_off()s to undo two push_off()s.  Also, if interrupts\n// are initially off, then push_off, pop_off leaves them off.\n\nvoid\npush_off(void)\n{\n  int old = intr_get();\n\n  intr_off();\n  if(mycpu()-&gt;noff == 0)\n    mycpu()-&gt;intena = old;\n  mycpu()-&gt;noff += 1;\n}\n\nvoid\npop_off(void)\n{\n  struct cpu *c = mycpu();\n  if(intr_get())\n    panic(\"pop_off - interruptible\");\n  if(c-&gt;noff &lt; 1)\n    panic(\"pop_off\");\n  c-&gt;noff -= 1;\n  if(c-&gt;noff == 0 &amp;&amp; c-&gt;intena)\n    intr_on();\n}\n</code></pre> <p>It is important that acquire call push_off strictly before setting <code>lk-&gt;locked</code> (kernel/spinlock.c:28). If the two were reversed, there would be a brief window when the lock was held with interrupts enabled, and an unfortunately timed interrupt would deadlock the system. Similarly, it is important that release call <code>pop_off</code> only after releasing the lock (kernel/spinlock.c:66).</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#66-instruction-and-memory-ordering","title":"6.6 Instruction and memory ordering","text":"<p>It is natural to think of programs executing in the order in which source code statements appear. Many compilers and CPUs, however, execute code out of order to achieve higher performance. If an instruction takes many cycles to complete, a CPU may issue the instruction early so that it can overlap with other instructions and avoid CPU stalls(\u505c\u987f). For example, a CPU may notice that in a serial sequence of instructions A and B are not dependent on each other. The CPU may start instruction B first, either because its inputs are ready before A\u2019s inputs, or in order to overlap execution of A and B. A compiler may perform a similar re-ordering by emitting instructions for one statement before the instructions for a statement that precedes it in the source.</p> <p>CPU\u548cCompiler\u4f1a\u4e3a\u4e86\u7a0b\u5e8f\u7684\u6709\u66f4\u9ad8\u7684\u6027\u80fd\u6253\u4e71\u6267\u884c\u7684\u987a\u5e8f\uff0c\u8fd9\u5bf9\u7ebf\u6027\u6267\u884c\u7684\u4ee3\u7801\u529f\u80fd\u6ca1\u6709\u5f71\u54cd\uff0c\u4f46\u5bf9\u4e8e\u5e76\u53d1\u7684\u4ee3\u7801\u5c31\u5e26\u6765\u4e86\u95ee\u9898\uff0c</p> <p>Compilers and CPUs follow rules when they re-order to ensure that they don\u2019t change the results of correctly-written serial code. However, the rules do allow re-ordering that changes the results of concurrent code, and can easily lead to incorrect behavior on multiprocessors . The CPU\u2019s ordering rules are called the <code>memory model</code>.</p> <p>For example, in this code for push, it would be a disaster if the compiler or CPU moved the store corresponding to line 4 to a point after the release on line 6:</p> <pre><code>1 l = malloc(sizeof *l);\n2 l-&gt;data = data;\n3 acquire(&amp;listlock);\n4 l-&gt;next = list;\n5 list = l;\n6 release(&amp;listlock);\n</code></pre> <p>If such a re-ordering occurred, there would be a window during which another CPU could acquire the lock and observe the updated list, but see an uninitialized list-&gt;next.</p> <p>To tell the hardware and compiler not to perform such re-orderings, xv6 uses <code>__sync_synchronize()</code> in both acquire (kernel/spinlock.c:22) and release (kernel/spinlock.c:47).<code>__sync_synchronize()</code> is a memory barrier: it tells the compiler and CPU to not reorder loads or stores across the barrier. The barriers in xv6\u2019s acquire and release force order in almost all cases where it matters, since xv6 uses locks around accesses to shared data. Chapter 9 discusses a few exceptions.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#67-sleep-locks","title":"6.7 Sleep locks","text":"<p>\u9501\u5e26\u6765\u95ee\u9898\u7684\u60c5\u51b5\u4e4b\u4e00\uff1a\u5411\u78c1\u76d8\u8bfb\u5199\u6587\u4ef6\u65f6\uff0c\u56e0\u4e3a\u9501\u7684\u539f\u56e0\uff0c\u5176\u4ed6\u7684\u8fdb\u7a0b\u4e5f\u65e0\u6cd5\u4f7f\u7528CPU\uff0c\u53ea\u80fd\u7b49\u5f85CPU\u6267\u884c\u5230\u78c1\u76d8\u8fd4\u56de\u6d88\u606f\u5e76\u89e3\u5f00\u9501\uff0c\u4f46\u78c1\u76d8\u7684\u8bfb\u5199\u662f\u975e\u5e38\u6162\u7684\u3002\u6211\u4eec\u5176\u5b9e\u53ef\u4ee5\u5728\u5f53\u524d\u8fdb\u7a0b\u7b49\u5f85I/O\u64cd\u4f5c\u7684\u7a7a\u95f2\u65f6\u95f4\uff0c\u628aCPU\u8ba9\u7ed9\u5176\u4ed6\u7684\u8fdb\u7a0b\u3002</p> <p>\u4f46\u662f\u5728\u62e5\u6709\u9501\u7684\u65f6\u5019\u5207\u6362\u8fdb\u7a0b\u662f\u4e0d\u5408\u6cd5\u7684\uff0c</p> <p>\u8fd9\u91cc\u7684\u4e0d\u5408\u6cd5\u6ca1\u6709\u592a\u660e\u767d\u3002\u3002\u3002\u3002\u3002\u3002\u3002\u3002\u3002\u3002\u3002\u3002\u3002\u3002\u4e4b\u540e\u8865\u5145</p> <p>\u7b2c\u4e03\u7ae0\u4f1a\u6df1\u5165\u8bf4\u660e</p> <p>Sometimes xv6 needs to hold a lock for a long time. For example, the file system (Chapter 8) keeps a file locked while reading and writing its content on the disk, and these disk operations can take tens of milliseconds. Holding a spinlock that long would lead to waste if another process wanted to acquire it, since the acquiring process would waste CPU for a long time while spinning. Another drawback of spinlocks is that a process cannot yield the CPU while retaining a spinlock; we\u2019d like to do this so that other processes can use the CPU while the process with the lock waits for the disk. Yielding while holding a spinlock is illegal because it might lead to deadlock if a second thread then tried to acquire the spinlock; since acquire doesn\u2019t yield the CPU, the second thread\u2019s spinning might prevent the first thread from running and releasing the lock. Yielding while holding a lock would also violate the requirement that interrupts must be off while a spinlock is held. Thus we\u2019d like a type of lock that yields the CPU while waiting to acquire, and allows yields (and interrupts) while the lock is held.</p> <p>Xv6 provides such locks in the form of sleep-locks. <code>acquiresleep</code> (kernel/sleeplock.c:22) yields the CPU while waiting, using techniques that will be explained in Chapter 7. At a high level, a sleep-lock has a locked field that is protected by a spinlock, and <code>acquiresleep</code> \u2019s call to sleep atomically yields the CPU and releases the spinlock. The result is that other threads can execute while <code>acquiresleep</code> waits.</p> <pre><code>void\nacquiresleep(struct sleeplock *lk)\n{\n  acquire(&amp;lk-&gt;lk);\n  while (lk-&gt;locked) {\n    sleep(lk, &amp;lk-&gt;lk);\n  }\n  lk-&gt;locked = 1;\n  lk-&gt;pid = myproc()-&gt;pid;\n  release(&amp;lk-&gt;lk);\n}\n</code></pre> <p>Because sleep-locks leave interrupts enabled, they cannot be used in interrupt handlers. Because <code>acquiresleep</code> may yield the CPU, sleep-locks cannot be used inside spinlock critical sections (though spinlocks can be used inside sleep-lock critical sections). Spin-locks are best suited to short critical sections, since waiting for them wastes CPU time; sleep-locks work well for lengthy operations.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#chapter-7-scheduling","title":"Chapter 7 Scheduling","text":"<p>Any operating system is likely to run with more processes than the computer has CPUs, so a plan is needed to time-share the CPUs among the processes. Ideally the sharing would be transparent to user processes. A common approach is to provide each process with the illusion that it has its own virtual CPU by multiplexing the processes onto the hardware CPUs. This chapter explains how xv6 achieves this multiplexing.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#71-multiplexing","title":"7.1 Multiplexing","text":"<p>xv6\u5728\u4e24\u79cd\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u5bf9CPU\u7684\u590d\u7528</p> <ol> <li>sleep\u548cwakeup\u673a\u5236</li> <li>timer\u65f6\u95f4\u7247\u673a\u5236</li> </ol> <p>\u5173\u4e8exv6\u7684\u7ebf\u7a0b\u95ee\u9898</p> <p>xv6\u5e76\u6ca1\u6709\u5b9e\u73b0\u7528\u6237\u7ea7\u522b\u7684\u591a\u7ebf\u7a0b\uff0cxv6\u7684\u6bcf\u4e2aprocess\u53ef\u4ee5\u88ab\u770b\u505a\u6709\u4e24\u4e2a\u7ebf\u7a0b\uff0c\u4e00\u4e2a\u662f\u5185\u6838\u7ebf\u7a0b\uff0c\u53e6\u4e00\u4e2a\u662f\u7528\u6237\u7ebf\u7a0b\u3002\u7ebf\u7a0b\u95f4\u7684context\u5207\u6362\u4e5f\u53ea\u662f\u9488\u5bf9kernel thread\u3002</p> <p>Xv6 multiplexes by switching each CPU from one process to another in two situations.</p> <ul> <li> <p>First, xv6\u2019s sleep and wakeup mechanism switches when a process waits for device or pipe I/O to complete, or waits for a child to exit, or waits in the sleep system call.</p> </li> <li> <p>Second, xv6 periodically forces a switch to cope with processes that compute for long periods without sleeping. This multiplexing creates the illusion that each process has its own CPU, just as xv6 uses the memory allocator and hardware page tables to create the illusion that each process has its own memory.</p> </li> </ul> <p>Implementing multiplexing poses a few challenges.</p> <ul> <li>First, how to switch from one process to another? Although the idea of context switching is simple, the implementation is some of the most opaque code in xv6.</li> <li>Second, how to force switches in a way that is transparent to user processes? Xv6 uses the standard technique of driving context switches with timer interrupts.</li> <li>Third, many CPUs may be switching among processes concurrently, and a locking plan is necessary to avoid races.</li> <li>Fourth, a process\u2019s memory and other resources must be freed when the process exits, but it cannot do all of this itself because (for example) it can\u2019t free its own kernel stack while still using it.</li> <li>Fifth, each core of a multi-core machine must remember which process it is executing so that system calls affect the correct process\u2019s kernel state.</li> <li>Finally, sleep and wakeup allow a process to give up the CPU and sleep waiting for an event, and allows another process to wake the first process up. Care is needed to avoid races that result in the loss of wakeup notifications. Xv6 tries to solve these problems as simply as possible, but nevertheless the resulting code is tricky.</li> </ul> <p></p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#72-code-context-switching","title":"7.2 Code: Context switching","text":"<p>Figure 7.1 outlines the steps involved in switching from one user process to another:</p> <p>\u8fd9\u91cc\u4ee5timer\u4e2d\u65ad\u673a\u5236\u89e6\u53d1scheduling\u4e3a\u4f8b</p> <ol> <li><code>\u8fdb\u7a0bA</code>\u6536\u5230\u65f6\u95f4\u4e2d\u65ad\uff0c\u4ece\u800c\u8fdb\u5165\u8be5\u8fdb\u7a0b\u7684kernel\u7ebf\u7a0b</li> <li><code>\u8fdb\u7a0bA\u7684\u5185\u6838\u7ebf\u7a0b</code>\u4fdd\u5b58\u5f53\u524d\u7684\u5bc4\u5b58\u5668\u503c\u5230p-&gt;context</li> <li><code>\u8fdb\u7a0bA\u7684\u5185\u6838\u7ebf\u7a0b</code>\u5c06\u5bc4\u5b58\u5668\u6062\u590d\u5230CPU\u7684scheduler\u7ebf\u7a0b\u5207\u6362\u524d\u7684\u72b6\u6001</li> <li><code>CPU\u7684scheduler\u7ebf\u7a0b</code>\u5bfb\u627e\u5230\u4e0b\u4e00\u4e2a<code>RUNNABLE</code>\u8fdb\u7a0bB\uff0c\u627e\u5230\u540e\u5c06\u5f53\u524d\u5bc4\u5b58\u5668\u4e2d\u7684\u503c\u4fdd\u5b58\u5230<code>cpu-&gt;context</code>\uff0c \u5c06\u5bc4\u5b58\u5668\u4e2d\u7684\u503c\u6062\u590d\u4e3a\u8fdb\u7a0bB\u4e2d\u4fdd\u5b58\u7684<code>p-&gt;context</code></li> <li><code>\u8fdb\u7a0bB</code>\u4e00\u8defreturn\u56de\u5230\u8fdb\u7a0bB\u7684user space\u7136\u540e\u7ee7\u7eed\u6267\u884c<code>\u8fdb\u7a0bB\u7684\u7528\u6237\u7ebf\u7a0b</code></li> </ol> <ul> <li> <p>a user-kernel transition (system call or interrupt) to the old process\u2019s kernel thread,</p> </li> <li> <p>a context switch to the current CPU\u2019s scheduler thread,</p> </li> <li> <p>a context switch to a new process\u2019s kernel thread, and</p> </li> <li> <p>a trap return to the user-level process.</p> </li> </ul> <p>\u6bcf\u4e2aCPU\u90fd\u6709\u4e00\u4e2ascheduler thread\uff0c\u4ed6\u6709\u7740\u81ea\u5df1\u72ec\u7acb\u7684\u6808\u548c\u4e00\u4e9b\u76f8\u5e94\u7684\u5bc4\u5b58\u5668\u503c\u3002xv6\u7684\u8fdb\u7a0b\u5207\u6362\u662f\u901a\u8fc7CPU\u8c03\u5ea6\u7ebf\u7a0b\u5b8c\u6210\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4</p> <p>process A -&gt; scheduler -&gt; process B</p> <p>\u6bcf\u4e2ascheduler thread\u662f\u62e5\u6709\u81ea\u5df1\u7684\u72ec\u7acb\u6808\u7684\uff0c\u8fd9\u4e9b\u6808\u5728<code>start.c</code>\u4e2d\u88ab\u8bbe\u7f6e\u3002\u8fd9\u6837\u8bbe\u8ba1\u7684\u539f\u56e0\u8981\u901a\u8fc7\u4ee3\u7801\u7406\u89e3\u3002</p> <p>The xv6 scheduler has a dedicated thread (saved registers and stack) per CPU because it is not safe for the scheduler execute on the old process\u2019s kernel stack: some other core might wake the process up and run it, and it would be a disaster to use the same stack on two different cores. In this section we\u2019ll examine the mechanics of switching between a kernel thread and a scheduler thread.</p> <p><code>switch context\uff08\u4e0a\u4e0b\u6587\u5207\u6362\uff09</code>\u8fd9\u4e2a\u672f\u8bed\u4e00\u822c\u7528\u4e8e\u5185\u6838\u53d1\u751f\u7684\u7ebf\u7a0b\u8c03\u5ea6\uff0c\u8fd9\u91cc\u8fd9\u6837\u8bf4\u660e\u662f\u56e0\u4e3auser trap\u8fdb\u5165\u5185\u6838\u524d\u5c06\u4e3b\u8981\u7684\u5bc4\u5b58\u5668\u4fdd\u5b58\u5230<code>trapframe</code>\u4e2d\u7684\u884c\u4e3a\u4e5f\u53ef\u4ee5\u88ab\u770b\u4f5c\u662f\u4e00\u79cdcontext\u7684\u5207\u6362\u3002</p> <p>\u7ebf\u7a0b\u8c03\u5ea6\u7684\u6838\u5fc3\u51fd\u6570\u5c31\u662f<code>swtch()</code>\u4e86\uff0c\u4ed6\u6240\u505a\u7684\u4e8b\u5c31\u662f\u4fdd\u5b58\u5f53\u524d\u7684\u5bc4\u5b58\u5668\u4e2d\u7684\u503c\uff0c\u7136\u540e\u628a\u5bc4\u5b58\u5668\u4e2d\u7684\u503c\u8bbe\u7f6e\u4e3aCPU\u8c03\u5ea6\u5668\u7684\u4e0a\u4e0b\u6587\u3002\u4e4b\u540e\u5c06\u8be6\u7ec6\u89e3\u91ca\u3002</p> <p>context\u662f\u4ec0\u4e48\uff1f\u5176\u5b9e\u672c\u8d28\u5c31\u662f\u4e00\u4e9b<code>callee saved</code>register\u548c<code>ra, sp</code>\u5bc4\u5b58\u5668\u3002\u4e3a\u4ec0\u4e48\u662f\u4ed6\u4eec\u5462\uff0c\u4e4b\u540e\u4f1a\u89e3\u91ca\u3002</p> <p>Switching from one thread to another involves saving the old thread\u2019s CPU registers, and restoring the previously-saved registers of the new thread; the fact that the stack pointer and program counter are saved and restored means that the CPU will switch stacks and switch what code it is executing.</p> <p>The function <code>swtch</code> performs the saves and restores for a kernel thread switch. <code>swtch</code> doesn\u2019t directly know about threads; it just saves and restores register sets, called <code>contexts</code>.</p> <p>When it is time for a process to give up the CPU, the process\u2019s kernel thread calls <code>swtch</code> to save its own context and return to the scheduler context. Each context is contained in a <code>struct context</code> (kernel/proc.h:2), itself contained in a process\u2019s struct proc or a CPU\u2019s <code>struct cpu</code>. <code>Swtch</code> takes two arguments: <code>struct context *old</code> and <code>struct context *new</code>. It saves the current registers in old, loads registers from new, and returns.</p> <pre><code>struct context {\n  uint64 ra;\n  uint64 sp;\n\n  // callee-saved\n  uint64 s0;\n  uint64 s1;\n  uint64 s2;\n  uint64 s3;\n  uint64 s4;\n  uint64 s5;\n  uint64 s6;\n  uint64 s7;\n  uint64 s8;\n  uint64 s9;\n  uint64 s10;\n  uint64 s11;\n};\n\n// Per-CPU state.\nstruct cpu {\n  struct proc *proc;          // The process running on this cpu, or null.\n  struct context context;     // swtch() here to enter scheduler().\n  int noff;                   // Depth of push_off() nesting.\n  int intena;                 // Were interrupts enabled before push_off()?\n};\n</code></pre> <p>Let\u2019s follow a process through <code>swtch</code> into the scheduler. We saw in Chapter 4 that one possibility at the end of an interrupt is that <code>usertrap</code> calls <code>yield</code>. <code>Yield</code> in turn calls <code>sched</code>, which calls <code>swtch</code> to save the current context in p-&gt;context and switch to the scheduler context previously saved in <code>cpu-&gt;scheduler</code> (kernel/proc.c:509).</p> <p>\u8fd9\u91cc\u4ee5timer interrupt\u4e3a\u4f8b\u5b50\uff0c\u6982\u8ff0\u4e86\u6574\u4e2a\u51fd\u6570\u8c03\u7528\u7684\u8fc7\u7a0b</p> <p><code>process A kernel thread: usertrap() -&gt; yield() -&gt; sched() -&gt; swtch()</code></p> <p><code>CPU scheduler thread(process A\u662f\u901a\u8fc7\u5b83\u88ab\u8c03\u5ea6\u6267\u884c\u7684): swtch() return -&gt; scheduler() for loop -&gt; find process B -&gt; swtch()</code></p> <p><code>process B kernel thread: swtch() return -&gt; sched() return -&gt; yield() return -&gt; usertrap()</code></p> <p><code>sched()</code>\u51fd\u6570\u4e3b\u8981\u7528\u6765\u5bf9<code>yield()</code>\u8fdb\u884c\u4e8c\u6b21\u68c0\u67e5</p> <pre><code>// Give up the CPU for one scheduling round.\nvoid\nyield(void)\n{\n  struct proc *p = myproc();\n  acquire(&amp;p-&gt;lock);\n  p-&gt;state = RUNNABLE;\n  sched();\n  release(&amp;p-&gt;lock);\n}\n\n// Switch to scheduler.  Must hold only p-&gt;lock\n// and have changed proc-&gt;state. Saves and restores\n// intena because intena is a property of this\n// kernel thread, not this CPU. It should\n// be proc-&gt;intena and proc-&gt;noff, but that would\n// break in the few places where a lock is held but\n// there's no process.\nvoid\nsched(void)\n{\n  int intena;\n  struct proc *p = myproc();\n\n  if(!holding(&amp;p-&gt;lock))\n    panic(\"sched p-&gt;lock\");\n  if(mycpu()-&gt;noff != 1)\n    panic(\"sched locks\");\n  if(p-&gt;state == RUNNING)\n    panic(\"sched running\");\n  if(intr_get())\n    panic(\"sched interruptible\");\n\n  intena = mycpu()-&gt;intena;\n  swtch(&amp;p-&gt;context, &amp;mycpu()-&gt;context);\n  mycpu()-&gt;intena = intena;\n}\n</code></pre> <p><code>Swtch</code> (kernel/swtch.S:3) saves only <code>callee-saved</code> registers; caller-saved registers are saved on the stack (if needed) by the calling C code. <code>Swtch</code> knows the offset of each register\u2019s field in struct context.</p> <p>It does not save the program counter. Instead, <code>swtch</code> saves the <code>ra</code> register, which holds the return address from which <code>swtch</code> was called. Now <code>swtch</code> restores registers from the new context, which holds register values saved by a previous <code>swtch</code>. When <code>swtch</code> returns, it returns to the instructions pointed to by the restored <code>ra</code> register, that is, the instruction from which the new thread previously called <code>swtch</code>.</p> <p>In addition, it returns on the new thread\u2019s stack.</p> <p><code>swtch()</code>\u7684\u4ee3\u7801\u975e\u5e38\u7b80\u5355\uff0c\u5c31\u662f\u7b80\u5355\u7684store\u548crestore\u3002</p> <p>\u8fd9\u91cc\u9700\u8981\u7559\u610f\u7684\u662f\uff0c\u6211\u4eec\u5728\u4e0a\u4e0b\u6587\u5207\u6362\u65f6\u4ec5\u4ec5\u4fdd\u5b58\u4e86<code>callee saved</code>\u5bc4\u5b58\u5668\uff0c\u8fd9\u4e9b\u5bc4\u5b58\u5668\u7684\u7279\u70b9\u5c31\u662f\u4ed6\u4eec\u4f1a\u88ab\u88ab\u8c03\u7528\u51fd\u6570\u7684\u6808\u5e27\u4fdd\u5b58\uff0c\u56e0\u4e3a\u88ab\u8c03\u7528\u51fd\u6570\u4f1a\u7ee7\u7eed\u7528\u4ed6\u4eec\u6267\u884c\u81ea\u5df1\u7684\u4efb\u52a1\uff0c\u8fd9\u6837\u5f53\u88ab\u8c03\u7528\u51fd\u6570\u8fd4\u56de\u65f6\uff0c\u8fd9\u4e9b\u5bc4\u5b58\u5668\u5c31\u4f1a\u6062\u590d\u4ed6\u4eec\u5728\u8c03\u7528\u8005\u90a3\u65f6\u7684\u72b6\u6001\u3002\u7136\u800c\uff0c<code>swtch()</code>\u51fd\u6570\u4e0d\u4f1a\u518d\u6709<code>callee</code>\u6765\u4e3a\u5b83\u4fdd\u5b58\u8fd9\u4e9b\u5bc4\u5b58\u5668\u4e86\uff0c\u6240\u4ee5\u6211\u4eec\u8fd9\u91cc\u53ea\u4fdd\u5b58<code>callee saved</code>\u3002</p> <p>\u53e6\u4e00\u70b9\u9700\u8981\u7559\u610f\u7684\u5c31\u662f\u6211\u4eec\u53ea\u4fdd\u5b58\u548c\u6062\u590d\u4e86<code>ra \u548c sp</code>\u3002<code>sp</code>\u5f88\u597d\u7406\u89e3\uff0c\u6bcf\u4e2a\u7ebf\u7a0b\u90fd\u6709\u81ea\u5df1\u72ec\u7acb\u7684\u6808\uff1b<code>ra</code>\u6307\u7684\u662freturn address\uff0c\u5f53\u4e0b\u8fb9\u7684\u6c47\u7f16\u4ee3\u7801\u6267\u884c\u5230ret\u65f6\uff0c\u6211\u4eec\u7684pc\u5c31\u4f1a\u6307\u5411<code>ra</code>\u4e2d\u7684\u5730\u5740, \u6240\u4ee5\u5728\u8fd9\u91cc\u8bbe\u7f6epc\u7684\u503c\u662f\u6ca1\u6709\u5fc5\u8981\u7684\u3002</p> <pre><code>## Context switch\n##\n##   void swtch(struct context *old, struct context *new);\n##\n## Save current registers in old. Load from new.\n\n\n.globl swtch\nswtch:\n        sd ra, 0(a0)\n        sd sp, 8(a0)\n        sd s0, 16(a0)\n        sd s1, 24(a0)\n        sd s2, 32(a0)\n        sd s3, 40(a0)\n        sd s4, 48(a0)\n        sd s5, 56(a0)\n        sd s6, 64(a0)\n        sd s7, 72(a0)\n        sd s8, 80(a0)\n        sd s9, 88(a0)\n        sd s10, 96(a0)\n        sd s11, 104(a0)\n\n        ld ra, 0(a1)\n        ld sp, 8(a1)\n        ld s0, 16(a1)\n        ld s1, 24(a1)\n        ld s2, 32(a1)\n        ld s3, 40(a1)\n        ld s4, 48(a1)\n        ld s5, 56(a1)\n        ld s6, 64(a1)\n        ld s7, 72(a1)\n        ld s8, 80(a1)\n        ld s9, 88(a1)\n        ld s10, 96(a1)\n        ld s11, 104(a1)\n\n        ret\n</code></pre> <p>\u9700\u8981\u518d\u5f3a\u8c03\u4e00\u6b21\uff0c\u7ebf\u7a0b\u7684\u5207\u6362\u662f\u8981\u7ecf\u8fc7CPU scheduler\u7ebf\u7a0b\u7684\u3002</p> <p>In our example, <code>sched</code> called <code>swtch</code> to switch to <code>cpu-&gt;scheduler</code>, the per-CPU scheduler context. That context had been saved by scheduler\u2019s call to <code>swtch</code> (kernel/proc.c:475). When the <code>swtch</code> we have been tracing returns, it returns not to <code>sched</code> but to scheduler, and its stack pointer points at the current CPU\u2019s scheduler stack.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#73-code-scheduling","title":"7.3 Code: Scheduling","text":"<p>The last section looked at the low-level details of <code>swtch</code>; now let\u2019s take <code>swtch</code> as a given and examine switching from one process\u2019s kernel thread through the scheduler to another process. The scheduler exists in the form of a special thread per CPU, each running the scheduler function. This function is in charge of choosing which process to run next.</p> <pre><code>// Per-CPU process scheduler.\n// Each CPU calls scheduler() after setting itself up.\n// Scheduler never returns.  It loops, doing:\n//  - choose a process to run.\n//  - swtch to start running that process.\n//  - eventually that process transfers control\n//    via swtch back to the scheduler.\nvoid\nscheduler(void)\n{\n  struct proc *p;\n  struct cpu *c = mycpu();\n\n  c-&gt;proc = 0;\n  for(;;){\n    // Avoid deadlock by ensuring that devices can interrupt.\n    intr_on();\n\n    for(p = proc; p &lt; &amp;proc[NPROC]; p++) {\n      acquire(&amp;p-&gt;lock);\n      if(p-&gt;state == RUNNABLE) {\n        // Switch to chosen process.  It is the process's job\n        // to release its lock and then reacquire it\n        // before jumping back to us.\n        p-&gt;state = RUNNING;\n        c-&gt;proc = p;\n        swtch(&amp;c-&gt;context, &amp;p-&gt;context);\n\n        // Process is done running for now.\n        // It should have changed its p-&gt;state before coming back.\n        c-&gt;proc = 0;\n      }\n      release(&amp;p-&gt;lock);\n    }\n  }\n}\n</code></pre> <p>A process that wants to give up the CPU must acquire its own process lock p-&gt;lock, release any other locks it is holding, update its own state (p-&gt;state), and then call <code>sched</code>. Yield (kernel/proc.c:515) follows this convention, as do sleep and exit, which we will examine later. Sched double-checks those conditions (kernel/proc.c:499-504) and then an implication of those conditions: since a lock is held, interrupts should be disabled. Finally, <code>sched</code> calls <code>swtch</code> to save the current context in p-&gt;context and switch to the scheduler context in <code>cpu-&gt;scheduler</code>. <code>Swtch</code> returns on the scheduler\u2019s stack as though scheduler\u2019s <code>swtch</code> had returned. The scheduler continues the for loop, finds a process to run, switches to it, and the cycle repeats.</p> <pre><code>// Give up the CPU for one scheduling round.\nvoid\nyield(void)\n{\n  struct proc *p = myproc();\n  acquire(&amp;p-&gt;lock);\n  p-&gt;state = RUNNABLE;\n  sched();\n  release(&amp;p-&gt;lock);\n}\n\n// Switch to scheduler.  Must hold only p-&gt;lock\n// and have changed proc-&gt;state. Saves and restores\n// intena because intena is a property of this\n// kernel thread, not this CPU. It should\n// be proc-&gt;intena and proc-&gt;noff, but that would\n// break in the few places where a lock is held but\n// there's no process.\nvoid\nsched(void)\n{\n  int intena;\n  struct proc *p = myproc();\n\n  if(!holding(&amp;p-&gt;lock))\n    panic(\"sched p-&gt;lock\");\n  if(mycpu()-&gt;noff != 1)\n    panic(\"sched locks\");\n  if(p-&gt;state == RUNNING)\n    panic(\"sched running\");\n  if(intr_get())\n    panic(\"sched interruptible\");\n\n  intena = mycpu()-&gt;intena;\n  swtch(&amp;p-&gt;context, &amp;mycpu()-&gt;context);\n  mycpu()-&gt;intena = intena;\n}\n</code></pre> <p>We just saw that xv6 holds p-&gt;lock across calls to <code>swtch</code>: the caller of <code>swtch</code> must already hold the lock, and control of the lock passes to the switched-to code. This convention is unusual with locks; usually the thread that acquires a lock is also responsible for releasing the lock, which makes it easier to reason about correctness.</p> <p>For context switching it is necessary to break this convention because p-&gt;lock protects invariants on the process\u2019s state and context fields that are not true while executing in <code>swtch</code>. One example of a problem that could arise if p-&gt;lock were not held during <code>swtch</code>: a different CPU might decide to run the process after yield had set its state to RUNNABLE, but before <code>swtch</code> caused it to stop using its own kernel stack. The result would be two CPUs running on the same stack, which cannot be right.</p> <p>\u4e0b\u56fe\u5bf9\u6574\u4e2a\u8c03\u5ea6\u7684\u8fc7\u7a0b\u8fdb\u884c\u4e86\u6c47\u603b\uff0c\u8fd9\u91cc\u5bf9\u9501\u7684\u4f7f\u7528\u662f\u5341\u5206\u5de7\u5999\u5730\uff0c\u4e3a\u4e86\u907f\u514d\u4e0a\u8ff0\u53ef\u80fd\u53d1\u751f\u7684\u60c5\u51b5\u3002\u6211\u4eec\u53ef\u4ee5\u770b\u5230\uff0cprocess A\u5728yield\u4e2d\u83b7\u5f97\u9501\uff0c\u5728\u8fdb\u5165scheduler\u7ebf\u7a0b\u4e2d\u65f6\u91ca\u653e\u4e86\u9501\uff0c\u8fd9\u6837\u4fdd\u8bc1\u4e86\u5207\u6362\u5230\u8c03\u5ea6\u8fdb\u7a0b\u7684\u539f\u5b50\u6027\u3002\u4e4b\u540eCPU\u7ebf\u7a0b\u5c31\u4f1a\u7ee7\u7eedfor\u5faa\u73af\uff0c\u76f4\u5230\u627e\u5230\u4e86\u65b0\u7684\u8fdb\u7a0bprocess B\uff0cscheduler\u7ebf\u7a0b\u7ed9\u8fdb\u7a0bB\u4e0a\u4e86\u9501\uff0c\u5728yield\u4e2d\u91ca\u653e\u4e86\u9501\uff0c\u8fd9\u6837\u4fdd\u8bc1\u4e86\u5207\u6362\u5230\u65b0\u7ebf\u7a0b\u7684\u539f\u5b50\u6027\u3002</p> <p>\u901a\u8fc7\u4e0b\u56fe\uff0c<code>p-&gt;context</code>\u548c<code>c-&gt;context</code>\u4e4b\u4e2d\u4fdd\u5b58\u4e86\u4ec0\u4e48\u4e5f\u5c31\u6e05\u6670\u4e86\u3002process A\u5728<code>swtch()</code>\u65f6\u5c06\u5f53\u524d\u5bc4\u5b58\u5668\u7684\u76f8\u5173\u503c\u4fdd\u5b58\u5230\u4e86<code>p-&gt;context</code>, \u8fd9\u65f6<code>cpu-&gt;context</code>\u4e2d\u5b58\u50a8\u7684\u662fscheduler\u7ebf\u7a0b\u8fdb\u884c\u627e\u5230process A\u540e\u6267\u884c<code>swtch()</code>\u65f6\u5bc4\u5b58\u5668\u7684\u72b6\u6001\uff0c<code>cpu-&gt;context</code>\u4f1a\u88abrestore\u5230\u5bc4\u5b58\u5668\u4e2d\uff0c\u4ece\u800c\u6211\u4eec\u5c31\u56de\u5230\u4e86scheduler\u7ebf\u7a0b\u3002</p> <p>scheduler\u7ebf\u7a0b\u901a\u8fc7for\u5faa\u73af\u627e\u5230\u7684\u65b0\u7684\u8fdb\u7a0bprocess B\uff0c\u53c8\u5c06<code>swtch()</code>\u65f6\u7684context\u4fdd\u5b58\u5230<code>cpu-&gt;context</code>\uff0c\u7136\u540e\u5c06process B\u4e2d\u4e4b\u524d\u4fdd\u5b58\u7684<code>p-&gt;context</code>restore\u5230\u5bc4\u5b58\u5668\u4e2d\uff0c\u63a5\u7740\u6211\u4eec\u5c31\u5207\u6362\u5230\u4e86process B\u7684\u5185\u6838\u7ebf\u7a0b\u4e2d\u3002</p> <p></p> <p>A kernel thread always gives up its CPU in <code>sched</code> and always switches to the same location in the scheduler, which (almost) always switches to some kernel thread that previously called <code>sched</code>. Thus, if one were to print out the line numbers where xv6 switches threads, one would observe the following simple pattern: (kernel/proc.c:475), (kernel/proc.c:509), (kernel/proc.c:475), (kernel/proc.c:509), and so on. The procedures in which this stylized switching between two threads happens are sometimes referred to as <code>coroutines</code>; in this example, <code>sched</code> and <code>scheduler</code> are co-routines of each other.</p> <p>\u53ef\u4ee5\u770b\u51fa\uff0c\u5185\u6838\u7ebf\u7a0b\u95f4\u7684\u5207\u6362\u7684\u51fd\u6570\u8c03\u7528\u90fd\u662f<code>sched</code> and <code>scheduler</code>\u4ea4\u66ff\u7740\u8fdb\u884c\u7684\uff0c\u4ed6\u4eec\u53ef\u4ee5\u88ab\u79f0\u4e3a<code>coroutines</code></p> <p>\u4e0a\u56fe\u4e5f\u76f8\u5e94\u7684\u5f15\u51fa\u4e86\u4e00\u4e2a\u95ee\u9898\uff0c\u770b\u4e0a\u53bb\u8fdb\u7a0b\u4e4b\u95f4\u90fd\u662f\u5728\u4e0d\u505c\u7684\u4ea4\u6362context\uff0c\u90a3\u4e48\u4e00\u5f00\u59cb\u8fd9\u4e9bprocess\u4e2d\u7684context\u662f\u54ea\u91cc\u6765\u7684\u5462\uff1f\u4e0b\u9762\u7684\u5185\u5bb9\u89e3\u7b54\u4e86\u8fd9\u4e00\u95ee\u9898\u3002</p> <p>\u53ef\u4ee5\u770b\u5230<code>allocproc</code>\u5728\u4e00\u5f00\u59cb\u521d\u59cb\u5316\u6bcf\u4e00\u4e2a<code>proc</code>\u7684\u65f6\u5019\uff0c\u5c31\u9884\u5148\u5c06\u4ed6\u4eec\u7684context\u4e2d\u7684\u8fd4\u56de\u5730\u5740\u8bbe\u4e3a\u4e86<code>forkret</code>, \u8fd9\u91cc\u6709\u4e00\u4e2a\u5047\u7684<code>usertrapret</code>\u8ba9\u65b0\u7684\u8fdb\u7a0b\u53ef\u4ee5\u8fd4\u56de\u7528\u6237\u7a7a\u95f4\u6267\u884c\u4ed6\u7684\u7528\u6237\u7ebf\u7a0b\u3002</p> <p>There is one case when the scheduler\u2019s call to <code>swtch</code> does not end up in <code>sched</code>. When a new process is first scheduled, it begins at <code>forkret</code> (kernel/proc.c:527). <code>Forkret</code> exists to release the p-&gt;lock; otherwise, the new process could start at <code>usertrapret</code>.</p> <pre><code>// A fork child's very first scheduling by scheduler()\n// will swtch to forkret.\nvoid\nforkret(void)\n{\n  static int first = 1;\n\n  // Still holding p-&gt;lock from scheduler.\n  release(&amp;myproc()-&gt;lock);\n\n  if (first) {\n    // File system initialization must be run in the context of a\n    // regular process (e.g., because it calls sleep), and thus cannot\n    // be run from main().\n    first = 0;\n    fsinit(ROOTDEV);\n  }\n\n  usertrapret();\n}\n\n// Look in the process table for an UNUSED proc.\n// If found, initialize state required to run in the kernel,\n// and return with p-&gt;lock held.\n// If there are no free procs, or a memory allocation fails, return 0.\nstatic struct proc*\nallocproc(void)\n{\n  struct proc *p;\n\n ...................\n\nfound:\n  p-&gt;pid = allocpid();\n  p-&gt;state = USED;\n\n  // Allocate a trapframe page.\n    ................\n  // An empty user page table.\n    ................\n  // Set up new context to start executing at forkret,\n  // which returns to user space.\n  memset(&amp;p-&gt;context, 0, sizeof(p-&gt;context));\n  p-&gt;context.ra = (uint64)forkret;\n  p-&gt;context.sp = p-&gt;kstack + PGSIZE;\n\n  return p;\n}\n</code></pre> <p>Scheduler (kernel/proc.c:457) runs a simple loop: find a process to run, run it until it yields, repeat. The scheduler loops over the process table looking for a runnable process, one that has p-&gt;state == RUNNABLE. Once it finds a process, it sets the per-CPU current process variable c-&gt;proc, marks the process as RUNNING, and then calls <code>swtch</code> to start running it (kernel/proc.c:470- 475).</p> <pre><code>// Per-CPU process scheduler.\n// Each CPU calls scheduler() after setting itself up.\n// Scheduler never returns.  It loops, doing:\n//  - choose a process to run.\n//  - swtch to start running that process.\n//  - eventually that process transfers control\n//    via swtch back to the scheduler.\nvoid\nscheduler(void)\n{\n  struct proc *p;\n  struct cpu *c = mycpu();\n\n  c-&gt;proc = 0;\n  for(;;){\n    // Avoid deadlock by ensuring that devices can interrupt.\n    intr_on();\n\n    for(p = proc; p &lt; &amp;proc[NPROC]; p++) {\n      acquire(&amp;p-&gt;lock);\n      if(p-&gt;state == RUNNABLE) {\n        // Switch to chosen process.  It is the process's job\n        // to release its lock and then reacquire it\n        // before jumping back to us.\n        p-&gt;state = RUNNING;\n        c-&gt;proc = p;\n        swtch(&amp;c-&gt;context, &amp;p-&gt;context);\n\n        // Process is done running for now.\n        // It should have changed its p-&gt;state before coming back.\n        c-&gt;proc = 0;\n      }\n      release(&amp;p-&gt;lock);\n    }\n  }\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#locks-in-scheduling-code","title":"Locks in scheduling code","text":"<p>One way to think about the structure of the scheduling code is that it enforces a set of invariants about each process, and holds p-&gt;lock whenever those invariants are not true. One invariant is that if a process is RUNNING, a timer interrupt\u2019s yield must be able to safely switch away from the process; this means that the CPU registers must hold the process\u2019s register values (i.e. <code>swtch</code> hasn\u2019t moved them to a context), and c-&gt;proc must refer to the process. Another invariant is that if a process is RUNNABLE, it must be safe for an idle CPU\u2019s scheduler to run it; this means that p-&gt;context must hold the process\u2019s registers (i.e., they are not actually in the real registers), that no CPU is executing on the process\u2019s kernel stack, and that no CPU\u2019s c-&gt;proc refers to the process. Observe that these properties are often not true while p-&gt;lock is held.</p> <p>Maintaining the above invariants is the reason why xv6 often acquires p-&gt;lock in one thread and releases it in other, for example acquiring in yield and releasing in scheduler. Once yield has started to modify a running process\u2019s state to make it RUNNABLE, the lock must remain held until the invariants are restored: the earliest correct release point is after scheduler (running on its own stack) clears c-&gt;proc. Similarly, once scheduler starts to convert a RUNNABLE process to RUNNING, the lock cannot be released until the kernel thread is completely running (after the <code>swtch</code>, for example in yield).</p> <p>p-&gt;lock protects other things as well: the interplay between exit and wait, the machinery to avoid lost wakeups (see Section 7.5), and avoidance of races between a process exiting and other processes reading or writing its state (e.g., the exit system call looking at <code>p-&gt;pid</code> and setting <code>p-&gt;killed</code> (kernel/proc.c:611)). It might be worth thinking about whether the different functions of p-&gt;lock could be split up, for clarity and perhaps for performance.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#74-code-mycpu-and-myproc","title":"7.4 Code: <code>mycpu</code> and <code>myproc</code>","text":"<p>Xv6 often needs a pointer to the current process\u2019s proc structure. On a uniprocessor one could have a global variable pointing to the current proc. This doesn\u2019t work on a multi-core machine, since each core executes a different process. The way to solve this problem is to exploit the fact that each core has its own set of registers; we can use one of those registers to help find per-core information.</p> <p>Xv6 maintains a struct <code>cpu</code> for each CPU (kernel/proc.h:22), which records the process currently running on that CPU (if any), saved registers for the CPU\u2019s scheduler thread, and the count of nested spinlocks needed to manage interrupt disabling. The function <code>mycpu</code> (kernel/proc.c:60) returns a pointer to the current CPU\u2019s struct <code>cpu</code>. RISC-V numbers its CPUs, giving each a <code>hartid</code>. Xv6 ensures that each CPU\u2019s <code>hartid</code> is stored in that CPU\u2019s <code>tp</code> register while in the kernel. This allows <code>mycpu</code> to use tp to index an array of <code>cpu</code> structures to find the right one.</p> <pre><code>// Return this CPU's cpu struct.\n// Interrupts must be disabled.\nstruct cpu*\nmycpu(void) {\n  int id = cpuid();\n  struct cpu *c = &amp;cpus[id];\n  return c;\n}\n\n// Must be called with interrupts disabled,\n// to prevent race with process being moved\n// to a different CPU.\nint\ncpuid()\n{\n  int id = r_tp();\n  return id;\n}\n\n// read and write tp, the thread pointer, which holds\n// this core's hartid (core number), the index into cpus[].\nstatic inline uint64\nr_tp()\n{\n  uint64 x;\n  asm volatile(\"mv %0, tp\" : \"=r\" (x) );\n  return x;\n}\n</code></pre> <p>Ensuring that a CPU\u2019s tp always holds the CPU\u2019s <code>hartid</code> is a little involved. <code>mstart</code> sets the tp register early in the CPU\u2019s boot sequence, while still in machine mode (kernel/start.c:46). <code>usertrapret</code> saves tp in the trampoline page, because the user process might modify tp. Finally, <code>uservec</code> restores that saved tp when entering the kernel from user space (kernel/trampoline.S:70). The compiler guarantees never to use the tp register. It would be more convenient if RISC-V allowed xv6 to read the current <code>hartid</code> directly, but that is allowed only in machine mode, not in supervisor mode.</p> <p>The return values of <code>cpuid</code> and <code>mycpu</code> are fragile: if the timer were to interrupt and cause the thread to yield and then move to a different CPU, a previously returned value would no longer be correct. To avoid this problem, xv6 requires that callers disable interrupts, and only enable them after they finish using the returned struct <code>cpu</code>.</p> <pre><code>void\nstart()\n{\n  // set M Previous Privilege mode to Supervisor, for mret.\n\n  // set M Exception Program Counter to main, for mret.\n  // requires gcc -mcmodel=medany\n\n  // disable paging for now.\n\n  // delegate all interrupts and exceptions to supervisor mode.\n\n  // configure Physical Memory Protection to give supervisor mode\n  // access to all of physical memory.\n\n  // ask for clock interrupts.\n  timerinit();\n\n  // keep each CPU's hartid in its tp register, for cpuid().\n  int id = r_mhartid();\n  w_tp(id);\n\n  // switch to supervisor mode and jump to main().\n  asm volatile(\"mret\");\n}\n</code></pre> <p>The function <code>myproc</code> (kernel/proc.c:68) returns the struct proc pointer for the process that is running on the current CPU. <code>myproc</code> disables interrupts, invokes <code>mycpu</code>, fetches the current process pointer (c-&gt;proc) out of the struct <code>cpu</code>, and then enables interrupts. The return value of <code>myproc</code> is safe to use even if interrupts are enabled: if a timer interrupt moves the calling process to a different CPU, its struct proc pointer will stay the same.</p> <pre><code>// Return the current struct proc *, or zero if none.\nstruct proc*\nmyproc(void) {\n  push_off();\n  struct cpu *c = mycpu();\n  struct proc *p = c-&gt;proc;\n  pop_off();\n  return p;\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#75-sleep-and-wakeup","title":"7.5 Sleep and wakeup","text":"<p>\u6709\u4e86\u8fdb\u7a0b\u8c03\u5ea6\u548c\u9501\uff0c\u4e3a\u4ec0\u4e48\u8fd8\u9700\u8981sleep\u548cwakeup\u5462\uff1f</p> <p>Scheduling and locks help conceal the existence of one process from another, but so far we have no abstractions that help processes intentionally interact. Many mechanisms have been invented to solve this problem. Xv6 uses one called sleep and wakeup, which allow one process to sleep waiting for an event and another process to wake it up once the event has happened. <code>Sleep</code> and <code>wakeup</code> are often called sequence coordination or conditional synchronization mechanisms.</p> <p>\u4e0b\u9762\u662f\u4e00\u4e2a\u4fe1\u53f7\u91cf\u7684\u4f8b\u5b50\u3002\u751f\u4ea7\u8005\u7ebf\u7a0b\u8c03\u7528V\u6765\u8ba9\u8ba9count\u589e\u52a0\uff0c\u6d88\u8d39\u8005\u7ebf\u7a0b\u8c03\u7528P\u4e00\u76f4\u76d1\u63a7\u7740count\uff0c\u4e00\u53d1\u73b0\u751f\u4ea7\u51fa\u4e1c\u897f\u5c31\u7acb\u523b\u6d88\u8d39\u3002\u7136\u800c\uff0c\u5982\u679c\u751f\u4ea7\u8005\u957f\u65f6\u95f4\u4e0d\u751f\u4ea7\uff0c\u90a3\u4e48\u6d88\u8d39\u8005\u7ebf\u7a0b\u4f1a\u4e00\u76f4\u5360\u7528CPU\uff0c\u6211\u4eec\u5e94\u8be5\u60f3\u529e\u6cd5\u8ba9\u6d88\u8d39\u8005\u5728\u7b49\u5f85\u7684\u8fd9\u6bb5\u65f6\u95f4\u8ba9\u51faCPU\u3002</p> <p>To illustrate, let\u2019s consider a synchronization mechanism called a semaphore(\u4fe1\u53f7) that coordinates producers and consumers. A semaphore maintains a count and provides two operations. The \u201cV\u201d operation (for the producer) increments the count. The \u201cP\u201d operation (for the consumer) waits until the count is non-zero, and then decrements it and returns. If there were only one producer thread and one consumer thread, and they executed on different CPUs, and the compiler didn\u2019t optimize too aggressively, this implementation would be correct:</p> <pre><code>struct semaphore {\n101 struct spinlock lock;\n102 int count;\n103 };\n104\n105 void\n106 V(struct semaphore *s)\n107 {\n108 acquire(&amp;s-&gt;lock);\n109 s-&gt;count += 1;\n110 release(&amp;s-&gt;lock);\n111 }\n112\n113 void\n114 P(struct semaphore *s)\n115 {\n116 while(s-&gt;count == 0)\n117 ;\n118 acquire(&amp;s-&gt;lock);\n119 s-&gt;count -= 1;\n120 release(&amp;s-&gt;lock);\n121 }\n</code></pre> <p>The implementation above is expensive. If the producer acts rarely, the consumer will spend most of its time spinning in the while loop hoping for a non-zero count. The consumer\u2019s CPU could find more productive work than with busy waiting by repeatedly polling s-&gt;count. Avoiding busy waiting requires a way for the consumer to yield the CPU and resume only after V increments the count.</p> <p>Here\u2019s a step in that direction, though as we will see it is not enough. Let\u2019s imagine a pair of calls, sleep and wakeup, that work as follows. Sleep(<code>chan</code>) sleeps on the arbitrary value <code>chan</code>, called the <code>wait channel</code>. <code>Sleep</code> puts the calling process to sleep, releasing the CPU for other work. <code>Wakeup(chan)</code>wakes all processes sleeping on<code>chan</code> (if any), causing their <code>sleep</code> calls to return. If no processes are waiting on <code>chan</code>, <code>wakeup</code> does nothing. We can change the semaphore implementation to use sleep and wakeup (changes highlighted in yellow):</p> <pre><code>200 void\n201 V(struct semaphore *s)\n202 {\n203 acquire(&amp;s-&gt;lock);\n204 s-&gt;count += 1;\n205 wakeup(s);//change\n206 release(&amp;s-&gt;lock);\n207 }\n208\n209 void\n210 P(struct semaphore *s)\n211 {\n212 while(s-&gt;count == 0)\n213     sleep(s);//change\n214 acquire(&amp;s-&gt;lock);\n215 s-&gt;count -= 1;\n216 release(&amp;s-&gt;lock);\n217 }\n</code></pre> <p>P now gives up the CPU instead of spinning, which is nice. However, it turns out not to be straightforward to design sleep and wakeup with this interface without suffering from what is known as the lost wake-up problem.</p> <p>\u8fd9\u79cd\u8bbe\u8ba1\u5e76\u4e0d\u5b8c\u7f8e\uff0c\u4ed6\u4f1a\u5e26\u6765**lost wake-up problem**\uff0c\u5177\u4f53\u7684\u60c5\u666f\u5c31\u662f\uff0c\u6d88\u8d39\u8005\u548c\u751f\u4ea7\u8005\u8fd0\u884c\u5728\u4e24\u4e2aCPU\u4e0a\uff0c\u5f53\u6d88\u8d39\u8005\u5904\u5728\u8fdb\u5165\u7761\u7720\u72b6\u6001\u7684\u8fc7\u7a0b\u4e2d\u65f6\uff0c\u751f\u4ea7\u8005\u5b8c\u6210\u4e86\u751f\u4ea7\u5e76\u5c06count\u53d8\u4e3a1\uff0c\u7136\u540e\u901a\u77e5\u7761\u7720\u4e2d\u7684\u8fdb\u7a0b\u82cf\u9192\uff0c\u7136\u800c\u8fd9\u65f6\u6d88\u8d39\u8005\u8fd8\u6ca1\u6709\u8fdb\u5165\u7761\u7720\uff0c \u4ece\u800c\u6d88\u8d39\u8005\u9762\u5bf9count = 1\u65f6\u4fdd\u6301\u7740\u7761\u7720\u7684\u72b6\u6001\u3002\u6700\u540e\u9020\u6210\u7684\u7ed3\u679c\u5c31\u662f\uff0c\u82e5\u751f\u4ea7\u8005\u4e4b\u540e\u4e0d\u518d\u8c03\u7528\u6d88\u8d39\u8005\uff0c\u90a3\u4e48\u6d88\u8d39\u8005\u5c31\u4f1a\u6c38\u8fdc\u7684\u6c89\u7761\u3002</p> <p>Suppose that P finds that s-&gt;count == 0 on line 212. While P is between lines 212 and 213, V runs on another CPU: it changes s-&gt;count to be nonzero and calls wakeup, which finds no processes sleeping and thus does nothing. Now P continues executing at line 213: it calls sleep and goes to sleep. This causes a problem: P is asleep waiting for a V call that has already happened. Unless we get lucky and the producer calls V again, the consumer will wait forever even though the count is non-zero.</p> <p>\u5e94\u5bf9\u4e0a\u9762\u8bf4\u7684**lost wake-up problem**\uff0c\u4e0b\u9762\u7684\u4ee3\u7801\u505a\u4e86\u4e00\u4e9b\u6539\u53d8\u3002\u770b\u8d77\u6765\uff0c\u751f\u4ea7\u8005\u5fc5\u987b\u7b49\u5230\u6d88\u8d39\u8005\u8fdb\u5165\u7761\u7720\u72b6\u6001\u540e\u624d\u80fd\u589e\u52a0count\u3002\u7136\u800c\uff0c\u5f53\u6d88\u8d39\u8005\u8fdb\u5165\u7761\u7720\u4e4b\u540e\uff0c\u4ed6\u4f1a\u4e00\u76f4\u62e5\u6709\u9501\uff0c\u4ece\u800c\u751f\u4ea7\u8005\u6c38\u8fdc\u65e0\u6cd5\u62ff\u5230\u9501\u8fdb\u884c\u751f\u4ea7\uff0c\u8fd9\u5c31\u9020\u6210\u4e86**\u6b7b\u9501**\u3002</p> <p>The root of this problem is that the invariant that P only sleeps when s-&gt;count == 0 is violated by V running at just the wrong moment. An incorrect way to protect the invariant would be to move the lock acquisition (highlighted in yellow below) in P so that its check of the count and its call to sleep are atomic:</p> <pre><code>300 void\n301 V(struct semaphore *s)\n302 {\n303 acquire(&amp;s-&gt;lock);\n304 s-&gt;count += 1;\n305 wakeup(s);\n306 release(&amp;s-&gt;lock);\n307 }\n308\n309 void\n310 P(struct semaphore *s)\n311 {\n312 acquire(&amp;s-&gt;lock);//change\n313 while(s-&gt;count == 0)\n314     sleep(s);\n315 s-&gt;count -= 1;\n316 release(&amp;s-&gt;lock);// \u8fd9\u91cc\u6c38\u8fdc\u6267\u884c\u4e0d\u5230\n317 }\n</code></pre> <p>One might hope that this version of P would avoid the lost wakeup because the lock prevents V from executing between lines 313 and 314. It does that, but it also deadlocks: P holds the lock while it sleeps, so V will block forever waiting for the lock.</p> <p>\u4e3a\u4e86\u89e3\u51b3\u6b7b\u9501\u7684\u95ee\u9898\uff0csleep\u5e94\u8be5\u505a\u5230\u4e24\u4ef6\u4e8b</p> <ol> <li>\u63a5\u53d7\u6d88\u8d39\u8005\u7684\u9501\u4e3a\u53c2\u6570\uff0c\u5f53\u6d88\u8d39\u8005\u5b8c\u5168\u8fdb\u5165sleep channel\u540e\uff0c\u5728sleep\u51fd\u6570\u5185\u90e8\u89e3\u9501\uff0c\u4ece\u800c\u751f\u4ea7\u8005\u5c31\u53ef\u4ee5\u5f97\u5230\u9501\u7ee7\u7eed\u6267\u884c\u3002</li> <li>\u5f53\u6d88\u8d39\u8005wakeup\u65f6\uff0csleep\u51fd\u6570\u8981\u91cd\u65b0\u83b7\u5f97\u9501\uff0c\u7136\u540e\u8fd4\u56de\u3002</li> </ol> <p>We\u2019ll fix the preceding scheme by changing sleep\u2019s interface: the caller must pass the condition lock to sleep so it can release the lock after the calling process is marked as asleep and waiting on the sleep channel. The lock will force a concurrent V to wait until P has finished putting itself to sleep, so that the wakeup will find the sleeping consumer and wake it up. Once the consumer is awake again sleep reacquires the lock before returning. Our new correct sleep/wakeup scheme is usable as follows (change highlighted in yellow):</p> <pre><code>400 void\n401 V(struct semaphore *s)\n402 {\n403 acquire(&amp;s-&gt;lock);\n404 s-&gt;count += 1;\n405 wakeup(s);\n406 release(&amp;s-&gt;lock);\n407 }\n408\n409 void\n410 P(struct semaphore *s)\n411 {\n412 acquire(&amp;s-&gt;lock);\n413 while(s-&gt;count == 0)\n414 sleep(s, &amp;s-&gt;lock);//change\n415 s-&gt;count -= 1;\n416 release(&amp;s-&gt;lock);\n417 }\n</code></pre> <p>The fact that P holds s-&gt;lock prevents V from trying to wake it up between P\u2019s check of c-&gt;count and its call to sleep. Note, however, that we need sleep to atomically release s-&gt;lock and put the consuming process to sleep.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#76-code-sleep-and-wakeup","title":"7.6 Code: Sleep and wakeup","text":"<p>\u63a5\u4e0b\u6765\u5c31\u8be5\u770b\u770bsleep\u548cwakeup\u7a76\u7adf\u662f\u600e\u4e48\u5b9e\u73b0\u7684\u4e86</p> <p>Let\u2019s look at the implementation of sleep (kernel/proc.c:548) and wakeup (kernel/proc.c:582). The basic idea is to have sleep mark the current process as SLEEPING and then call <code>sched</code> to release the CPU; wakeup looks for a process sleeping on the given wait channel and marks it as RUNNABLE. Callers of sleep and wakeup can use any mutually convenient number as the channel. Xv6 often uses the address of a kernel data structure involved in the waiting.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#sleep","title":"Sleep","text":"<pre><code>// Atomically release lock and sleep on chan.\n// Reacquires lock when awakened.\nvoid\nsleep(void *chan, struct spinlock *lk)\n{\n  struct proc *p = myproc();\n\n  // Must acquire p-&gt;lock in order to\n  // change p-&gt;state and then call sched.\n  // Once we hold p-&gt;lock, we can be\n  // guaranteed that we won't miss any wakeup\n  // (wakeup locks p-&gt;lock),\n  // so it's okay to release lk.\n  if(lk != &amp;p-&gt;lock){  //DOC: sleeplock0\n    acquire(&amp;p-&gt;lock);  //DOC: sleeplock1\n    release(lk);\n  }\n\n  // Go to sleep.\n  p-&gt;chan = chan;\n  p-&gt;state = SLEEPING;\n\n  sched();\n\n  // Tidy up.\n  p-&gt;chan = 0;\n\n  // Reacquire original lock.\n  if(lk != &amp;p-&gt;lock){\n    release(&amp;p-&gt;lock);\n    acquire(lk);\n  }\n}\n</code></pre> <p><code>lk</code>\u662fwakeup\u53ef\u4ee5\u5f00\u59cb\u7684\u6761\u4ef6\uff0csleep\u5728\u62ff\u5230<code>p-&gt;lock</code>\u540e\u5c31\u7acb\u523b\u91ca\u653e\u4e86<code>lk</code>\uff0c\u4ece\u800cwakeup\u5c31\u53ef\u4ee5\u5f00\u59cb\u5de5\u4f5c\u4e86\u3002</p> <p>\u4f46\u8fd9\u5e76\u4e0d\u4f1a\u5bfc\u81f4missing wake up\u7684\u95ee\u9898\uff0c\u867d\u7136\u6211\u4eec\u91ca\u653e\u4e86<code>lk</code>\u8ba9wakeup\u5f97\u4ee5\u8fdb\u5165for loop\u5f00\u59cb\u5bfb\u627e\u9700\u8981\u88ab\u5524\u9192\u7684\u8fdb\u7a0b\uff0c\u4f46\u662ffor loop\u4e2d\u9700\u8981\u83b7\u53d6\u6bcf\u4e2a\u8fdb\u7a0b\u7684\u9501\u3002\u6b63\u5728\u51c6\u5907sleeping\u7684\u8fdb\u7a0b\u6b63\u6301\u6709\u7740\u8fd9\u4e2a\u9501\uff0c\u4ece\u800cwakeup\u5fc5\u987b\u7b49\u5f85sleep\u8fdb\u7a0b\u5f7b\u5e95\u5165\u7761\u540e\u624d\u80fd\u8fdb\u884c\u5524\u9192\u4efb\u52a1\u3002</p> <p>\u8fd9\u91cc\u8fd8\u6709\u4e00\u4e2axv6\u7684\u51c6\u5219\u9700\u8981\u6ce8\u610f\uff0c\u6211\u4eec**\u5728\u8fdb\u5165<code>sched</code>\u4e4b\u524d\uff0c\u5fc5\u987b\u4fdd\u8bc1\u53ea\u6709<code>p-&gt;lock</code>\u8fd9\u4e00\u628a\u9501**\uff0c\u56e0\u4e3a\u8fd9\u628a\u9501\u4f1a\u5728\u8c03\u5ea6\u8fdb\u7a0b\u90a3\u91cc\u88abrelease\u3002\u5982\u679c\u6211\u4eec\u6709\u5176\u4ed6\u9501\u7684\u8bdd\uff0c\u90a3\u4e48\u4ed6\u4eec\u5728<code>sched</code>\u4e4b\u540e\u5c06\u65e0\u6cd5\u91ca\u653e\uff0c\u4ece\u800c\u5f53\u53e6\u5916\u4e00\u4e9b\u8fdb\u7a0b\u9700\u8981\u8fd9\u4e9b\u9501\u7684\u65f6\u5019\uff0c\u5bfc\u81f4\u6b7b\u9501\u3002</p> <p>Sleep acquires p-&gt;lock (kernel/proc.c:559). Now the process going to sleep holds both <code>p-&gt;lock</code> and <code>lk</code>. Holding <code>lk</code> was necessary in the caller (in the example, P): it ensured that no other process (in the example, one running V) could start a call to <code>wakeup(chan)</code>. Now that sleep holds <code>p-&gt;lock</code>, it is safe to release <code>lk</code>: some other process may start a call to <code>wakeup(chan)</code>, but wakeup will wait to acquire <code>p-&gt;lock</code>, and thus will wait until sleep has finished putting the process to sleep, keeping the wakeup from missing the sleep.</p> <p>sleep\u6709\u4e00\u4e2a\u7279\u6b8a\u7684\u60c5\u5f62\uff0c\u5982\u679c<code>lk</code>\u5c31\u662f<code>p-&gt;lock</code>\u600e\u4e48\u529e\u5462\uff1f</p> <p>\u90a3\u4e48\u6211\u4eec\u5176\u5b9e\u4ec0\u4e48\u4e5f\u4e0d\u7528\u505a\uff0c\u7b49\u5230sleeping\u8fdb\u7a0b\u5207\u6362\u5230\u8c03\u5ea6\u8fdb\u7a0b\u88ab\u91ca\u653e\u540e\uff0c\u5bf9\u5e94\u7684wakeup\u5c31\u53ef\u4ee5\u8fdb\u5165for\u5faa\u73af\u53d6\u5524\u9192\u5b83\u4e86\u3002</p> <p>\u8fd9\u79cd\u60c5\u5f62\u51fa\u73b0\u5728<code>wait()</code>\u7cfb\u7edf\u8c03\u7528\u8fd9\u91cc\uff0c\u4f1a\u5728\u4e4b\u540e\u8bf4\u660e\u3002</p> <p>There is a minor complication: if <code>lk</code> is the same lock as <code>p-&gt;lock</code>, then sleep would deadlock with itself if it tried to acquire p-&gt;lock. But if the process calling sleep already holds <code>p-&gt;lock</code>, it doesn\u2019t need to do anything more in order to avoiding missing a concurrent wakeup. This case arises when wait (kernel/proc.c:582) calls sleep with p-&gt;lock.</p> <p>\u4e3a\u4ec0\u4e48<code>p-&gt;lock</code> is not released (by scheduler) until after the process is marked SLEEPING?</p> <p>Now that sleep holds p-&gt;lock and no others, it can put the process to sleep by recording the sleep channel, changing the process state to SLEEPING, and calling <code>sched</code> (kernel/proc.c:564-567). In a moment it will be clear why it\u2019s critical that <code>p-&gt;lock</code> is not released (by scheduler) until after the process is marked SLEEPING.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#wakeup","title":"Wakeup","text":"<p>At some point, a process will acquire the condition lock, set the condition that the sleeper is waiting for, and call <code>wakeup(chan</code>). It\u2019s important that wakeup is called while holding the condition lock . Wakeup loops over the process table (kernel/proc.c:582). It acquires the p-&gt;lock of each process it inspects, both because it may manipulate that process\u2019s state and because p-&gt;lock ensures that sleep and wakeup do not miss each other. When wakeup finds a process in state SLEEPING with a matching <code>chan</code>, it changes that process\u2019s state to RUNNABLE. The next time the scheduler runs, it will see that the process is ready to be run.</p> <pre><code>// Wake up all processes sleeping on chan.\n// Must be called without any p-&gt;lock.\nvoid\nwakeup(void *chan)\n{\n  struct proc *p;\n\n  for(p = proc; p &lt; &amp;proc[NPROC]; p++) {\n    acquire(&amp;p-&gt;lock);\n    if(p-&gt;state == SLEEPING &amp;&amp; p-&gt;chan == chan) {\n      p-&gt;state = RUNNABLE;\n    }\n    release(&amp;p-&gt;lock);\n  }\n}\n</code></pre> <p>\u4e3a\u4f55\u8fd9\u79cd\u8bbe\u8ba1\u4e0d\u4f1amiss wakeup\uff1f</p> <ol> <li>wakeup\u8fd0\u884c\u65f6\u4e00\u76f4\u62ff\u7740\u4e24\u628a\u9501\uff1a\u8fdb\u7a0b\u9501\u548ccondition\u9501\uff08condition\u9501\u662fwakeup\u51fd\u6570\u6267\u884c\u7684\u524d\u4e00\u6b65\uff09</li> <li>condition\u9501\u4fdd\u8bc1\u4e86\u5728\u8fdb\u5165wakeup\u4e4b\u524d\uff0c\u5df2\u7ecf\u539f\u5b50\u6027\u7684\u5b8c\u6210\u4e86\u8be5\u505a\u7684\u4e1a\u52a1\u903b\u8f91\uff08\u4f8b\u5982\uff0c\u7ed9buffer\u4e2d\u5199\u5165\u5185\u5bb9\uff09</li> <li>\u8fdb\u7a0b\u9501\u4fdd\u8bc1\u4e86\u5728sleeping\u8fdb\u7a0b\u5b8c\u6210\u7761\u7720\u8fc7\u7a0b\u4e4b\u524d\uff0cwakeup\u4e0d\u53ef\u4ee5\u5ffd\u7565\u4ed6\uff08\u4f8b\u5982\uff0cbuffer\u4e2d\u5df2\u7ecf\u6709\u4e86\u4e00\u4e9b\u5185\u5bb9\uff0c\u4f46<code>bufferReader</code>\u8fd8\u6ca1\u6709\u8fdb\u5165\u7761\u7720\uff0c\u53ea\u6709\u5728<code>bufferReader</code>\u8fdb\u5165\u7761\u7720\u540e\uff0cwakeup\u624d\u4f1a\u53eb\u9192\u4ed6\uff09</li> </ol> <p>Why do the locking rules for sleep and wakeup ensure a sleeping process won\u2019t miss a wakeup? The sleeping process holds either the condition lock or its own p-&gt;lock or both from a point before it checks the condition to a point after it is marked SLEEPING. The process calling wakeup holds both of those locks in wakeup\u2019s loop. Thus the <code>waker</code> either makes the condition true before the consuming thread checks the condition; or the <code>waker\u2019s</code> wakeup examines the sleeping thread strictly after it has been marked SLEEPING. Then wakeup will see the sleeping process and wake it up (unless something else wakes it up first).</p> <p>\u591a\u4e2a\u8fdb\u7a0b\u90fd\u5728\u540c\u4e00\u4e2achannel\u4e2d\u7761\u7720\u7684\u60c5\u51b5</p> <p>\u7136\u800c\uff0c\u53ea\u6709\u4e00\u4e2a\u8fdb\u7a0b\u4f1a\u5728sleep\u4e2d\u82cf\u9192\u540e\u62a2\u5230condition lock\u7136\u540e\u8bfb\u53d6\u751f\u4ea7\u8005\u751f\u4ea7\u7684\u5185\u5bb9</p> <p>\u5f53\u5176\u4ed6\u88ab\u5524\u9192\u7684\u6559\u7a0b\u4e4b\u540e\u62ff\u5230condition lock\uff0c\u53ea\u4f1a\u53d1\u73b0\u4ec0\u4e48\u90fd\u6ca1\u4e86\uff0c\u53ea\u80fd\u5728while\u5faa\u73af\u4e2d\u518d\u6b21\u8fdb\u5165\u7761\u7720</p> <p>\u8fd9\u4e5f\u662f\u4e3a\u4ec0\u4e48sleep\u4e3a\u4ec0\u4e48\u603b\u662f\u5728while\u5faa\u73af\u4e2d\u88ab\u8c03\u7528</p> <p>It is sometimes the case that multiple processes are sleeping on the same channel; for example, more than one process reading from a pipe. A single call to wakeup will wake them all up. One of them will run first and acquire the lock that sleep was called with, and (in the case of pipes) read whatever data is waiting in the pipe. The other processes will find that, despite being woken up, there is no data to be read. From their point of view the wakeup was \u201cspurious(\u865a\u5047\u7684),\u201d and they must sleep again. For this reason sleep is always called inside a loop that checks the condition.</p> <p>No harm is done if two uses of sleep/wakeup accidentally choose the same channel: they will see spurious wakeups, but looping as described above will tolerate this problem. Much of the charm of sleep/wakeup is that it is both lightweight (no need to create special data structures to act as sleep channels) and provides a layer of indirection (callers need not know which specific process they are interacting with).</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#77-code-pipes","title":"7.7 Code: Pipes","text":"<p>\u7ba1\u9053\u662f\u4f7f\u7528sleep\u548cwakeup\u6765\u5b9e\u73b0\u8fdb\u7a0b\u540c\u6b65\u7684</p> <p>A more complex example that uses sleep and wakeup to synchronize producers and consumers is xv6\u2019s implementation of pipes. We saw the interface for pipes in Chapter 1: bytes written to one end of a pipe are copied to an in-kernel buffer and then can be read from the other end of the pipe. Future chapters will examine the file descriptor support surrounding pipes, but let\u2019s look now at the implementations of <code>pipewrite</code> and <code>piperead</code>.</p> <p>Each pipe is represented by a struct pipe, which contains a lock and a data buffer. The fields <code>nread</code> and <code>nwrite</code> count the total number of bytes read from and written to the buffer. The buffer wraps around: the next byte written after <code>buf[PIPESIZE-1]</code> is <code>buf[0]</code>. The counts do not wrap. This convention lets the implementation distinguish a full buffer (<code>nwrite == nread+PIPESIZE</code>) from an empty buffer (<code>nwrite == nread</code>), but it means that indexing into the buffer must use <code>buf[nread % PIPESIZE]</code> instead of just <code>buf[nread]</code> (and similarly for <code>nwrite</code>).</p> <pre><code>struct pipe {\n  struct spinlock lock;\n  char data[PIPESIZE];\n  uint nread;     // number of bytes read\n  uint nwrite;    // number of bytes written\n  int readopen;   // read fd is still open\n  int writeopen;  // write fd is still open\n};\n</code></pre> <p>Let\u2019s suppose that calls to <code>piperead</code> and <code>pipewrite</code> happen simultaneously on two different CPUs. <code>Pipewrite</code> (kernel/pipe.c:77) begins by acquiring the pipe\u2019s lock, which protects the counts, the data, and their associated invariants. <code>Piperead</code> (kernel/pipe.c:103) then tries to acquire the lock too, but cannot. It spins in acquire (kernel/spinlock.c:22) waiting for the lock. While <code>piperead</code> waits, <code>pipewrite</code> loops over the bytes being written (<code>addr[0..n-1]</code>), adding each to the pipe in turn (kernel/pipe.c:95). During this loop, it could happen that the buffer fills (kernel/pipe.c:85). In this case, <code>pipewrite</code> calls wakeup to alert any sleeping readers to the fact that there is data waiting in the buffer and then sleeps on <code>&amp;pi-&gt;nwrite</code> to wait for a reader to take some bytes out of the buffer. Sleep releases <code>pi-&gt;lock</code> as part of putting <code>pipewrite</code>\u2019s process to sleep.</p> <pre><code>int\npipewrite(struct pipe *pi, uint64 addr, int n)\n{\n  int i = 0;\n  struct proc *pr = myproc();\n\n  acquire(&amp;pi-&gt;lock);\n  while(i &lt; n){\n    if(pi-&gt;readopen == 0 || pr-&gt;killed){\n      release(&amp;pi-&gt;lock);\n      return -1;\n    }\n    if(pi-&gt;nwrite == pi-&gt;nread + PIPESIZE){ //DOC: pipewrite-full\n      wakeup(&amp;pi-&gt;nread);\n      sleep(&amp;pi-&gt;nwrite, &amp;pi-&gt;lock);\n    } else {\n      char ch;\n      if(copyin(pr-&gt;pagetable, &amp;ch, addr + i, 1) == -1)\n        break;\n      pi-&gt;data[pi-&gt;nwrite++ % PIPESIZE] = ch;\n      i++;\n    }\n  }\n  wakeup(&amp;pi-&gt;nread);\n  release(&amp;pi-&gt;lock);\n\n  return i;\n}\n</code></pre> <pre><code>int\npiperead(struct pipe *pi, uint64 addr, int n)\n{\n  int i;\n  struct proc *pr = myproc();\n  char ch;\n\n  acquire(&amp;pi-&gt;lock);\n  while(pi-&gt;nread == pi-&gt;nwrite &amp;&amp; pi-&gt;writeopen){  //DOC: pipe-empty\n    if(pr-&gt;killed){\n      release(&amp;pi-&gt;lock);\n      return -1;\n    }\n    sleep(&amp;pi-&gt;nread, &amp;pi-&gt;lock); //DOC: piperead-sleep\n  }\n  for(i = 0; i &lt; n; i++){  //DOC: piperead-copy\n    if(pi-&gt;nread == pi-&gt;nwrite)\n      break;\n    ch = pi-&gt;data[pi-&gt;nread++ % PIPESIZE];\n    if(copyout(pr-&gt;pagetable, addr + i, &amp;ch, 1) == -1)\n      break;\n  }\n  wakeup(&amp;pi-&gt;nwrite);  //DOC: piperead-wakeup\n  release(&amp;pi-&gt;lock);\n  return i;\n}\n</code></pre> <p>Now that <code>pi-&gt;lock</code> is available, <code>piperead</code> manages to acquire it and enters its critical section: it finds that <code>pi-&gt;nread != pi-&gt;nwrite</code> (kernel/pipe.c:110) (<code>pipewrite</code> went to sleep because <code>pi-&gt;nwrite == pi-&gt;nread+PIPESIZE</code> (kernel/pipe.c:85)), so it falls through to the for loop, copies data out of the pipe (kernel/pipe.c:117), and increments <code>nread</code> by the number of bytes copied. That many bytes are now available for writing, so <code>piperead</code> calls wakeup (kernel/pipe.c:124) to wake any sleeping writers before it returns. Wakeup finds a process sleeping on <code>&amp;pi-&gt;nwrite</code>, the process that was running <code>pipewrite</code> but stopped when the buffer filled. It marks that process as RUNNABLE.</p> <p>\u4e0b\u9762\u8fd9\u4e00\u90e8\u5206\u542c\u8bfe\u8865\u5145 \u4e3a\u4ec0\u4e48\u4e24\u4e2achannel\u66f4\u9ad8\u6548\uff1f\u6ca1\u8bf4:(</p> <p>The pipe code uses separate sleep channels for reader and writer (<code>pi-&gt;nread</code> and <code>pi-&gt;nwrite</code>); this might make the system more efficient in the unlikely event that there are lots of readers and writers waiting for the same pipe. The pipe code sleeps inside a loop checking the sleep condition; if there are multiple readers or writers, all but the first process to wake up will see the condition is still false and sleep again.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#78-code-wait-exit-and-kill","title":"7.8 Code: Wait, exit, and kill","text":"<p><code>Sleep</code> and <code>wakeup</code> can be used for many kinds of waiting. An interesting example, introduced in Chapter 1, is the interaction between a child\u2019s <code>exit</code> and its parent\u2019s <code>wait</code>.</p> <p>At the time of the child\u2019s death, the parent may already be sleeping in <code>wait</code>, or may be doing something else; in the latter case, a subsequent call to wait must observe the child\u2019s death, perhaps long after it calls <code>exit</code>.</p> <ul> <li>The way that xv6 records the child\u2019s demise(\u706d\u4ea1) until wait observes it is for exit to put the caller into the ZOMBIE state, where it stays until the parent\u2019s wait notices it, changes the child\u2019s state to UNUSED, copies the child\u2019s exit status, and returns the child\u2019s process ID to the parent.</li> <li>If the parent exits before the child, the parent gives the child to the <code>init process</code>, which perpetually(\u6c38\u8fdc) calls wait; thus every child has a parent to clean up after it. The main implementation challenge is the possibility of races and deadlock between parent and child wait and exit, as well as exit and exit.</li> </ul>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#wait","title":"Wait","text":"<p>Wait uses the calling process\u2019s <code>p-&gt;lock</code> as the condition lock to avoid lost wakeups, and it acquires that lock at the start (kernel/proc.c:398).</p> <p>Then it scans the process table.</p> <ul> <li> <p>If it finds a child in ZOMBIE state, it frees that child\u2019s resources and its proc structure, copies the child\u2019s exit status to the address supplied to wait (if it is not 0), and returns the child\u2019s process ID.</p> </li> <li> <p>If wait finds children but none have exited, it calls sleep to wait for one of them to exit (kernel/proc.c:445), then scans again.</p> </li> </ul> <p>\u8fd9\u91cc\u5c31\u8981\u89e3\u7b54\u76f4\u63a5\u63d0\u51fa\u7684sleep\u7684\u7279\u6b8a\u60c5\u51b5\u4e86\uff1asleep\u4e2d\u4f20\u5165\u7684condition lock\u662f\u8fdb\u7a0b\u9501\u672c\u8eab\u600e\u4e48\u529e</p> <p>// Wait for a child to exit. <code>sleep(p, &amp;p-&gt;lock);  //DOC: wait-sleep</code></p> <p>\u4e3a\u4e86\u907f\u514d\u6b7b\u9501\uff0c\u6211\u4eec\u5c31\u8981\u4e25\u683c\u9075\u5b88\u4e0a\u9501\u7684\u987a\u5e8f\uff0c\u5148parent\u518dchild</p> <p>Here, the condition lock being released in sleep is the waiting process\u2019s p-&gt;lock, the special case mentioned above. Note that wait often holds two locks; that it acquires its own lock before trying to acquire any child\u2019s lock; and that thus all of xv6 must obey the same locking order (parent, then child) in order to avoid deadlock.</p> <pre><code>// Wait for a child process to exit and return its pid.\n// Return -1 if this process has no children.\nint\nwait(uint64 addr)\n{\n  struct proc *np;\n  int havekids, pid;\n  struct proc *p = myproc();\n\n  // hold p-&gt;lock for the whole time to avoid lost\n  // wakeups from a child's exit().\n  acquire(&amp;p-&gt;lock);\n\n  for(;;){\n    // Scan through table looking for exited children.\n    havekids = 0;\n    for(np = proc; np &lt; &amp;proc[NPROC]; np++){\n      // this code uses np-&gt;parent without holding np-&gt;lock.\n      // acquiring the lock first would cause a deadlock,\n      // since np might be an ancestor, and we already hold p-&gt;lock.\n      if(np-&gt;parent == p){\n        // np-&gt;parent can't change between the check and the acquire()\n        // because only the parent changes it, and we're the parent.\n        acquire(&amp;np-&gt;lock);\n        havekids = 1;\n        if(np-&gt;state == ZOMBIE){\n          // Found one.\n          pid = np-&gt;pid;\n          if(addr != 0 &amp;&amp; copyout(p-&gt;pagetable, addr, (char *)&amp;np-&gt;xstate,\n                                  sizeof(np-&gt;xstate)) &lt; 0) {\n            release(&amp;np-&gt;lock);\n            release(&amp;p-&gt;lock);\n            return -1;\n          }\n          freeproc(np);\n          release(&amp;np-&gt;lock);\n          release(&amp;p-&gt;lock);\n          return pid;\n        }\n        release(&amp;np-&gt;lock);\n      }\n    }\n\n    // No point waiting if we don't have any children.\n    if(!havekids || p-&gt;killed){\n      release(&amp;p-&gt;lock);\n      return -1;\n    }\n\n    // Wait for a child to exit.\n    sleep(p, &amp;p-&gt;lock);  //DOC: wait-sleep\n  }\n}\n</code></pre> <p>Wait looks at every process\u2019s np-&gt;parent to find its children.</p> <p>It uses np-&gt;parent without holding np-&gt;lock, which is a violation of the usual rule that shared variables must be protected by locks.</p> <p>\u8fd9\u53c8\u6709\u4e00\u5904\u8fdd\u53cd\u89c4\u5219\u7684\u5730\u65b9\uff0c\u6211\u4eec\u5728\u68c0\u67e5\u6bcf\u4e2aprocess\u7684parent\u65f6\u5e76\u6ca1\u6709\u7ed9\u8fd9\u4e2aprocess\u4e0a\u9501\u3002\u5982\u679c\u4e0a\u9501\u7684\u8bdd\uff0c\u53ef\u80fd\u5e26\u6765\u4e00\u4e2a\u95ee\u9898\uff1a\u4e5f\u5c31\u662f\u5982\u679c<code>np</code>\u662f\u5f53\u524d\u8fdb\u7a0b\u7684\u7956\u5148\uff0c\u8fd9\u6837\u7684\u8bdd\u6211\u4eec\u5982\u679c\u7ed9<code>np</code>\u4e0a\u9501\u5c31\u4f1a\u5bfc\u81f4\u5b50\u8fdb\u7a0bp\u7684\u9501\u5728\u5176\u7236\u8fdb\u7a0bnp\u4e4b\u524d\u88ab\u83b7\u5f97\u4e86\uff0c\u8fd9\u5c31\u8fdd\u53cd\u4e86\u83b7\u5f97\u9501\u5e94\u8be5\u9075\u5b88\u7684\u987a\u5e8f\u3002</p> <pre><code>// \u5982\u679c\u6211\u4eec\u5728if\u5224\u65ad\u524d\u52a0\u9501\u53ef\u80fd\u9047\u5230\u7684\u60c5\u51b5\nacquire(&amp;p-&gt;lock);// child\nfor(np = proc; np &lt; &amp;proc[NPROC]; np++){\n      acquire(&amp;np-&gt;lock);//parent\n      if(np-&gt;parent == p){\n</code></pre> <p>\u8fd9\u91cc\u6ca1\u6709\u95ee\u9898\u7684\u539f\u56e0\u662f\uff1a</p> <ol> <li>\u5b50\u8fdb\u7a0b\u7684parent\u53ea\u80fd\u88ab\u7236\u8fdb\u7a0b\u6539\u53d8\uff0c\u7136\u800c\u6211\u4eec\u5df2\u7ecf\u62e5\u6709\u7236\u8fdb\u7a0b\u7684\u9501\u4e86</li> </ol> <p>It is possible that np is an ancestor of the current process, in which case acquiring np-&gt;lock could cause a deadlock since that would violate the order mentioned above. Examining np-&gt;parent without a lock seems safe in this case; a process\u2019s parent field is only changed by its parent, so if np-&gt;parent==p is true, the value can\u2019t change unless the current process changes it.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#exit","title":"Exit","text":"<p>Exit (kernel/proc.c:333)</p> <ol> <li> <p>records the exit status, frees some resources,</p> </li> <li> <p>gives any children to the <code>init</code> process,</p> </li> <li> <p>wakes up the parent in case it is in wait, marks the caller as a zombie, and permanently yields the CPU.</p> </li> </ol> <p>\u4e3a\u4ec0\u4e48\u5b50\u8fdb\u7a0b\u5728\u6700\u540e\u8bbe\u7f6eZOMBIE\u548cwakeup\u5176\u7236\u8fdb\u7a0b\u65f6\u4e00\u76f4\u62ff\u7740\u5b83parent\u7684\u9501</p> <p>\u7236\u8fdb\u7a0b\u7684\u9501\u662fcondition lock\uff0c\u6ca1\u6709\u4ed6\u7236\u8fdb\u7a0b\u5c31\u65e0\u6cd5\u8fdb\u5165for\u5faa\u73af\u5f00\u59cb\u5bfb\u627e\u5b50\u8fdb\u7a0b</p> <p>\u5b50\u8fdb\u7a0b\u81ea\u5df1\u7684\u9501\u7528\u4e8e\u4fdd\u8bc1\u7236\u8fdb\u7a0b\u4e0d\u4f1a\u770b\u5230\u81ea\u5df1\u662fZOMBIE\u5c31\u5f00\u59cb<code>freeproc</code>\uff0c</p> <pre><code>  acquire(&amp;original_parent-&gt;lock);\n  acquire(&amp;p-&gt;lock);\n  // Give any children to init.\n  reparent(p);\n  // Parent might be sleeping in wait().\n  wakeup1(original_parent);\n  p-&gt;xstate = status;\n  p-&gt;state = ZOMBIE;\n  release(&amp;original_parent-&gt;lock);\n</code></pre> <p>**\u9501\u7684\u83b7\u5f97\u987a\u5e8f**\u5bf9\u4e8e**\u907f\u514d\u6b7b\u9501**\u662f\u975e\u5e38\u91cd\u8981\u7684\uff0cwait\u548cexit\u5c31\u662f\u4e00\u5bf9\u53ef\u80fd\u5f15\u53d1race condition\u7684\u8fdb\u7a0b\uff0c\u4ed6\u4eec\u5c31\u5fc5\u987b\u9075\u5faa\u540c\u6837\u7684\u83b7\u5f97\u9501\u7684\u987a\u5e8f</p> <p>The final sequence is a little tricky. The exiting process must hold its parent\u2019s lock while it sets its state to ZOMBIE and wakes the parent up, since the parent\u2019s lock is the condition lock that guards against lost wakeups in wait. The child must also hold its own <code>p-&gt;lock</code>, since otherwise the parent might see it in state ZOMBIE and free it while it is still running. The lock acquisition order is important to avoid deadlock: since wait acquires the parent\u2019s lock before the child\u2019s lock, exit must use the same order.</p> <pre><code>// Exit the current process.  Does not return.\n// An exited process remains in the zombie state\n// until its parent calls wait().\nvoid\nexit(int status)\n{\n  struct proc *p = myproc();\n\n  if(p == initproc)\n    panic(\"init exiting\");\n\n  // Close all open files.\n  for(int fd = 0; fd &lt; NOFILE; fd++){\n    if(p-&gt;ofile[fd]){\n      struct file *f = p-&gt;ofile[fd];\n      fileclose(f);\n      p-&gt;ofile[fd] = 0;\n    }\n  }\n\n  begin_op();\n  iput(p-&gt;cwd);\n  end_op();\n  p-&gt;cwd = 0;\n\n  // we might re-parent a child to init. we can't be precise about\n  // waking up init, since we can't acquire its lock once we've\n  // acquired any other proc lock. so wake up init whether that's\n  // necessary or not. init may miss this wakeup, but that seems\n  // harmless.\n  acquire(&amp;initproc-&gt;lock);\n  wakeup1(initproc);\n  release(&amp;initproc-&gt;lock);\n\n  // grab a copy of p-&gt;parent, to ensure that we unlock the same\n  // parent we locked. in case our parent gives us away to init while\n  // we're waiting for the parent lock. we may then race with an\n  // exiting parent, but the result will be a harmless spurious wakeup\n  // to a dead or wrong process; proc structs are never re-allocated\n  // as anything else.\n  acquire(&amp;p-&gt;lock);\n  struct proc *original_parent = p-&gt;parent;\n  release(&amp;p-&gt;lock);\n\n  // we need the parent's lock in order to wake it up from wait().\n  // the parent-then-child rule says we have to lock it first.\n  acquire(&amp;original_parent-&gt;lock);\n\n  acquire(&amp;p-&gt;lock);\n\n  // Give any children to init.\n  reparent(p);\n\n  // Parent might be sleeping in wait().\n  wakeup1(original_parent);\n\n  p-&gt;xstate = status;\n  p-&gt;state = ZOMBIE;\n\n  release(&amp;original_parent-&gt;lock);\n\n  // Jump into the scheduler, never to return.\n  sched();\n  panic(\"zombie exit\");\n}\n</code></pre> <p><code>Exit</code> calls a specialized wakeup function, <code>wakeup1</code>, that wakes up only the parent, and only if it is sleeping in wait (kernel/proc.c:598). It may look incorrect for the child to wake up the parent before setting its state to ZOMBIE, but that is safe: although <code>wakeup1</code> may cause the parent to run, the loop in wait cannot examine the child until the child\u2019s p-&gt;lock is released by scheduler, so wait can\u2019t look at the exiting process until well after exit has set its state to ZOMBIE (kernel/proc.c:386)</p> <p>\u5728\u6211\u770b\u6765\u8fd9\u91cc\u4f7f\u7528wakeup1\u8fd9\u79cd\u8bbe\u8ba1\u6709\u70b9\u50cf\u662f\u4e3a\u4e86\u514b\u670dsleep\u7684condition lock\u662f\u7236\u8fdb\u7a0b\u9501\u7684\u5f0a\u7aef\uff0c\u5982\u679c\u4e0d\u4f7f\u7528wakeup1\uff0c\u90a3\u4e48\u7236\u8fdb\u7a0b\u8c03\u7528wait\u5c31\u8981\u7b49\u5230\u5b50\u8fdb\u7a0b\u5728\u8c03\u5ea6\u7ebf\u7a0b\u88ab\u89e3\u9501\u65f6\u624d\u80fd\u6267\u884c\u3002</p> <pre><code>// Wake up p if it is sleeping in wait(); used by exit().\n// Caller must hold p-&gt;lock.\nstatic void\nwakeup1(struct proc *p)\n{\n  if(!holding(&amp;p-&gt;lock))\n    panic(\"wakeup1\");\n  if(p-&gt;chan == p &amp;&amp; p-&gt;state == SLEEPING) {\n    p-&gt;state = RUNNABLE;\n  }\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#kill","title":"Kill","text":"<p>While exit allows a process to terminate itself, kill (kernel/proc.c:611) lets one process request that another terminate. It would be too complex for kill to directly destroy the victim process, since the victim might be executing on another CPU, perhaps in the middle of a sensitive sequence of updates to kernel data structures.</p> <pre><code>// Kill the process with the given pid.\n// The victim won't exit until it tries to return\n// to user space (see usertrap() in trap.c).\nint\nkill(int pid)\n{\n  struct proc *p;\n\n  for(p = proc; p &lt; &amp;proc[NPROC]; p++){\n    acquire(&amp;p-&gt;lock);\n    if(p-&gt;pid == pid){\n      p-&gt;killed = 1;\n      if(p-&gt;state == SLEEPING){\n        // Wake process from sleep().\n        p-&gt;state = RUNNABLE;\n      }\n      release(&amp;p-&gt;lock);\n      return 0;\n    }\n    release(&amp;p-&gt;lock);\n  }\n  return -1;\n}\n</code></pre> <p>Thus kill does very little: it just sets the victim\u2019s p-&gt;killed and, if it is sleeping, wakes it up.</p> <p>Eventually the victim will enter or leave the kernel, at which point code in <code>usertrap</code> will call <code>exit</code> if p-&gt;killed is set.</p> <ul> <li> <p>If the victim is running in user space, it will soon enter the kernel by making a system call or because the timer (or some other device) interrupts.</p> </li> <li> <p>If the victim process is in sleep, <code>kill</code>\u2019s call to <code>wakeup</code> will cause the victim to return from sleep.</p> </li> </ul> <p>kill\u5e76\u4e0d\u80fd\u76f4\u63a5\u8ba9\u4e00\u4e2a\u8fdb\u7a0b\u76f4\u63a5\u7ed3\u675f\uff0c\u4ed6\u53ea\u80fd\u901a\u8fc7\u8c03\u5ea6\u7684\u65b9\u5f0f\u8ba9killed\u8fdb\u7a0b\u5728\u4e0b\u4e00\u6b21\u88ab\u8c03\u5ea6\u65f6\u88ab\u6740\u6b7b\u3002\u6740\u6b7b\u7684\u65b9\u5f0f\u5c31\u662f\u8ba9\u4ed6\u81ea\u5df1\u8c03\u7528<code>exit()</code>\u9000\u51fa\u3002</p> <p>\u4e0b\u4e00\u6b21\u7684\u8c03\u5ea6\u53ef\u4ee5\u53d1\u751f\u5728\u4e24\u4e2a\u5730\u65b9</p> <ol> <li>\u7528\u6237\u7a7a\u95f4\uff0ctimer\u5c06\u8be5\u8fdb\u7a0b\u4ece\u7528\u6237\u7a7a\u95f4\u5e26\u5165<code>usertrap</code>\uff0c\u7136\u540e\u8fdb\u884ckill</li> <li>\u5185\u6838\u7a7a\u95f4\uff0c\u4ecesleep\u4e2d\u82cf\u9192\uff0c\u88absleep\u6240\u5728\u7684for\u5faa\u73af\u6740\u6b7b\uff08sleep\u603b\u662f\u5904\u5728for\u5faa\u73af\u4e2d\uff0c\u7528\u6765\u9884\u5907\u8fd9\u79cd\u60c5\u51b5\uff09</li> </ol> <pre><code>for (....) {\n    if (p-&gt;state == KILLED)\n        exit();\n    sleep();\n}\n</code></pre> <p>This is potentially dangerous because the condition being waiting for may not be true. However, xv6 calls to sleep are always wrapped in a while loop that re-tests the condition after sleep returns. Some calls to sleep also test p-&gt;killed in the loop, and abandon the current activity if it is set. This is only done when such abandonment would be correct. For example, the pipe read and write code returns if the killed flag is set; eventually the code will return back to trap, which will again check the flag and exit.</p> <p>sleep\u4e0d\u5728for\u5faa\u73af\u4e2d\u7684\u4f8b\u5916</p> <p>Some xv6 sleep loops do not check <code>p-&gt;killed</code> because the code is in the middle of a multistep system call that should be atomic. The <code>virtio driver</code>(kernel/<code>virtio_disk.c</code>:242) is an example: it does not check <code>p-&gt;killed</code> because a disk operation may be one of a set of writes that are all needed in order for the file system to be left in a correct state.</p> <p>A process that is killed while waiting for disk I/O won\u2019t exit until it completes the current system call and <code>usertrap</code> sees the killed flag.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#79-real-world","title":"7.9 Real world","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#different-scheduling-policy","title":"Different scheduling policy","text":"<p>The xv6 scheduler implements a simple scheduling policy, which runs each process in turn. This policy is called round robin.</p> <p>Real operating systems implement more sophisticated policies that, for example, allow processes to have priorities. The idea is that a runnable high-priority process will be preferred by the scheduler over a runnable low-priority process.</p> <p>These policies can become complex quickly because there are often competing goals:</p> <p>for example, the operating might also want to guarantee fairness and high throughput\uff08\u541e\u5410\u91cf\uff09. In addition, complex policies may lead to unintended interactions such as priority inversion and convoys.</p> <ul> <li>Priority inversion can happen when a low-priority and high-priority process share a lock, which when acquired by the low-priority process can prevent the high-priority process from making progress.</li> <li>A long convoy(\u62a4\u822a\u961f) of waiting processes can form when many high-priority processes are waiting for a low-priority process that acquires a shared lock; once a convoy has formed it can persist for long time. To avoid these kinds of problems additional mechanisms are necessary in sophisticated schedulers.</li> </ul>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#different-synchronization-method","title":"Different synchronization method","text":"<p><code>Sleep</code> and <code>wakeup</code> are a simple and effective synchronization method, but there are many others.</p> <p>The first challenge in all of them is to avoid the \u201clost wakeups\u201d problem we saw at the beginning of the chapter.</p> <p>sleep\u7684\u4e0d\u540c\u5b9e\u73b0</p> <p>The original Unix kernel\u2019s sleep simply disabled interrupts, which sufficed(\u8db3\u591f) because Unix ran on a single-CPU system. Because xv6 runs on multiprocessors, it adds an explicit lock to sleep. FreeBSD\u2019s <code>msleep</code> takes the same approach. Plan 9\u2019s <code>sleep</code> uses a callback function that runs with the scheduling lock held just before going to sleep; the function serves as a last-minute check of the sleep condition, to avoid lost wakeups. The Linux kernel\u2019s sleep uses an explicit process queue, called a wait queue, instead of a wait channel; the queue has its own internal lock.</p> <p>wakeup\u7684\u4e0d\u540c\u5b9e\u73b0</p> <p>\u4e00\u79cd\u88ab\u53eb\u505aconditional variable\u7684\u6570\u636e\u7ed3\u6784</p> <p>Scanning the entire process list in wakeup for processes with a matching <code>chan</code> is inefficient.</p> <p>A better solution is to replace the <code>chan</code> in both sleep and wakeup with a <code>data structure</code> that holds a list of processes sleeping on that structure, such as Linux\u2019s wait queue. Plan 9\u2019s sleep and wakeup call that structure a rendezvous point or <code>Rendez</code>. Many thread libraries refer to the same structure as a condition variable; in that context, the operations sleep and wakeup are called wait and signal. All of these mechanisms share the same flavor: the sleep condition is protected by some kind of lock dropped atomically during sleep.</p> <p>xv6 wakeup \u5524\u9192\u5168\u90e8\u7b49\u5f85\u8fdb\u7a0b\u7684\u95ee\u9898</p> <p>\u89e3\u51b3\u65b9\u6848\uff1asignal\u548cbroadcast</p> <p>The implementation of <code>wakeup</code> wakes up all processes that are waiting on a particular channel, and it might be the case that many processes are waiting for that particular channel. The operating system will schedule all these processes and they will race to check the sleep condition. Processes that behave in this way are sometimes called a thundering herd, and it is best avoided.</p> <p>Most condition variables have two primitives for wakeup: <code>signal</code>, which wakes up one process, and <code>broadcast</code>, which wakes up all waiting processes.</p> <p>Semaphores are often used for synchronization. The count typically corresponds to something like the number of bytes available in a pipe buffer or the number of zombie children that a process has. Using an explicit count as part of the abstraction avoids the \u201clost wakeup\u201d problem: there is an explicit count of the number of wakeups that have occurred. The count also avoids the spurious wakeup and thundering herd problems.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#terminating-process","title":"Terminating Process","text":"<p>Terminating processes and cleaning them up introduces much complexity in xv6. In most operating systems it is even more complex, because, for example, the victim process may be deep inside the kernel sleeping, and unwinding\uff08\u5c55\u5f00\uff09 its stack requires much careful programming. Many operating systems unwind the stack using explicit mechanisms for exception handling, such as <code>longjmp</code>.</p> <p>Furthermore, there are other events that can cause a sleeping process to be woken up, even though the event it is waiting for has not happened yet. For example, when a Unix process is sleeping, another process may send a signal to it. In this case, the process will return from the interrupted system call with the value -1 and with the error code set to EINTR. The application can check for these values and decide what to do. Xv6 doesn\u2019t support signals and this complexity doesn\u2019t arise.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#kill-problem","title":"Kill Problem","text":"<p>Xv6\u2019s support for kill is not entirely satisfactory: there are sleep loops which probably should check for p-&gt;killed. A related problem is that, even for sleep loops that check p-&gt;killed, there is a race between sleep and kill; the latter may set p-&gt;killed and try to wake up the victim just after the victim\u2019s loop checks p-&gt;killed but before it calls sleep. If this problem occurs, the victim won\u2019t notice the p-&gt;killed until the condition it is waiting for occurs. This may be quite a bit later (e.g., when the <code>virtio</code> driver returns a disk block that the victim is waiting for) or never (e.g., if the victim is waiting from input from the console, but the user doesn\u2019t type any input).</p> <p>A real operating system would find free proc structures with an explicit free list in constant time instead of the linear-time search in <code>allocproc</code>; xv6 uses the linear scan for simplicity.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#chapter-8-file-system","title":"Chapter 8 File system","text":"<p>The purpose of a file system is to organize and store data. File systems typically support sharing of data among users and applications, as well as persistence so that data is still available after a reboot.</p> <p>The xv6 file system provides Unix-like files, directories, and pathnames (see Chapter 1), and stores its data on a <code>virtio</code> disk for persistence (see Chapter 4). The file system addresses several challenges:</p> <ul> <li> <p>The file system needs on-disk data structures to represent the tree of named directories and files, to record the identities of the blocks that hold each file\u2019s content, and to record which areas of the disk are free.</p> </li> <li> <p>The file system must support crash recovery. That is, if a crash (e.g., power failure) occurs, the file system must still work correctly after a restart. The risk is that a crash might interrupt a sequence of updates and leave inconsistent on-disk data structures (e.g., a block that is both used in a file and marked free).</p> </li> <li> <p>Different processes may operate on the file system at the same time, so the file-system code must coordinate to maintain invariants.</p> </li> <li> <p>Accessing a disk is orders of magnitude slower than accessing memory, so the file system must maintain an in-memory cache of popular blocks.</p> </li> </ul> <p>The rest of this chapter explains how xv6 addresses these challenges.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#81-overview","title":"8.1 Overview","text":"<p>The xv6 file system implementation is organized in seven layers, shown in Figure 8.1.</p> <p></p> <ul> <li> <p>The disk layer reads and writes blocks on an <code>virtio</code> hard drive.</p> </li> <li> <p>The buffer cache layer caches disk blocks and synchronizes access to them, making sure that only one kernel process at a time can modify the data stored in any particular block.</p> </li> <li> <p>The logging layer allows higher layers to wrap updates to several blocks in a transaction, and ensures that the blocks are updated atomically in the face of crashes (i.e., all of them are updated or none).</p> </li> <li> <p>The <code>inode</code> layer provides individual files, each represented as an <code>inode</code> with a unique<code>i-number</code> and some blocks holding the file\u2019s data.</p> </li> <li> <p>The directory layer implements each directory as a special kind of <code>inode</code> whose content is a sequence of directory entries, each of which contains a file\u2019s name and <code>i-number</code>.</p> </li> <li> <p>The pathname layer provides hierarchical path names like <code>/usr/rtm/xv6/fs.c</code>, and resolves them with recursive lookup.</p> </li> <li> <p>The file descriptor layer abstracts many Unix resources (e.g., pipes, devices, files, etc.) using the file system interface, simplifying the lives of application programmers.</p> </li> </ul> <p>The file system must have a plan for where it stores <code>inodes</code> and content blocks on the disk. To do so, xv6 divides the disk into several sections, as Figure 8.2 shows.</p> <p></p> <ul> <li> <p>The file system does not use block 0 (it holds the boot sector).</p> </li> <li> <p>Block 1 is called the superblock; it contains metadata about the file system (the file system size in blocks, the number of data blocks, the number of <code>inodes</code>, and the number of blocks in the log).</p> </li> <li> <p>Blocks starting at 2 hold the log.</p> </li> <li> <p>After the log are the <code>inodes</code>, with multiple <code>inodes</code> per block.</p> </li> <li> <p>After those come bitmap blocks tracking which data blocks are in use.</p> </li> <li> <p>The remaining blocks are data blocks; each is either marked free in the bitmap block, or holds content for a file or directory.</p> </li> </ul> <p>The superblock is filled in by a separate program, called <code>mkfs</code>, which builds an initial file system.</p> <p>super block\u662f\u5bf9\u6574\u4e2a\u6587\u4ef6\u7cfb\u7edf\u7684\u63cf\u8ff0\u3002\u6211\u4eec\u5728\u4e4b\u540e\u8fdb\u884c\u5b9a\u4f4d<code>inode</code>\u7b49\u64cd\u4f5c\u7684\u65f6\u5019\uff0c\u5c31\u9700\u8981super block\u6765\u544a\u8bc9\u6211\u4eec\u5177\u4f53\u7684\u8d77\u59cb\u4f4d\u7f6e\u5728\u54ea\u91cc\u3002</p> <pre><code>#define ROOTINO  1   // root i-number\n#define BSIZE 1024  // block size\n</code></pre> <p>\u6240\u6709\u7684\u6587\u4ef6\u548c\u6587\u4ef6\u5939\u90fd\u662f\u7531<code>inode</code>\u6570\u636e\u7ed3\u6784\u6765\u8868\u793a\u7684\uff0c\u6211\u4eec\u5b9a\u4f4d<code>inode</code>\u4e3b\u8981\u662f\u901a\u8fc7\u5b83\u7684\u7f16\u53f7\uff08\u4f8b\u5982x\uff09\u4f5c\u4e3a\u504f\u79fb\u91cf\uff0c\u5728\u4e0a\u56fe\u6240\u793a\u7684\u7ed3\u6784\u56fe\u4e2d\u5b9a\u4f4d\u4ed6\u6240\u5904\u7684Block\u3002\u5177\u4f53\u7684\u8ba1\u7b97\u65b9\u5f0f\u662f\uff1a<code>sperblock.inodestart + x * inode_size / BSIZE</code>\u3002\u5728<code>xv6</code>\u4e2d\uff0c\u4e00\u4e2a<code>inode</code>\u7684\u5927\u5c0f\u662f64KB\uff0c\u4e00\u4e2aBlock\u7684\u5927\u5c0f\u662f1024KB\u3002\u5728\u78c1\u76d8\u4e0a\uff0c\u901a\u5e38\u7528Sector\u4f5c\u4e3a\u78c1\u76d8\u7684\u6700\u5c0f\u8ba1\u91cf\u5355\u4f4d\uff0c1 sector = 512KB\u3002</p> <pre><code>// Disk layout:\n// [ boot block | super block | log | inode blocks |\n//                                          free bit map | data blocks]\n//\n// mkfs computes the super block and builds an initial file system. The\n// super block describes the disk layout:\nstruct superblock {\n  uint magic;        // Must be FSMAGIC\n  uint size;         // Size of file system image (blocks)\n  uint nblocks;      // Number of data blocks\n  uint ninodes;      // Number of inodes.\n  uint nlog;         // Number of log blocks\n  uint logstart;     // Block number of first log block\n  uint inodestart;   // Block number of first inode block\n  uint bmapstart;    // Block number of first free map block\n};\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#82-buffer-cache-layer","title":"8.2 Buffer cache layer","text":"<p>Buffer cache\u662f\u5bf9\u6574\u4e2a\u6587\u4ef6\u7cfb\u7edf\u7684\u7f13\u5b58\uff0c\u5728\u5176\u4e4b\u4e0a\u7684\u5c42\u53ef\u4ee5\u901a\u8fc7\u5b83\u66f4\u5feb\u7684\u548cdisk\u8fdb\u884c\u4ea4\u4e92\u3002</p> <p>The buffer cache has two jobs:</p> <ul> <li> <p>(1) synchronize access to disk blocks to ensure that</p> </li> <li> <p>only one copy of a block is in memory and that</p> </li> <li> <p>only one kernel thread at a time uses that copy;</p> </li> <li> <p>(2) cache popular blocks so that they don\u2019t need to be re-read from the slow disk. The code is in <code>bio.c</code>.</p> </li> </ul> <p>The main interface exported by the buffer cache consists of <code>bread</code> and <code>bwrite</code>;</p> <ul> <li> <p>the former**(<code>bread</code>)** obtains a <code>buf</code> containing a copy of a block which can be read or modified in memory, and</p> </li> <li> <p>the latter**(<code>bwriter</code>)** writes a modified buffer to the appropriate block on the disk.</p> </li> <li> <p>A kernel thread must release a buffer by calling <code>brelse</code> when it is done with it. The buffer cache uses a per-buffer sleep-lock to ensure that only one thread at a time uses each buffer (and thus each disk block); bread returns a locked buffer, and <code>brelse</code> releases the lock.</p> </li> </ul> <p>\u5f53\u4e0a\u5c42\u8981\u4f7f\u7528\u6ca1\u6709\u7f13\u5b58\u5728buffer\u4e0a\u7684disk\u5185\u5bb9\u65f6\uff0c\u4f7f\u7528LRU\u7b97\u6cd5\u5c06\u6700\u8fd1\u6700\u5c11\u4f7f\u7528\u7684buffer\u4e2d\u7684\u5185\u5bb9\u66ff\u6362\u4e3a\u4e0a\u5c42\u9700\u8981\u7684\u5185\u5bb9\u3002</p> <p>Let\u2019s return to the buffer cache. The buffer cache has a fixed number of buffers to hold disk blocks, which means that if the file system asks for a block that is not already in the cache, the buffer cache must recycle a buffer currently holding some other block. The buffer cache recycles the least recently used buffer for the new block. The assumption is that the least recently used buffer is the one least likely to be used again soon.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#83-code-buffer-cache","title":"8.3 Code: Buffer cache","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#buffer-cache-data-structure","title":"Buffer Cache Data Structure","text":"<p>The buffer cache is a doubly-linked list of buffers. The function <code>binit</code>, called by main (kernel/- main.c:27), initializes the list with the NBUF buffers in the static array <code>buf</code> (kernel/bio.c:43-52). All other access to the buffer cache refer to the linked list via <code>bcache.head</code>, not the <code>buf</code> array.</p> <pre><code>struct {\n  struct spinlock lock;\n  struct buf buf[NBUF];\n\n  // Linked list of all buffers, through prev/next.\n  // Sorted by how recently the buffer was used.\n  // head.next is most recent, head.prev is least.\n  struct buf head;\n} bcache;\n</code></pre> <pre><code>void\nbinit(void)\n{\n  struct buf *b;\n\n  initlock(&amp;bcache.lock, \"bcache\");\n\n  // Create linked list of buffers\n  bcache.head.prev = &amp;bcache.head;\n  bcache.head.next = &amp;bcache.head;\n  for(b = bcache.buf; b &lt; bcache.buf+NBUF; b++){\n    b-&gt;next = bcache.head.next;\n    b-&gt;prev = &amp;bcache.head;\n    initsleeplock(&amp;b-&gt;lock, \"buffer\");\n    bcache.head.next-&gt;prev = b;\n    bcache.head.next = b;\n  }\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#buf-data-structure","title":"<code>Buf</code> Data Structure","text":"<p>\u4e00\u4e2abuffer\u4e2d\u53ea\u80fd\u5b58\u653e\u4e00\u4e2ablock\u4e2d\u7684\u5185\u5bb9\uff0c\u4e5f\u5c31\u662f1024B\u5927\u5c0f\u7684\u5185\u5bb9\u3002</p> <p>A buffer has two state fields associated with it. The field valid indicates that the buffer contains a copy of the block. The field disk indicates that the buffer content has been handed to the disk, which may change the buffer (e.g., write data from the disk into data).</p> <pre><code>struct buf {\n  int valid;   // has data been read from disk?\n  int disk;    // does disk \"own\" buf?\n  uint dev;\n  uint blockno;\n  struct sleeplock lock;\n  uint refcnt;\n  struct buf *prev; // LRU cache list\n  struct buf *next;\n  uchar data[BSIZE];\n};\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#bread","title":"<code>Bread</code>","text":"<p><code>Bread</code> (kernel/bio.c:93) calls <code>bget</code> to get a buffer for the given sector (kernel/bio.c:97). If the buffer needs to be read from disk, <code>bread</code> calls <code>virtio_disk_rw</code> to do that before returning the buffer.</p> <pre><code>// Return a locked buf with the contents of the indicated block.\nstruct buf*\nbread(uint dev, uint blockno)\n{\n  struct buf *b;\n\n  b = bget(dev, blockno);\n  if(!b-&gt;valid) {\n    virtio_disk_rw(b, 0);\n    b-&gt;valid = 1;\n  }\n  return b;\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#sleep-lock","title":"<code>Sleep-Lock</code>","text":"<p>\u4ece\u4e0b\u4e00\u5c0f\u8282\u7684\u4ee3\u7801\u4e2d\u53ef\u4ee5\u77e5\u9053\uff0c<code>Sleep-Lock</code>\u662f\u7528\u6765\u4fdd\u8bc1\u4e00\u4e2abuffer cache\u7684\u552f\u4e00\u8bfb\u5199\u6743\u9650\u7684\u3002\u6bcf\u4e2abuffer cache\u90fd\u6709\u4e00\u5757\u81ea\u5df1\u7684<code>Sleep-Lock</code>\u3002</p> <p>\u65e2\u7136sleep lock\u662f\u57fa\u4e8espinlock\u5b9e\u73b0\u7684\uff0c\u4e3a\u4ec0\u4e48\u5bf9\u4e8eblock cache\uff0c\u6211\u4eec\u4f7f\u7528\u7684\u662fsleep lock\u800c\u4e0d\u662fspinlock\uff1f</p> <p>\u5bf9\u4e8e**spinlock**\u6709\u5f88\u591a\u9650\u5236\uff0c\u5176\u4e2d\u4e4b\u4e00\u662f**\u52a0\u9501\u65f6\u4e2d\u65ad\u5fc5\u987b\u8981\u5173\u95ed**\u3002</p> <p>\u6240\u4ee5\u5982\u679c\u4f7f\u7528spinlock\u7684\u8bdd\uff0c\u5f53\u6211\u4eec\u5bf9block cache\u505a\u64cd\u4f5c\u7684\u65f6\u5019\u9700\u8981\u6301\u6709\u9501\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u6c38\u8fdc\u4e5f\u4e0d\u80fd\u4ece\u78c1\u76d8\u6536\u5230\u6570\u636e\u3002\u6216\u8bb8\u53e6\u4e00\u4e2aCPU\u6838\u53ef\u4ee5\u6536\u5230\u4e2d\u65ad\u5e76\u8bfb\u5230\u78c1\u76d8\u6570\u636e\uff0c\u4f46\u662f\u5982\u679c\u6211\u4eec\u53ea\u6709\u4e00\u4e2aCPU\u6838\u7684\u8bdd\uff0c\u6211\u4eec\u5c31\u6c38\u8fdc\u4e5f\u8bfb\u4e0d\u5230\u6570\u636e\u4e86\u3002</p> <p>\u51fa\u4e8e\u540c\u6837\u7684\u539f\u56e0\uff0c\u4e5f\u4e0d\u80fd\u5728\u6301\u6709spinlock\u7684\u65f6\u5019\u8fdb\u5165sleep\u72b6\u6001\u3002</p> <p>\u6240\u4ee5\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528sleep lock\u3002sleep lock\u7684\u4f18\u52bf\u5c31\u662f\uff0c</p> <ul> <li>\u6211\u4eec\u53ef\u4ee5\u5728\u6301\u6709\u9501\u7684\u65f6\u5019\u4e0d\u5173\u95ed\u4e2d\u65ad\uff08\u6301\u6709\u7684\u662fsleep lock\u800c\u4e0d\u662f\u4ed6\u91cc\u8fb9\u7684spin lock\uff09\u3002\u6211\u4eec\u53ef\u4ee5\u5728\u78c1\u76d8\u64cd\u4f5c\u7684\u8fc7\u7a0b\u4e2d\u6301\u6709\u9501\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u957f\u65f6\u95f4\u6301\u6709\u9501\u3002</li> <li>\u5f53\u6211\u4eec\u5728\u7b49\u5f85sleep lock\u7684\u65f6\u5019\uff0c\u6211\u4eec\u5e76\u6ca1\u6709\u8ba9CPU\u4e00\u76f4\u7a7a\u8f6c\uff0c\u6211\u4eec\u901a\u8fc7sleep\u5c06CPU\u51fa\u8ba9\u51fa\u53bb\u4e86\u3002</li> </ul> <p>\u4ed4\u7ec6\u8bf4\u8bf4\u8fd9\u4e00\u5757\u7684\u4ee3\u7801\u5427\uff0csleep lock\u91cc\u8fb9\u6709\u4e00\u4e2aspin lock\uff0c\u8fd9\u4e2aspinlock\u4fdd\u8bc1\u4e86\u4e00\u6b21\u53ea\u6709\u4e00\u4e2aprocess\u53ef\u4ee5\u83b7\u5f97\u5bf9\u8fd9\u4e2abuffer cache\u7684\u8bbf\u95ee\u6743\u9650\u3002\u7136\u800c\uff0c\u5982\u4e0a\u6587\u6240\u8bf4\uff0cspin lock\u5bfc\u81f4\u4e2d\u65ad\u88ab\u505c\u6b62\uff0c\u6240\u4ee5\u8bfb\u5199\u5c31\u65e0\u6cd5\u8fdb\u884c\u3002\u4e8e\u662f\u5c31\u6709\u4e86\u4e0b\u8fb9\u8fd9\u4e2a\u5de7\u5999\u7684\u8bbe\u8ba1\u3002</p> <p>\u5bf9\u4e8e\u7b2c\u4e00\u4e2a\u62ff\u5230spin lock\u7684\u8fdb\u7a0b\uff0c\u4ed6\u4e0d\u4f1a\u6267\u884cwhile loop\uff0c\u800c\u662f\u76f4\u63a5\u7ed9sleep lock\u4e2d\u7684\u5c5e\u6027locked\u7f6e\u4e3a1\uff08\u8868\u793a\u4e0a\u9501\uff09\uff0c\u6700\u540e\u91ca\u653e\u6389spin lock\uff0c\u4ece\u800c\u4f7f\u5f97\u8bfb\u5199\u64cd\u4f5c\u53ef\u4ee5\u8fdb\u884c\u3002</p> <p>\u5bf9\u4e8e\u5176\u4ed6\u60f3\u8981\u8bfb\u5199\u8fd9\u4e00\u5757buffer cache\u7684\u8fdb\u7a0b\u6765\u8bf4\uff0c\u4ed6\u4eec\u80fd\u83b7\u5f97spin lock\uff0c\u7136\u800c\uff0c\u4ed6\u4eec\u4f1a\u8fdb\u5165while\u5faa\u73af\uff0c\u56e0\u4e3asleep lock\u4e2d\u7684locked\u4e3a1\u3002\u6b64\u65f6\uff0c\u8fd9\u4e00\u5757buffer cache\u88ab\u5176\u4ed6\u8fdb\u7a0b\u5360\u6709\uff0c\u800c\u4e14\u4e0d\u80fd\u7981\u6b62\u4e2d\u65ad\uff0c\u6240\u4ee5while\u5faa\u73af\u4e2d\u53c8\u8c03\u7528\u4e86sleep\u51fd\u6570\u5c06\u8fd9\u4e2a\u8fdb\u7a0b\u7684spinlock\u91ca\u653e\uff0c\u5e76\u4e14\u8ba9\u51faCPU\u4f9b\u5176\u4ed6\u8fdb\u7a0b\u6267\u884c\u3002</p> <pre><code>// Long-term locks for processes\nstruct sleeplock {\n  uint locked;       // Is the lock held?\n  struct spinlock lk; // spinlock protecting this sleep lock\n\n  // For debugging:\n  char *name;        // Name of lock.\n  int pid;           // Process holding lock\n};\n\nvoid\nacquiresleep(struct sleeplock *lk)\n{\n  acquire(&amp;lk-&gt;lk);\n  while (lk-&gt;locked) {\n    sleep(lk, &amp;lk-&gt;lk);\n  }\n  lk-&gt;locked = 1;\n  lk-&gt;pid = myproc()-&gt;pid;\n  release(&amp;lk-&gt;lk);\n}\n\nvoid\nreleasesleep(struct sleeplock *lk)\n{\n  acquire(&amp;lk-&gt;lk);\n  lk-&gt;locked = 0;\n  lk-&gt;pid = 0;\n  wakeup(lk);\n  release(&amp;lk-&gt;lk);\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#bget","title":"<code>Bget</code>","text":"<p><code>Bget</code> (kernel/bio.c:59) scans the buffer list for a buffer with the given device and sector numbers (kernel/bio.c:65-73). If there is such a buffer, <code>bget</code> acquires the sleep-lock for the buffer. <code>Bget</code> then returns the locked buffer.</p> <p>\u8fd9\u91cc\u4f7f\u7528\u4e86\u7761\u7720\u9501\uff0c\u7761\u7720\u9501\u7684\u672c\u8d28\u662f\u65cb\u8f6c\u9501\uff0c\u4f46\u662f\u4ed6\u5e76\u4e0d\u4f1a\u4e00\u76f4while\u5faa\u73af\u5360\u7528CPU\u3002</p> <p>\u8fd9\u91cc\u4f7f\u7528\u7761\u7720\u9501\u7684\u76ee\u7684\u5176\u5b9e\u5c31\u662f\u4e3a\u4e86\u5728\u8fdb\u884cIO\u7684\u8fc7\u7a0b\u4e2d\uff0c\u628aCPU\u8ba9\u6e21\u51fa\u53bb\uff0c\u800c\u4e0d\u662f\u8ba9\u5f53\u524d\u8fdb\u7a0b\u5728CPU\u4e0a\u4e00\u76f4\u7b49\u5f85IO\u3002</p> <pre><code>// Long-term locks for processes\nstruct sleeplock {\n  uint locked;       // Is the lock held?\n  struct spinlock lk; // spinlock protecting this sleep lock\n\n  // For debugging:\n  char *name;        // Name of lock.\n  int pid;           // Process holding lock\n};\n\nvoid\nacquiresleep(struct sleeplock *lk)\n{\n  acquire(&amp;lk-&gt;lk);\n  while (lk-&gt;locked) {\n    sleep(lk, &amp;lk-&gt;lk);\n  }\n  lk-&gt;locked = 1;\n  lk-&gt;pid = myproc()-&gt;pid;\n  release(&amp;lk-&gt;lk);\n}\n</code></pre> <p>If there is no cached buffer for the given sector, <code>bget</code> must make one, possibly reusing a buffer that held a different sector. It scans the buffer list a second time, looking for a buffer that is not in use (<code>b-&gt;refcnt = 0</code>); any such buffer can be used.</p> <p><code>Bget</code> edits the buffer metadata to record the new device and sector number and acquires its sleep-lock. Note that the assignment <code>b-&gt;valid = 0</code> ensures that <code>bread</code> will read the block data from disk rather than incorrectly using the buffer\u2019s previous contents.</p> <pre><code>// Look through buffer cache for block on device dev.\n// If not found, allocate a buffer.\n// In either case, return locked buffer.\nstatic struct buf*\nbget(uint dev, uint blockno)\n{\n  struct buf *b;\n\n  acquire(&amp;bcache.lock);\n\n  // Is the block already cached?\n  for(b = bcache.head.next; b != &amp;bcache.head; b = b-&gt;next){\n    if(b-&gt;dev == dev &amp;&amp; b-&gt;blockno == blockno){\n      b-&gt;refcnt++;\n      release(&amp;bcache.lock);\n      acquiresleep(&amp;b-&gt;lock);\n      return b;\n    }\n  }\n\n  // Not cached.\n  // Recycle the least recently used (LRU) unused buffer.\n  for(b = bcache.head.prev; b != &amp;bcache.head; b = b-&gt;prev){\n    if(b-&gt;refcnt == 0) {\n      b-&gt;dev = dev;\n      b-&gt;blockno = blockno;\n      b-&gt;valid = 0;\n      b-&gt;refcnt = 1;\n      release(&amp;bcache.lock);\n      acquiresleep(&amp;b-&gt;lock);\n      return b;\n    }\n  }\n  panic(\"bget: no buffers\");\n}\n</code></pre> <p>It is important that</p> <ul> <li> <p>there is at most one cached buffer per disk sector,</p> </li> <li> <p>to ensure that readers see writes,</p> </li> <li> <p>and because the file system uses locks on buffers for synchronization.</p> </li> </ul> <p><code>Bget</code> ensures this invariant by holding the <code>bache.lock</code> continuously from the first loop\u2019s check of whether the block is cached through the second loop\u2019s declaration that the block is now cached (by setting dev, <code>blockno</code>, and <code>refcnt</code>). This causes the check for a block\u2019s presence and (if not present) the designation of a buffer to hold the block to be atomic.</p> <p><code>bache.lock</code>\u8d2f\u7a7f\u4e86\u5bf9buffer\u7684\u5c5e\u6027\u7684\u4fee\u6539\uff0c\u4e5f\u5c31\u662f\u8bf4\u6bcf\u6b21\u53ea\u6709\u4e00\u4e2a\u8fdb\u7a0b\u53ef\u4ee5\u5bf9\u6574\u4e2abuffer cache\u8fdb\u884c\u64cd\u4f5c\u3002\u4ece\u800c\uff0c\u4fdd\u8bc1\u4e86\u4e0a\u8ff0\u7684\u4e09\u70b9\u8981\u6c42\u3002</p> <p>It is safe for <code>bget</code> to acquire the buffer\u2019s sleep-lock outside of the <code>bcache.lock</code> critical section, since the non-zero <code>b-&gt;refcnt</code> prevents the buffer from being re-used for a different disk block. The sleep-lock protects reads and writes of the block\u2019s buffered content, while the <code>bcache.lock</code> protects information about which blocks are cached.</p> <p>\u53ef\u4ee5\u770b\u5230sleep lock\u662f\u5728<code>bache.lock</code>\u88ab\u91ca\u653e\u540e\u624d\u53bb\u83b7\u5f97\u7684\uff0c\u8fd9\u4f1a\u4e0d\u4f1a\u5bfc\u81f4\u5f53\u524d\u7684buffer\u88ab\u5f53\u4f5c\u53ef\u66ff\u6362\u7684buffer\u800c\u88ab\u4f7f\u7528\uff0c\u4ece\u800c\u8fdb\u4e00\u6b65\u5bfc\u81f4\u5f53\u524d\u8fdb\u7a0b\u7684buffer\u91cc\u7684\u5185\u5bb9\u4e0d\u662f\u8fdb\u7a0b\u4e00\u5f00\u59cb\u60f3\u8981\u7684\u5185\u5bb9\u5462\uff1f\u5e76\u4e0d\u4f1a\u8fd9\u6837\uff0c\u56e0\u4e3a\u5f53\u524d\u8fdb\u7a0b\u4f7f\u5f97buffer\u7684<code>refcnt++</code>\uff0c\u4e5f\u5c31\u662f\u5f53\u524dbuffer\u5fc5\u7136\u5927\u4e8e\u7b49\u4e8e\u4e00\uff0c\u6240\u4ee5\u4e0d\u5b58\u5728\u88ab\u91ca\u653e\u7684\u98ce\u9669\u3002</p> <p><code>bache.lock</code>\u4fdd\u8bc1\u4e86\u6bcf\u4e2a\u7f13\u5b58\u5c5e\u6027\u7684\u51c6\u786e\u6027\uff08\u4f8b\u5982<code>refcnt, blockno....</code>\uff09\uff0csleep lock\u88ab\u7528\u6765\u4fdd\u8bc1buffer\u4e2d\u5185\u5bb9(<code>char[BSIZE] data</code>)\u4e0d\u4f1a\u88ab\u9519\u8bef\u7684\u4fee\u6539\u3002</p> <p>If all the buffers are busy, then too many processes are simultaneously executing file system calls; <code>bget</code> panics. A more graceful response might be to sleep until a buffer became free, though there would then be a possibility of deadlock.</p> <p>\u6bcf\u4e2abuffer\u88ab\u8fd4\u56de\u7ed9\u4e0a\u5c42\u65f6\uff0c\u4ed6\u90fd\u62ff\u7740\u81ea\u5df1\u7684sleep lock\uff0c\u53ea\u6709\u4e0a\u5c42\u6240\u5904\u7684\u8fdb\u7a0b\u53ef\u4ee5\u5bf9buffer\u91cc\u7684\u5185\u5bb9\u8fdb\u884c\u64cd\u4f5c\u3002\u82e5buffer\u4e2d\u7684\u5185\u5bb9\u88ab\u6539\u53d8\u4e86\uff0c\u90a3\u4e48\u4e0a\u5c42\u5fc5\u987b\u8c03\u7528<code>bwrite</code>\u6765\u5c06buffer\u4e2d\u7684\u5185\u5bb9\u5199\u56dedisk\u3002</p> <p>Once <code>bread</code> has read the disk (if needed) and returned the buffer to its caller, the caller has exclusive use of the buffer and can read or write the data bytes. If the caller does modify the buffer, it must call <code>bwrite</code> to write the changed data to disk before releasing the buffer.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#bwrite","title":"<code>Bwrite</code>","text":"<p><code>Bwrite</code> (kernel/bio.c:107) calls <code>virtio_disk_rw</code> to talk to the disk hardware.</p> <pre><code>// Write b's contents to disk.  Must be locked.\nvoid\nbwrite(struct buf *b)\n{\n  if(!holdingsleep(&amp;b-&gt;lock))\n    panic(\"bwrite\");\n  virtio_disk_rw(b, 1);\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#brelse","title":"<code>Brelse</code>","text":"<p>When the caller is done with a buffer, it must call <code>brelse</code> to release it. (The name <code>brelse</code>, a shortening of b-release, is cryptic but worth learning: it originated in Unix and is used in BSD, Linux, and Solaris too.)</p> <p>\u5728buffer\u88ab\u8fd4\u56de\u7ed9\u4e0a\u5c42\u4e4b\u540e\uff0c\u5f53\u524d\u7684\u8fdb\u7a0b\u59cb\u7ec8\u62e5\u6709\u7740\u5bf9buffer\u4e2d\u5185\u5bb9\u7684\u552f\u4e00\u4f7f\u7528\u6743\uff0c\u5f53\u4f7f\u7528\u5b8c\u6bd5\u540e\uff0c\u5c31\u8981\u91ca\u653e\u4fdd\u8bc1\u8fd9\u4e00\u5207\u7684sleep lock\u3002</p> <p>\u63a5\u7740\uff0c\u5982\u679c\u5f53\u524dbuffer\u7684<code>refcnt==0</code>\uff0c\u90a3\u5c31\u8bc1\u660e\u5f53\u524d\u7684\u8fd9\u4e2abuffer\u662f\u6700\u8fd1\u521a\u4f7f\u7528\u5b8c\u7684\uff0c\u6211\u4eec\u628a\u5b83\u653e\u5728\u94fe\u8868\u7684\u5934\u90e8\u3002\u7531\u6b64\u63a8\u65ad\uff0c\u94fe\u8868\u7684\u5c3e\u90e8\u5c31\u662f\u5f88\u4e45\u4ee5\u524d\u5c31\u4f7f\u7528\u5b8c\u7684buffer\u3002</p> <p><code>Brelse</code> (kernel/bio.c:117) releases the sleep-lock and moves the buffer to the front of the linked list (kernel/bio.c:128-133). Moving the buffer causes the list to be ordered by how recently the buffers were used (meaning released): the first buffer in the list is the most recently used, and the last is the least recently used.</p> <p>\u8fd9\u65f6\u53cd\u89c2<code>bget</code>, \u53ef\u4ee5\u53d1\u73b0\u5728\u5bfb\u627ebuffer\u4e2d\u662f\u5426\u5b58\u6709\u4e0a\u5c42\u8981\u7684\u5185\u5bb9\u65f6\uff0c\u662f\u4ece\u524d\u5f80\u540e\u626b\u63cf\uff0c\u8fd9\u6837\u9047\u5230\u6700\u8fd1\u4f7f\u7528\u8fc7\u7684\u51e0\u7387\u5927\u3002\u5728\u5bfb\u627e\u8981\u88abfree\u5e76\u66ff\u4ee3\u7684buffer\u65f6\uff0c\u662f\u4ece\u540e\u5411\u524d\u626b\u63cf\uff0c\u8fd9\u6837\u9047\u5230LRU\u7684\u6982\u7387\u66f4\u5927\u4e00\u4e9b\u3002</p> <p>The two loops in <code>bget</code> take advantage of this: the scan for an existing buffer must process the entire list in the worst case, but checking the most recently used buffers first (starting at <code>bcache.head</code> and following next pointers) will reduce scan time when there is good locality of reference. The scan to pick a buffer to reuse picks the least recently used buffer by scanning backward (following <code>prev</code> pointers).</p> <pre><code>// Release a locked buffer.\n// Move to the head of the most-recently-used list.\nvoid\nbrelse(struct buf *b)\n{\n  if(!holdingsleep(&amp;b-&gt;lock))\n    panic(\"brelse\");\n\n  releasesleep(&amp;b-&gt;lock);\n\n  acquire(&amp;bcache.lock);\n  b-&gt;refcnt--;\n  if (b-&gt;refcnt == 0) {\n    // no one is waiting for it.\n    b-&gt;next-&gt;prev = b-&gt;prev;\n    b-&gt;prev-&gt;next = b-&gt;next;\n    b-&gt;next = bcache.head.next;\n    b-&gt;prev = &amp;bcache.head;\n    bcache.head.next-&gt;prev = b;\n    bcache.head.next = b;\n  }\n\n  release(&amp;bcache.lock);\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#87-code-block-allocator","title":"8.7 Code: Block allocator","text":"<p>8.3\u8bb2\u7684\u7684\u90fd\u662fMemory\u91cc\u5b58\u50a8\u7684\u7f13\u5b58\uff0c\u4f46\u6211\u4eec\u5728\u5efa\u7acb\u6587\u4ef6\u7684\u65f6\u5019\uff0c\u662f\u8981\u5728\u78c1\u76d8\u4e0a\u7ed9\u6bcf\u4e2a\u6587\u4ef6\u5206\u914d\u4e00\u4e9b\u5730\u65b9\u7684\u3002\u64cd\u4f5c\u7cfb\u7edf\u5c06\u78c1\u76d8\u62bd\u8c61\u6210\u4e86\u8bb8\u591a\u7684BLOCK, \u5e76\u628a\u5176\u4e2d\u4e00\u4e2aBLOCK\u7528\u4f5cbitmap\u7528\u6765\u8bb0\u5f55\u54ea\u4e9bBLOCK\u5df2\u7ecf\u88ab\u5206\u914d\u4e86\u3002</p> <p>bitmap\u662f\u4e00\u4e2aBLOCK SIZE\u5927\u5c0f\u7684\u5757\uff0c\u4e5f\u5c31\u662f1024B\uff0c\u4ed6\u7684\u6bcf\u4e00\u4f4d\u5bf9\u5e94\u7740\u4e00\u4e2a\u5757\u662f\u5426\u88ab\u4f7f\u7528\u3002</p> <p>File and directory content is stored in disk blocks, which must be allocated from a free pool. xv6\u2019s block allocator maintains a free bitmap on disk, with one bit per block.</p> <ul> <li> <p>A zero bit indicates that the corresponding block is free;</p> </li> <li> <p>a one bit indicates that it is in use.</p> </li> </ul> <p>The program <code>mkfs</code> sets the bits corresponding to the boot sector, superblock, log blocks, <code>inode</code> blocks, and bitmap blocks.</p> <p>The block allocator provides two functions:</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#balloc","title":"<code>Balloc</code>","text":"<p><code>balloc</code> allocates a new disk block, and <code>bfree</code> frees a block.</p> <p>\u5148\u6765\u770b\u770b\u4ee3\u7801\u4e2d\u7684\u4e00\u4e9b\u540d\u8bcd\u7684\u610f\u601d</p> <p><code>sb.size</code>: super block\u4e2d\u8bb0\u8f7d\u7740\u7cfb\u7edf\u7684\u63cf\u8ff0\u4fe1\u606f\uff0csize\u6307\u7684\u662f\u603b\u7684block\u6570\u91cf</p> <p><code>BPB</code>: Bitmap bits per block (BSIZE*8) = 1024 x 8bits</p> <p><code>BBLOCK(b, sb) ((b)/BPB + sb.bmapstart)</code> : // Block of free map containing bit for block b</p> <p>The loop in <code>balloc</code> at (kernel/fs.c:71) considers every block, starting at block 0 up to <code>sb.size</code>, the number of blocks in the file system. It looks for a block whose bitmap bit is zero, indicating that it is free. If <code>balloc</code> finds such a block, it updates the bitmap and returns the block. For efficiency, the loop is split into two pieces.</p> <p>The outer loop reads each block of bitmap bits.</p> <p>The inner loop checks all BPB bits in a single bitmap block.</p> <p>The race that might occur if two processes try to allocate a block at the same time is prevented by the fact that the buffer cache only lets one process use any one bitmap block at a time.</p> <p></p> <p><code>Balloc</code>\u5728\u5916\u5c42\u5faa\u73af\u904d\u5386\u6bcf\u4e00\u4e2a\u5757\uff0c\u4ee3\u7801\u4e2db\u6240\u4ee3\u8868\u7684\u5c31\u662f\u6bcf\u4e2a\u5757\u7684\u8d77\u59cb\u5730\u5740</p> <p><code>bp</code>\u5728\u8fd9\u91cc\u5e94\u8be5\u6307\u5411\u7684\u662fbitmap\u7684\u7f13\u5b58\uff0c</p> <p>\u5185\u5faa\u73af\u904d\u5386bitmap\u4e2d\u7684\u6bcf\u4e00\u4e2a\u4f4d\uff0c\u627e\u5230\u4e00\u4e2a\u7a7a\u4f4d\u540e\uff0c\u8fd4\u56de<code>b + bi</code>, \u4e5f\u5c31\u662fBLOCK\u7684\u5e8f\u53f7\uff08\u6309\u7167\u56fe\u4e2d\u7684\u8bbe\u8ba1\u6240\u6709\u7684\u7f16\u53f7\u3002\u4f8b\u598246\uff09</p> <p>\u8fd9\u91cc\u8fd8\u5b58\u6709\u8bb8\u591a\u4e0d\u8fde\u8d2f\u7684\u5730\u65b9\u3002\u6211\u7684\u89e3\u8bfb\u5bf9\u5417\uff1f\u4e3a\u4ec0\u4e48\u8981\u8bbe\u7acb\u4e24\u4e2afor\u5faa\u73af\u5462\uff1f\u5185\u5b58\u91cc\u7684\u6570\u636e\u662f\u600e\u6837\u88ab\u5199\u56de\u78c1\u76d8\u7684\u5462\uff1f<code>bread</code>\u4e2d\u7684<code>blockno</code>\u7a76\u7adf\u662f\u4ee5bit\u4e3a\u5355\u4f4d\u8fd8\u662f\u4ee5\u56fe\u4e2d\u7684\u5e8f\u53f7\u4e3a\u5355\u4f4d\uff1f<code>balloc</code>\u5230\u5e95\u8fd4\u56de\u4e86\u4ec0\u4e48\uff1f</p> <p>\u8fd9\u91cc\u76ee\u524d\u65e0\u6cd5\u7406\u6e05\uff0c\u4f46**\u8fd9\u6bb5\u4ee3\u7801\u6240\u505a\u7684\u4e8b\u662f\u5f88\u660e\u786e\u7684\uff0c\u5728bitmap\u4e2d\u627e\u5230\u4e00\u4e2a\u7a7a\u95f2\u7684block\uff0c\u7136\u540e\u5c06\u8fd9\u4e2ablock\u4ee5\u67d0\u79cd\u5f62\u5f0f\u8fd4\u56de**\u3002</p> <p>\u8fd9\u91cc\u9700\u8981\u540e\u7eed\u7684\u8865\u5145\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01</p> <pre><code>// Allocate a zeroed disk block.`\nstatic uint\nballoc(uint dev)\n{\n  int b, bi, m;\n  struct buf *bp;\n\n  bp = 0;\n  for(b = 0; b &lt; sb.size; b += BPB){\n    bp = bread(dev, BBLOCK(b, sb));\n    for(bi = 0; bi &lt; BPB &amp;&amp; b + bi &lt; sb.size; bi++){\n      m = 1 &lt;&lt; (bi % 8);\n      if((bp-&gt;data[bi/8] &amp; m) == 0){  // Is block free?\n        bp-&gt;data[bi/8] |= m;  // Mark block in use.\n        log_write(bp);\n        brelse(bp);\n        bzero(dev, b + bi);\n        return b + bi;\n      }\n    }\n    brelse(bp);\n  }\n  panic(\"balloc: out of blocks\");\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#bfree","title":"<code>Bfree</code>","text":"<p><code>Bfree</code> (kernel/fs.c:90) finds the right bitmap block and clears the right bit. Again the exclusive use implied by <code>bread</code> and <code>brelse</code> avoids the need for explicit locking.</p> <pre><code>// Free a disk block.\nstatic void\nbfree(int dev, uint b)\n{\n  struct buf *bp;\n  int bi, m;\n\n  bp = bread(dev, BBLOCK(b, sb));\n  bi = b % BPB;\n  m = 1 &lt;&lt; (bi % 8);\n  if((bp-&gt;data[bi/8] &amp; m) == 0)\n    panic(\"freeing free block\");\n  bp-&gt;data[bi/8] &amp;= ~m;\n  log_write(bp);\n  brelse(bp);\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#88-inode-layer","title":"8.8 <code>Inode</code> layer","text":"<p><code>Inode</code>\u662f\u5bf9BLOCK\u7684\u518d\u4e00\u6b21\u62bd\u8c61\uff0c\u6211\u4eec\u4e0d\u53ef\u80fd\u4ec5\u4ec5\u628a\u6587\u4ef6\u5b58\u50a8\u5728\u4e00\u4e2aBLOCK\u91cc\u8fb9\uff0c<code>Inode</code>\u5c31\u662f\u4e00\u4e2aBLOCK\u7684\u96c6\u5408\uff0c\u8ba9\u6211\u4eec\u53ef\u4ee5\u5b58\u50a8\u66f4\u5927\u7684\u6587\u4ef6\u3002</p> <p>The term <code>inode</code> can have one of two related meanings.</p> <ul> <li> <p>It might refer to the on-disk data structure containing a file\u2019s size and list of data block numbers. Or</p> </li> <li> <p><code>\u201cinode\u201d</code> might refer to an <code>in-memory inode</code>, which contains a copy of the on-disk <code>inode</code> as well as extra information needed within the kernel.</p> </li> </ul>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#on-disk-inodes","title":"on-disk <code>inodes</code>","text":"<p>on-disk <code>inodes</code> \u5b58\u50a8\u5728BLOCK32 \u2192 BLOCK44\u4e4b\u95f4\uff0c\u6bcf\u4e2a**on-disk <code>inodes</code>** \u90fd\u6709\u7740\u56fa\u5b9a\u7684\u5927\u5c0f64B\uff0c\u4ece\u800c\uff0c\u6211\u4eec\u53ef\u4ee5\u77e5\u9053Xv6\u64cd\u4f5c\u7cfb\u7edf\u80fd\u6709\u591a\u5c11**on-disk <code>inodes</code>** \uff0c\u6362\u53e5\u8bdd\u8bf4\u5c31\u662f\u80fd\u521b\u5efa\u591a\u5c11\u4e2a\u6587\u4ef6\u3002</p> <p>The on-disk <code>inodes</code> are packed into a contiguous area of disk called the <code>inode blocks</code>. Every <code>inode</code> is the same size, so it is easy, given a number n, to find the <code>nth inode</code> on the disk. In fact, this number n, called the**<code>inode number</code> or <code>i-number</code>,** is how <code>inodes</code> are identified in the implementation.</p> <p>The on-disk <code>inode</code> is defined by a struct <code>dinode</code> (kernel/fs.h:32).</p> <ul> <li> <p>The type field distinguishes between files, directories, and special files (devices). A type of zero indicates that an on disk<code>inode</code> is free.</p> </li> <li> <p>The <code>nlink</code> field counts the number of directory entries that refer to this <code>inode</code>, in order to recognize when the on-disk <code>inode</code> and its data blocks should be freed.</p> </li> <li> <p>The size field records the number of bytes of content in the file.</p> </li> <li> <p>The <code>addrs</code> array records the block numbers of the disk blocks holding the file\u2019s content.</p> </li> </ul> <pre><code>// On-disk inode structure\nstruct dinode {\n  short type;           // File type\n  short major;          // Major device number (T_DEVICE only)\n  short minor;          // Minor device number (T_DEVICE only)\n  short nlink;          // Number of links to inode in file system\n  uint size;            // Size of file (bytes)\n  uint addrs[NDIRECT+1];   // Data block addresses\n};\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#in-memory-inode","title":"in-memory <code>inode</code>","text":"<p>\u5185\u5b58\u4e2d\u7684<code>inodes</code>\u591a\u4e86\u4e00\u4e9b\u65b0\u7279\u6027\uff0c\u53ea\u6709C\u6307\u9488\u6307\u5411\u7684 <code>inodes</code>\u624d\u6709\u8d44\u683c\u88ab\u52a0\u8f7d\u5230\u5185\u5b58\u4e2d\u3002</p> <p>The kernel keeps the set of active <code>inodes</code> in memory; struct <code>inode</code> (kernel/file.h:17) is the in-memory copy of a struct <code>dinode</code> on disk.</p> <p>The kernel stores an <code>inode</code> in memory only if there are C pointers referring to that <code>inode</code>.</p> <p>The ref field counts the number of C pointers referring to the in-memory <code>inode</code>, and the kernel discards the <code>inode</code> from memory if the reference count drops to zero.</p> <pre><code>// in-memory copy of an inode\nstruct inode {\n  uint dev;           // Device number\n  uint inum;          // Inode number\n  int ref;            // Reference count\n  struct sleeplock lock; // protects everything below here\n  int valid;          // inode has been read from disk?\n\n  short type;         // copy of disk inode\n  short major;\n  short minor;\n  short nlink;\n  uint size;\n  uint addrs[NDIRECT+1];\n};\n</code></pre> <p>The <code>iget</code> and <code>iput</code> functions acquire and release pointers to an <code>inode</code>, modifying the reference count. Pointers to an <code>inode</code> can come from file descriptors, current working directories, and transient kernel code such as <code>exec</code>.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#lock-in-inode","title":"Lock in <code>Inode</code>","text":"<p>\u56e0\u4e3a<code>inodes</code>\u5728\u5185\u6838\u4e2d\u4e5f\u4f1a\u88ab\u7f13\u5b58\uff0c\u6240\u4ee5\u548cbuffer cache\u5f88\u76f8\u4f3c\uff0c<code>inodes</code>\u4e5f\u6709\u4e00\u628a\u5927\u9501\u7528\u6765\u4fdd\u8bc1<code>inodes</code>\u7684\u539f\u5b50\u6027\uff08\u5185\u5b58\u4e2d\u4e0d\u4f1a\u6709\u91cd\u590d\u7684<code>inodes</code>\uff0c\u5185\u6838\u5bf9<code>inodes</code>\u7684\u5f15\u7528\u8ba1\u6570\u4e5f\u662f\u6b63\u786e\u7684\uff09\u3002\u6bcf\u4e2a<code>inodes</code>\u91cc\u8fb9\u4e5f\u6709\u4e00\u628a\u5c0f\u9501\uff08\u7761\u7720\u9501\uff09\uff0c\u7528\u6765\u4fdd\u8bc1\u8be5\u6587\u4ef6\u7684\u72ec\u4eab\u8bbf\u95ee\u6743\u9650\u3002</p> <p>There are four lock or lock-like mechanisms in xv6\u2019s <code>inode</code> code.</p> <p><code>icache.lock</code> protects the invariant that an <code>inode</code> is present in the cache at most once, and the invariant that a cached <code>inode\u2019s</code> ref field counts the number of in-memory pointers to the cached <code>inode</code>.</p> <p>Each in-memory <code>inode</code> has a lock field containing a sleep-lock, which ensures exclusive access to the <code>inode\u2019s</code> fields (such as file length) as well as to the <code>inode\u2019s</code> file or directory content blocks.</p> <p>\u4e00\u4e2a\u5728\u5185\u5b58\u4e2d\u7684<code>inode</code>, \u5982\u679c\u4ed6\u7684ref\uff08\u6307\u5411<code>inode</code>\u7684C\u6307\u9488\u7684\u6570\u91cf\uff09\u5927\u4e8e0\uff0c\u90a3\u4e48\u5185\u6838\u5c31\u8981\u5728\u5185\u5b58\u4e2d\u7ef4\u62a4\u8fd9\u4e2a<code>inode</code>\u5e76\u4e14\u4e0d\u4f1a\u91cd\u7528\u8fd9\u4e2a<code>inode</code>\u7684cache entry\u3002</p> <p><code>nlink</code>\u8bb0\u5f55\u7684\u662f\u6307\u5411\u8fd9\u4e2a\u6587\u4ef6\u7684\u6587\u4ef6\u5939\u7684\u4e2a\u6570\uff0c\u53ea\u6709<code>nlink</code>\u4e3a0\u7684\u65f6\u5019\uff0c\u7cfb\u7edf\u624d\u4f1afree\u8fd9\u4e2a<code>inode</code>\u3002</p> <p>An <code>inode\u2019s</code> ref, if it is greater than zero, causes the system to maintain the <code>inode</code> in the cache, and not re-use the cache entry for a different <code>inode</code>. Finally, each <code>inode</code> contains a <code>nlink</code> field (on disk and copied in memory if it is cached) that counts the number of directory entries that refer to a file; xv6 won\u2019t free an <code>inode</code> if its link count is greater than zero.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#life-cycle-of-inode","title":"Life Cycle of <code>inode</code>","text":"<p>\u6211\u4eec\u83b7\u53d6\u5230\u7684\u5185\u5b58\u4e2d\u7684<code>inodes</code>\u5982\u4e0b\u7279\u6027\u3002</p> <p>\u6bcf\u4e2a\u8fdb\u7a0b\u90fd\u53ef\u4ee5\u6307\u5411\u540c\u4e00\u4e2a<code>inodes</code>\uff0c\u8fd9\u79cd\u8bbe\u8ba1\u6709\u70b9\u8bfb\u5199\u9501\u7684\u610f\u601d\uff0c\u6211\u4eec\u5728\u7528\u6587\u4ef6\u7cfb\u7edf\u7684\u65f6\u5019\uff0c\u4f1a\u7ecf\u5e38\u5728\u76f8\u540c\u7684\u8def\u5f84\u4e0b\u627e\u4e0d\u540c\u7684\u6587\u4ef6\uff0c\u5982\u679c\u8bbe\u7f6e\u9501\u7684\u8bdd\uff0c\u90a3\u4e48\u5982\u679c\u6211\u4eec\u6253\u5f00\u4e86\u8def\u5f84a/b/c\uff0c\u90a3\u4e48\u5176\u4ed6\u4efb\u4f55\u8fdb\u7a0b\u90fd\u65e0\u6cd5\u518d\u8bbf\u95ee\u8fd9\u4e2a\u8def\u5f84\u4e86\u3002</p> <p>\u5f53\u7136\uff0c\u5728\u5bf9<code>inodes</code>\u8fdb\u884c\u5199\u7684\u64cd\u4f5c\u65f6\uff0c\u4f8b\u5982\uff1a\u52a0\u8f7ddisk\u7684\u5185\u5bb9\u5230<code>inodes</code>\u4ee5\u53ca\u5199\u5165<code>inodes</code>\uff0c\u53ea\u6709\u4e00\u4e2a\u8fdb\u7a0b\u53ef\u4ee5\u72ec\u4eab\u8fd9\u4e2a\u8d44\u6e90\u3002</p> <p>A struct <code>inode</code> pointer returned by <code>iget()</code> is guaranteed to be valid until the corresponding call to <code>iput()</code>; the <code>inode</code> won\u2019t be deleted, and the memory referred to by the pointer won\u2019t be re-used for a different <code>inode</code>.</p> <p><code>iget()</code> provides non-exclusive access to an <code>inode</code>, so that there can be many pointers to the same <code>inode</code>. Many parts of the file-system code depend on this behavior of <code>iget()</code>, both to hold long-term references to <code>inodes</code> (as open files and current directories) and to prevent races while avoiding deadlock in code that manipulates multiple <code>inodes</code> (such as pathname lookup).</p> <p>The struct <code>inode</code> that <code>iget</code> returns may not have any useful content. In order to ensure it holds a copy of the <code>on-disk inode</code>, code must call <code>ilock</code>. This locks the <code>inode</code> (so that no other process can <code>ilock</code> it) and reads the <code>inode</code> from the disk, if it has not already been read. <code>iunlock</code>releases the lock on the <code>inode</code>. Separating acquisition of <code>inode</code> pointers from locking helps avoid deadlock in some situations, for example during directory lookup. Multiple processes can hold a C pointer to an <code>inode</code> returned by <code>iget</code>, but only one process can lock the <code>inode</code> at a time.</p> <p>\u5185\u5b58\u4e2d\u7684<code>inodes</code>\u76ee\u7684\u5e76\u4e0d\u5728\u4e8e\u7f13\u5b58\uff0c\u800c\u5728\u4e8e\u540c\u6b65\u4e0d\u540c\u8fdb\u7a0b\u5bf9\u8d44\u6e90\u7684\u8bf7\u6c42\u3002</p> <p><code>inodes</code>\u7f13\u5b58\u7684\u53e6\u4e00\u5927\u7279\u70b9\u662f\u5199\u5b8c\u5c31\u8981\u540c\u6b65\u5230disk</p> <p>The <code>inode</code> cache only caches <code>inodes</code> to which kernel code or data structures hold C pointers. Its main job is really synchronizing access by multiple processes; caching is secondary. If an <code>inode</code> is used frequently, the buffer cache will probably keep it in memory if it isn\u2019t kept by the <code>inode</code> cache. The <code>inode</code> cache is write-through, which means that code that modifies a cached <code>inode</code> must immediately write it to disk with <code>iupdate</code>.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#89-code-inodes","title":"8.9 Code: <code>Inodes</code>","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#ialloc","title":"<code>ialloc</code>","text":"<p><code>ialloc</code> \u5c31\u662f\u521b\u5efa\u6587\u4ef6\u5b9e\u73b0\uff0c\u5b83\u7684\u539f\u7406\u5f88\u7b80\u5355\uff0c\u628adisk\u4e0a<code>inodes</code>\u90a3\u4e00\u6bb5BLOCK\u52a0\u8f7d\u5230buffer cache\u4e2d\uff0c\u7136\u540e\u5728\u5176\u4e2d\u627e\u5230\u4e00\u4e2a\u7a7a\u95f2\u7684<code>inodes</code></p> <p>\u63a5\u7740\u5c31\u6539\u53d8<code>inodes</code>\u7684\u5c5e\u6027type\u8868\u660e\u5b83\u5df2\u7ecf\u88ab\u5360\u7528</p> <p>\u6700\u540e\u7528<code>iget()</code>\u65b9\u6cd5\u8fd4<code>inodes</code>\u5728\u5185\u5b58\u4e2d\u7684\u7f13\u5b58</p> <p>\u8fd9\u91cc\uff0c\u5e76\u6ca1\u6709\u7528\u5230\u9501\uff0c\u56e0\u4e3abuffer cache\u4fdd\u8bc1\u4e86\u6bcf\u6b21\u53ea\u6709\u4e00\u4e2aprocess\u53ef\u4ee5\u4fee\u6539\u4e00\u4e2ablock</p> <p>To allocate a new <code>inode</code> (for example, when creating a file), xv6 calls <code>ialloc</code> (kernel/fs.c:196). <code>Ialloc</code> is similar to <code>balloc</code>:</p> <ul> <li> <p>it loops over the <code>inode</code> structures on the disk, one block at a time, looking for one that is marked free.</p> </li> <li> <p>When it finds one, it claims it by writing the new type to the disk and then</p> </li> <li> <p>returns an entry from the <code>inode</code> cache with the tail call to <code>iget</code> (kernel/fs.c:210).</p> </li> </ul> <p>The correct operation of <code>ialloc</code> depends on the fact that only one process at a time can be holding a reference to <code>bp</code>: <code>ialloc</code> can be sure that some other process does not simultaneously see that the <code>inode</code> is available and try to claim it.</p> <pre><code>// Allocate an inode on device dev.\n// Mark it as allocated by  giving it type type.\n// Returns an unlocked but allocated and referenced inode.\nstruct inode*\nialloc(uint dev, short type)\n{\n  int inum;\n  struct buf *bp;\n  struct dinode *dip;\n\n  for(inum = 1; inum &lt; sb.ninodes; inum++){\n    bp = bread(dev, IBLOCK(inum, sb));\n    dip = (struct dinode*)bp-&gt;data + inum%IPB;\n    if(dip-&gt;type == 0){  // a free inode\n      memset(dip, 0, sizeof(*dip));\n      dip-&gt;type = type;\n      log_write(bp);   // mark it allocated on the disk\n      brelse(bp);\n      return iget(dev, inum);\n    }\n    brelse(bp);\n  }\n  panic(\"ialloc: no inodes\");\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#iget","title":"<code>Iget</code>","text":"<p>\u4e66\u63a5\u4e0a\u6587\uff0c\u4e0a\u4e00\u6b65\uff0c\u6211\u4eec\u5728<code>inode</code> BLOCK\u4e2d\u62ff\u5230\u4e86\u4e00\u4e2a\u65b0\u7684<code>inode</code>\uff0c\u6211\u4eec\u4e0b\u4e00\u6b65\u8981\u505a\u7684\u5c31\u662f\u628a\u8fd9\u4e2a\u65b0\u7684<code>inode</code>\u653e\u8fdb<code>inode</code> \u7f13\u5b58\u4e2d\u3002\uff08Xv6\u7ef4\u62a4\u4e86\u4e24\u4e2a\u7f13\u5b58\uff0c\u4e00\u4e2a\u662fBLOCK\u7684\u7f13\u5b58\uff0c\u53e6\u4e00\u4e2a\u662f<code>inode</code>\u7684\u7f13\u5b58\uff0c\u5177\u4f53\u67e5\u770b8.3\uff0c8.7)\u3002</p> <p>\u8fd9\u91cc\u5176\u5b9e\u903b\u8f91\u4e5f\u5f88\u7b80\u5355\uff0c\u5982\u679c\u6709\u7684\u8bdd\u5c31\u8fd4\u56de\uff0c\u6ca1\u6709\u7684\u8bdd\u5c31\u627e\u4e00\u4e2a\u6709\u7a7a\u95f2\u4f4d\u7f6e\u7684\u7f13\u5b58\u7528\u4e8e\u5b58\u653e\u8fd9\u4e2a\u65b0\u7684<code>inode</code>\u3002</p> <p><code>Iget</code> (kernel/fs.c:243) looks through the <code>inode</code> cache for an active entry (<code>ip-&gt;ref &gt; 0</code>) with the desired device and <code>inode</code> number. If it finds one, it returns a new reference to that <code>inode</code> (kernel/fs.c:252-256). As <code>iget</code> scans, it records the position of the first empty slot (kernel/fs.c:257- 258), which it uses if it needs to allocate a cache entry.</p> <pre><code>// Find the inode with number inum on device dev\n// and return the in-memory copy. Does not lock\n// the inode and does not read it from disk.\nstatic struct inode*\niget(uint dev, uint inum)\n{\n  struct inode *ip, *empty;\n\n  acquire(&amp;icache.lock);\n\n  // Is the inode already cached?\n  empty = 0;\n  for(ip = &amp;icache.inode[0]; ip &lt; &amp;icache.inode[NINODE]; ip++){\n    if(ip-&gt;ref &gt; 0 &amp;&amp; ip-&gt;dev == dev &amp;&amp; ip-&gt;inum == inum){\n      ip-&gt;ref++;\n      release(&amp;icache.lock);\n      return ip;\n    }\n    if(empty == 0 &amp;&amp; ip-&gt;ref == 0)    // Remember empty slot.\n      empty = ip;\n  }\n\n  // Recycle an inode cache entry.\n  if(empty == 0)\n    panic(\"iget: no inodes\");\n\n  ip = empty;\n  ip-&gt;dev = dev;\n  ip-&gt;inum = inum;\n  ip-&gt;ref = 1;\n  ip-&gt;valid = 0;\n  release(&amp;icache.lock);\n\n  return ip;\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#ilock","title":"<code>ilock</code>","text":"<p>\u5728Buffer Cache\u4e2d\u53ef\u4ee5\u5f97\u77e5\uff0c\u9047\u5230\u6709\u7f13\u5b58\u7684\u95ee\u9898\uff0c\u6211\u4eec\u5c31\u8981\u60f3\u529e\u6cd5\u89e3\u51b3\u591a\u7ebf\u7a0b\u7684\u95ee\u9898\u3002\u8fd9\u4e00\u8282\u7684\u524d\u4e00\u90e8\u5206\uff0c\u6211\u4eec\u77e5\u9053\uff0c<code>inode</code> cache\u5916\u8fb9\u6709\u628a\u5927\u9501\uff0c\u6bcf\u4e2a<code>inode</code>\u7f13\u5b58\u4e2d\u6709\u628a\u5c0f\u9501\u3002\u8fd9\u4e2a<code>ilock</code>\u5c31\u662f\u90a3\u4e2a\u5c0f\u9501\uff0c\u4ed6\u7684\u672c\u8d28\u662f\u4e00\u4e2asleep lock\u3002</p> <p><code>ilock</code>\u7684\u5de5\u4f5c\u5185\u5bb9\u662f\u628adisk\u91cc<code>dinode</code>\u7684\u5185\u5bb9\u8bfb\u5230\u7f13\u5b58\u4e2d\u7684<code>inode</code>\u91cc\u8fb9\u53bb\u3002</p> <p>\u76ee\u524d\u8fd8\u4e0d\u662f\u5f88\u660e\u767d\u4ed6\u7684\u5e94\u7528\u573a\u666f\u5728\u54ea\u91cc</p> <p>\u540e\u7eed\u8865\u5145\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01</p> <p>Code must lock the <code>inode</code> using <code>ilock</code> before reading or writing its metadata or content.</p> <p><code>ilock</code> (kernel/fs.c:289) uses a <code>sleep-lock</code> for this purpose.</p> <p>Once <code>ilock</code> has exclusive access to the <code>inode</code>, it reads the <code>inode</code> from disk (more likely, the buffer cache) if needed. The function <code>iunlock</code> (kernel/fs.c:317) releases the sleep-lock, which may cause any processes sleeping to be woken up.</p> <pre><code>// Lock the given inode.\n// Reads the inode from disk if necessary.\nvoid\nilock(struct inode *ip)\n{\n  struct buf *bp;\n  struct dinode *dip;\n\n  if(ip == 0 || ip-&gt;ref &lt; 1)\n    panic(\"ilock\");\n\n  acquiresleep(&amp;ip-&gt;lock);\n\n  if(ip-&gt;valid == 0){\n    bp = bread(ip-&gt;dev, IBLOCK(ip-&gt;inum, sb));\n    dip = (struct dinode*)bp-&gt;data + ip-&gt;inum%IPB;\n    ip-&gt;type = dip-&gt;type;\n    ip-&gt;major = dip-&gt;major;\n    ip-&gt;minor = dip-&gt;minor;\n    ip-&gt;nlink = dip-&gt;nlink;\n    ip-&gt;size = dip-&gt;size;\n    memmove(ip-&gt;addrs, dip-&gt;addrs, sizeof(ip-&gt;addrs));\n    brelse(bp);\n    ip-&gt;valid = 1;\n    if(ip-&gt;type == 0)\n      panic(\"ilock: no type\");\n  }\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#iput","title":"<code>Iput</code>","text":"<p><code>Iput</code>\u6d89\u53ca\u7684\u662f<code>inode</code>\u7f13\u5b58\u7684\u91ca\u653e\uff0c\u82e5\u662f\u6ca1\u6709C\u6307\u9488\u6307\u5411\u5b83\uff0c\u90a3\u7f13\u5b58\u5c31\u6ca1\u6709\u5fc5\u8981\u4e86\uff1b</p> <p>\u82e5\u662flinks\uff08\u6587\u4ef6\u91cc\u4e5f\u6ca1\u6709\u8fd9\u4e2a<code>inode</code>\u4e86\uff09\u4e5f\u7b49\u4e8e0\uff0c\u90a3\u4e48\u5bf9\u5e94\u7684BLOCK\u4e5f\u5c31\u8981\u88ab\u6e05\u7406\u4e86\u3002</p> <p><code>Iput</code> (kernel/fs.c:333) releases a C pointer to an <code>inode</code> by decrementing the reference count (kernel/fs.c:356). If this is the last reference, the <code>inode\u2019s</code>slot in the <code>inode</code> cache is now free and can be re-used for a different <code>inode</code>.</p> <p>If <code>iput</code> sees that there are no C pointer references to an <code>inode</code> and that the <code>inode</code> has no links to it (occurs in no directory), then the <code>inode</code> and its data blocks must be freed. <code>Iput</code> calls <code>itrunc</code> to truncate the file to zero bytes, freeing the data blocks; sets the <code>inode</code> type to 0 (unallocated); and writes the <code>inode</code> to disk (kernel/fs.c:338).</p> <pre><code>// Drop a reference to an in-memory inode.\n// If that was the last reference, the inode cache entry can\n// be recycled.\n// If that was the last reference and the inode has no links\n// to it, free the inode (and its content) on disk.\n// All calls to iput() must be inside a transaction in\n// case it has to free the inode.\nvoid\niput(struct inode *ip)\n{\n  acquire(&amp;icache.lock);\n\n  if(ip-&gt;ref == 1 &amp;&amp; ip-&gt;valid &amp;&amp; ip-&gt;nlink == 0){\n    // inode has no links and no other references: truncate and free.\n\n    // ip-&gt;ref == 1 means no other process can have ip locked,\n    // so this acquiresleep() won't block (or deadlock).\n    acquiresleep(&amp;ip-&gt;lock);\n\n    release(&amp;icache.lock);\n\n    itrunc(ip);\n    ip-&gt;type = 0;\n    iupdate(ip);\n    ip-&gt;valid = 0;\n\n    releasesleep(&amp;ip-&gt;lock);\n\n    acquire(&amp;icache.lock);\n  }\n\n  ip-&gt;ref--;\n  release(&amp;icache.lock);\n}\n</code></pre> <p>The locking protocol in <code>iput</code> in the case in which it frees the <code>inode</code> deserves a closer look.</p> <p>\u9700\u8981\u7406\u6e05\u8fd9\u91cc\u7684\u9501\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4e3b\u8981\u662f\u7b2c\u4e8c\u6bb5</p> <p>\u8fd9\u91cc\u6d89\u53ca\u5bf9sleep lock\u7684\u7406\u89e3</p> <p>\u4e4b\u540e\u9700\u8981\u8865\u5145\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01\uff01</p> <p>One danger is that a concurrent thread might be waiting in <code>ilock</code> to use this <code>inode</code> (e.g., to read a file or list a directory), and won\u2019t be prepared to find that the <code>inode</code> is not longer allocated. This can\u2019t happen because there is no way for a system call to get a pointer to a cached <code>inode</code> if it has no links to it and<code>ip-&gt;ref</code> is one. That one reference is the reference owned by the thread calling <code>iput</code>. It\u2019s true that <code>iput</code> checks that the reference count is one outside of its <code>icache.lock</code> critical section, but at that point the link count is known to be zero, so no thread will try to acquire a new reference.</p> <p>The other main danger is that a concurrent call to <code>ialloc</code> might choose the same <code>inode</code> that <code>iput</code> is freeing. This can only happen after the <code>iupdate</code> writes the disk so that the <code>inode</code> has type zero. This race is benign; the allocating thread will politely wait to acquire the <code>inode\u2019s</code> sleep-lock before reading or writing the <code>inode</code>, at which point <code>iput</code> is done with it.</p> <p>\u8fd9\u91cc\u5f15\u51fa\u4e00\u4e2a\u6709\u610f\u601d\u7684\u70b9\uff0c\u6587\u4ef6\u7cfb\u7edf\u7684system call\u53ef\u80fd\u90fd\u4f1a\u6d89\u53ca\u5230\u78c1\u76d8\u7684\u5199\u5165\uff0c\u5373\u4f7f\u662f\u4e00\u4e2a\u8bfb\u8fdb\u7a0b\u3002</p> <p>\u53ef\u4ee5\u60f3\u8c61\uff0c\u4e00\u4e2a\u8fdb\u7a0b\u5b8c\u6210\u4e86\u6587\u4ef6\u7684\u5199\u5165\uff0c\u4f46\u8fd9\u8fd8\u505c\u7559\u5728\u7f13\u5b58\u7684\u5c42\u9762\u3002\u56e0\u4e3a\u6b64\u65f6\u8fd8\u6709\u4e00\u4e2a\u8fdb\u7a0b\u5728\u8bfb\u8fd9\u4e2a\u6587\u4ef6\uff0c\u5199\u5165\u7684\u4ee3\u7801\u8fd8\u662f\u65e0\u6cd5\u89e6\u53d1\uff0c\u5f53\u6211\u4eec\u5173\u95ed\u4e86\u8bfb\u8fdb\u7a0b\u4e4b\u540e\uff0c<code>iput</code>\u8fdb\u5165\u4e86\u56de\u6536\u6a21\u5f0f\uff0c\u8fd9\u624d\u628a\u5199\u8fdb\u7a0b\u5199\u5b8c\u7684\u5185\u5b58\u5199\u5165\u4e86disk\u4e0a\u3002</p> <p><code>iput()</code> can write to the disk. This means that any system call that uses the file system may write the disk, because the system call may be the last one having a reference to the file. Even calls like <code>read()</code> that appear to be read-only, may end up calling <code>iput()</code>. This, in turn, means that even read-only system calls must be wrapped in transactions if they use the file system.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#iput-and-crashes","title":"<code>iput()</code> and <code>crashes</code>","text":"<p>\u8fd9\u91cc\u5f15\u51fa\u4e86\u4e00\u4e2a\u6709\u8da3\u7684\u95ee\u9898\uff0c<code>iput()</code>\u4ee3\u7801\u5728<code>inode</code> link\u7b49\u4e8e0\u65f6\u5e76\u6ca1\u6709\u9009\u62e9\u53bb\u5427disk\u4e2d\u7684\u5185\u5bb9\u5220\u9664\uff0c\u800c\u662f\u9009\u62e9\u7ee7\u7eed\u8ba9\u8fdb\u7a0b\u5bf9\u7f13\u5b58\u4e2d\u7684\u5185\u5bb9\u8fdb\u884c\u8bfb\u5199\u3002</p> <p>\u8fd9\u6837\u4f1a\u5f15\u53d1\u4e00\u4e2a\u95ee\u9898\uff0c\u82e5\u6587\u4ef6\u7cfb\u7edf\u5728\u6211\u4eec\u628a\u8fd9\u4e9b\u5185\u5bb9\u5f7b\u5e95\u5199\u5165disk\u4e4b\u524d\u51fa\u73b0\u4e86crash\uff0c\u90a3\u4e48\u8fd9\u4e2a\u6587\u4ef6\u4f1a\u88ab\u8ba4\u4e3a\u662f\u5b58\u5728\u4e8edisk\u4e0a\u7684\uff08<code>inode</code>\u5185\u5bb9\u6ca1\u6709\u88ab\u6e05\u96f6\uff09\uff0c\u4f46\u662f\u4e8b\u5b9e\u4e0a\u6587\u4ef6\u5939\u4e2d\u5df2\u7ecf\u6ca1\u6709\u8fd9\u4e2a\u6587\u4ef6\u4e86\u3002</p> <p>Xv6\u5e76\u6ca1\u6709\u5bf9\u8fd9\u4e00\u95ee\u9898\u4f5c\u51fa\u5904\u7406\uff0c\u8fd9\u4e5f\u5c31\u610f\u5473\u7740\uff0c\u4f1a\u51fa\u73b0disk\u5b58\u50a8\u7684\u6cc4\u9732\u3002</p> <p>There is a challenging interaction between <code>iput()</code> and <code>crashes</code>. <code>iput()</code> doesn\u2019t truncate a file immediately when the link count for the file drops to zero, because some process might still hold a reference to the <code>inode</code> in memory: a process might still be reading and writing to the file, because it successfully opened it.</p> <p>But, if a crash happens before the last process closes the file descriptor for the file, then the file will be marked allocated on disk but no directory entry will point to it.</p> <p>File systems handle this case in one of two ways.</p> <ul> <li> <p>The simple solution is that on recovery, after reboot, the file system scans the whole file system for files that are marked allocated, but have no directory entry pointing to them. If any such file exists, then it can free those files.</p> </li> <li> <p>The second solution doesn\u2019t require scanning the file system. In this solution, the file system records on disk (e.g., in the super block) the <code>inode inumber</code> of a file whose link count drops to zero but whose reference count isn\u2019t zero. If the file system removes the file when its reference counts reaches 0, then it updates the on-disk list by removing that <code>inode</code> from the list. On recovery, the file system frees any file in the list.</p> </li> </ul> <p>Xv6 implements neither solution, which means that <code>inodes</code> may be marked allocated on disk, even though they are not in use anymore. This means that over time xv6 runs the risk that it may run out of disk space.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#810-code-inode-content","title":"8.10 Code: <code>Inode</code> content","text":"<pre><code>// On-disk inode structure\nstruct dinode {\n  short type;           // File type\n  short major;          // Major device number (T_DEVICE only)\n  short minor;          // Minor device number (T_DEVICE only)\n  short nlink;          // Number of links to inode in file system\n  uint size;            // Size of file (bytes)\n  uint addrs[NDIRECT+1];   // Data block addresses\n};\n</code></pre> <p>\u4e0a\u4e00\u8282\u8bb2\u4e86<code>inode</code>\u5728\u54ea\u91cc\u88ab\u5b58\u50a8\u7740\uff0c\u5982\u4f55\u4f7f\u7528\u548c\u9500\u6bc1\uff0c\u4f46\u57288.9\u8282\u7684\u5f00\u7bc7\uff0c\u6211\u5c31\u63d0\u5230\u4e86\uff0c<code>inode</code>\u7684\u4e3b\u8981\u76ee\u7684\u662f\u628aBLOCK\u6253\u5305\u8d77\u6765\uff0c\u8fd9\u5757\u5c31\u662f\u6587\u4ef6\u7684\u6838\u5fc3\u4e86\u3002</p> <p>\u4e0b\u8fb9\u7684\u56fe\u4e5f\u8bf4\u5f97\u5f88\u6e05\u6670\u4e86\uff0c\u524d12\u4e2a\u5730\u5740\u90fd\u5bf9\u5e94\u7740\u4e00\u4e2aBLOCK</p> <p>\u7b2c13\u4e2a\u5730\u5740\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e8c\u7ea7\u7d22\u5f15\uff0c\u4e5f\u5c31\u662f\u8bf4\u8fd9\u4e2aBLOCK\u91cc\u53c8\u5b58\u50a8\u4e86\u8bb8\u591a\u7684\u5730\u5740\uff0cBLOCK\u7684\u5927\u5c0f\u662f1024B\uff0c \u4e00\u4e2a\u5730\u5740\u7684\u5927\u5c0f\u662f4B\uff0c\u4ece\u800c\uff0c\u8fd9\u4e2a\u4e8c\u7ea7\u7d22\u5f15\u8ba9\u6574\u4e2a<code>inode</code>\u53c8\u591a\u4e86256\u4e2aBLOCK\u3002</p> <p>The on-disk <code>inode</code> structure, struct <code>dinode</code>, contains a size and an array of block numbers (see Figure 8.3). The <code>inode</code> data is found in the blocks listed in the <code>dinode</code> \u2019s <code>addrs</code> array.</p> <ul> <li> <p>The first <code>NDIRECT</code> blocks of data are listed in the first <code>NDIRECT</code> entries in the array; these blocks are called direct blocks.</p> </li> <li> <p>The next <code>NINDIRECT</code> blocks of data are listed not in the <code>inode</code> but in a data block called the indirect block. The last entry in the <code>addrs</code> array gives the address of the indirect block.</p> </li> </ul> <p>Thus the first 12 kB ( NDIRECT x BSIZE) bytes of a file can be loaded from blocks listed in the <code>inode</code>, while the next 256 kB ( NINDIRECT x BSIZE) bytes can only be loaded after consulting the indirect block.</p> <p></p> <p>This is a good on-disk representation but a complex one for clients. The function <code>bmap</code> manages the representation so that higher-level routines such as <code>readi</code> and<code>writei</code>, which we will see shortly. <code>Bmap</code> returns the disk block number of the <code>bn\u2019th</code> data block for the <code>inode ip</code>. If <code>ip</code> does not have such a block yet, <code>bmap</code> allocates one.</p> <p>\u8fd9\u91cc\u5c31\u628a\u6587\u4ef6\u5b58\u50a8\u7684\u65b9\u5f0f\u8bf4\u660e\u767d\u4e86\uff0c\u4f46\u662f\u4e0d\u5f97\u4e0d\u627f\u8ba4\u7684\u662f\uff0c\u8ba9\u7528\u6237\u9762\u5bf9\u7740\u8fd9\u6837\u7684\u6570\u636e\u7ed3\u6784\u53bb\u64cd\u4f5c\u6587\u4ef6\uff0c\u786e\u5b9e\u662f\u5f88\u56f0\u96be\u7684\u3002\u6240\u4ee5\u8fd9\u5c31\u5f15\u51fa\u4e86\u4e0b\u8fb9\u7684\u51fd\u6570\u3002</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#bmap","title":"<code>Bmap</code>","text":"<p><code>Bmap</code>\u7684\u4f1a\u63a5\u53d7\u4e00\u4e2aBLOCK\u7684\u5e8f\u53f7\uff0c\u5f53\u7136\u8fd9\u91cc\u7684\u5e8f\u53f7\u662f<code>inode</code>\u7ed9\u771f\u5b9e\u7684BLOCK\u6240\u7f16\u7684\u5e8f\u53f7\u3002</p> <p>\u7136\u540e\uff0c\u6839\u636e\u8fd9\u4e2a\u5e8f\u53f7\uff0c<code>Bmap</code>\u4f1a\u6309\u7167\u4e0a\u8ff0\u7684\u6570\u636e\u7ed3\u6784\u53bb\u627e\u5230\u5bf9\u5e94\u7684BLOCK\uff0c\u5982\u679c\u6ca1\u6709\u5c31\u4f1a\u8c03\u7528<code>balloc</code>\u5206\u914d\u4e00\u4e2a\u3002</p> <p>\u6700\u540e\uff0c<code>Bmap</code>\u4f1a\u628a\u627e\u5230\u7684BLOCK\u5e8f\u53f7\u8fd4\u56de(\u8fd9\u91cc\u7684\u5e8f\u53f7\u662fOS\u62bd\u8c61\u51fa\u7684\u78c1\u76d8\u7684\u5e8f\u53f7)\u3002</p> <p>The function <code>bmap</code> (kernel/fs.c:378) begins by picking off the easy case: the first NDIRECT blocks are listed in the <code>inode</code> itself (kernel/fs.c:383-387). The next NINDIRECT blocks are listed in the indirect block at <code>ip-&gt;addrs[NDIRECT]</code>. <code>Bmap</code> reads the indirect block (kernel/fs.c:394) and then reads a block number from the right position within the block (kernel/fs.c:395). If the block number exceeds <code>NDIRECT+NINDIRECT</code>, <code>bmap</code> panics; <code>writei</code> contains the check that prevents this from happening (kernel/fs.c:490).</p> <pre><code>// Inode content\n//\n// The content (data) associated with each inode is stored\n// in blocks on the disk. The first NDIRECT block numbers\n// are listed in ip-&gt;addrs[].  The next NINDIRECT blocks are\n// listed in block ip-&gt;addrs[NDIRECT].\n\n// Return the disk block address of the nth block in inode ip.\n// If there is no such block, bmap allocates one.\nstatic uint\nbmap(struct inode *ip, uint bn)\n{\n  uint addr, *a;\n  struct buf *bp;\n\n  if(bn &lt; NDIRECT){\n    if((addr = ip-&gt;addrs[bn]) == 0)\n      ip-&gt;addrs[bn] = addr = balloc(ip-&gt;dev);\n    return addr;\n  }\n  bn -= NDIRECT;\n\n  if(bn &lt; NINDIRECT){\n    // Load indirect block, allocating if necessary.\n    if((addr = ip-&gt;addrs[NDIRECT]) == 0)\n      ip-&gt;addrs[NDIRECT] = addr = balloc(ip-&gt;dev);\n    bp = bread(ip-&gt;dev, addr);\n    a = (uint*)bp-&gt;data;\n    if((addr = a[bn]) == 0){\n      a[bn] = addr = balloc(ip-&gt;dev);\n      log_write(bp);\n    }\n    brelse(bp);\n    return addr;\n  }\n\n  panic(\"bmap: out of range\");\n}\n</code></pre> <p><code>Bmap</code> allocates blocks as needed. An <code>ip-&gt;addrs[]</code> or indirect entry of zero indicates that no block is allocated. As <code>bmap</code> encounters zeros, it replaces them with the numbers of fresh blocks, allocated on demand (kernel/fs.c:384-385) (kernel/fs.c:392-393).</p> <p><code>Bmap</code> makes it easy for <code>readi</code> and <code>writei</code> to get at an <code>inode\u2019s</code> data.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#readi","title":"<code>readi</code>","text":"<p><code>readi</code>\u662f\u5728<code>bmap</code>\u4e0a\u7684\u53c8\u4e00\u5c42\u62bd\u8c61\u3002</p> <p>\u7b80\u800c\u8a00\u4e4b\uff0c<code>readi</code>\u548c\u6211\u4eec\u5e38\u7528\u7684\u6587\u4ef6\u8bfb\u5199\u63a5\u53e3\u5c31\u6bd4\u8f83\u7c7b\u4f3c\u4e86\u3002</p> <p><code>readi</code>\u4f1a\u63a5\u53d7\u4e00\u4e2a\u504f\u79fb\u91cf\uff0c\u6211\u4eec\u901a\u8fc7\u8fd9\u4e2a \u504f\u79fb\u91cf/BLOCLK_SIZE \u5c31\u53ef\u4ee5\u786e\u5b9a\uff0c\u8fd9\u4e2a\u504f\u79fb\u91cf\u5bf9\u5e94\u7684\u6570\u636e\u662f\u5728<code>inode</code>\u7684\u54ea\u4e00\u4e2aBLOCK\u91cc\uff0c<code>bmap</code>\u4f1a\u8fd4\u56de\u8fd9\u4e2aBLOCK\u5728disk\u4e0a\u7684\u771f\u5b9e\u7f16\u53f7\u3002\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u628a\u8fd9\u5757BLOCK\u52a0\u8f7d\u5230buffer cache\u4e2d\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u4ece\u6307\u5b9a\u4f4d\u7f6e\u5f00\u59cb\u8bfb\u53d6\u6570\u636e\u4e86\u3002</p> <p><code>Readi</code> (kernel/fs.c:456) starts by making sure that the offset and count are not beyond the end of the file. Reads that start beyond the end of the file return an error (kernel/fs.c:461-462) while reads that start at or cross the end of the file return fewer bytes than requested (kernel/fs.c:463-464). The main loop processes each block of the file, copying data from the buffer into <code>dst</code> (kernel/fs.c:466-474).</p> <pre><code>// Read data from inode.\n// Caller must hold ip-&gt;lock.\n// If user_dst==1, then dst is a user virtual address;\n// otherwise, dst is a kernel address.\nint\nreadi(struct inode *ip, int user_dst, uint64 dst, uint off, uint n)\n{\n  uint tot, m;\n  struct buf *bp;\n\n  if(off &gt; ip-&gt;size || off + n &lt; off)\n    return 0;\n  if(off + n &gt; ip-&gt;size)\n    n = ip-&gt;size - off;\n\n  for(tot=0; tot&lt;n; tot+=m, off+=m, dst+=m){\n    bp = bread(ip-&gt;dev, bmap(ip, off/BSIZE));\n    m = min(n - tot, BSIZE - off%BSIZE);\n    if(either_copyout(user_dst, dst, bp-&gt;data + (off % BSIZE), m) == -1) {\n      brelse(bp);\n      tot = -1;\n      break;\n    }\n    brelse(bp);\n  }\n  return tot;\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#writei","title":"<code>writei</code>","text":"<p><code>writei</code>\u548c<code>readi</code>\u662f\u5341\u5206\u7c7b\u4f3c\u7684\uff0c\u4f46\u662f\u5199\u64cd\u4f5c\u591a\u4e86\u4e09\u4e2a\u5f02\u5e38</p> <ul> <li>\u5199\u64cd\u4f5c\u53ef\u4ee5\u8ba9\u589e\u5927\u6587\u4ef6\u5927\u5c0f\uff0c\u5f53\u7136\u4e0d\u80fd\u8d85\u8fc7\u6587\u4ef6\u7684\u6700\u5927\u9650\u5236</li> <li>\u6570\u636e\u4ece\u5185\u5b58\u4e2d\u88ab\u62f7\u8d1d\u5230\u4e86buffer cache\u4e4b\u4e2d</li> <li>\u4ee5\u4e3a\u5199\u64cd\u4f5c\u53ef\u80fd\u6d89\u53ca\u5230\u6587\u4ef6\u4f53\u79ef\u7684\u589e\u5927\uff0c\u9700\u8981\u66f4\u65b0<code>inode</code>\u4e2d\u5bf9\u4e8e\u6587\u4ef6\u5927\u5c0f\u7684\u63cf\u8ff0</li> </ul> <p>\u6211\u7684\u7591\u95ee\uff0c\u5982\u679c\u6211\u8981\u5728\u6587\u4ef6\u4e4b\u4e2d\u5f00\u59cbwrite\uff0c\u90a3\u4e48\u4f1a\u4e0d\u4f1a\u51fa\u73b0BLOCK\u4e2d\u7684\u65e7\u6570\u636e\u88ab\u65b0\u6570\u636e\u8986\u76d6\u7684\u95ee\u9898\u5462\uff1f</p> <p><code>writei</code> (kernel/fs.c:483) is identical to <code>readi</code>, with three exceptions:</p> <p>writes that start at or cross the end of the file grow the file, up to the maximum file size (kernel/fs.c:490-491);</p> <p>the loop copies data into the buffers instead of out (kernel/fs.c:36); and</p> <p>if the write has extended the file, <code>writei</code> must update its size (kernel/fs.c:504-511).</p> <pre><code>// Write data to inode.\n// Caller must hold ip-&gt;lock.\n// If user_src==1, then src is a user virtual address;\n// otherwise, src is a kernel address.\nint\nwritei(struct inode *ip, int user_src, uint64 src, uint off, uint n)\n{\n  uint tot, m;\n  struct buf *bp;\n\n  if(off &gt; ip-&gt;size || off + n &lt; off)\n    return -1;\n  if(off + n &gt; MAXFILE*BSIZE)\n    return -1;\n\n  for(tot=0; tot&lt;n; tot+=m, off+=m, src+=m){\n    bp = bread(ip-&gt;dev, bmap(ip, off/BSIZE));\n    m = min(n - tot, BSIZE - off%BSIZE);\n    if(either_copyin(bp-&gt;data + (off % BSIZE), user_src, src, m) == -1) {\n      brelse(bp);\n      n = -1;\n      break;\n    }\n    log_write(bp);\n    brelse(bp);\n  }\n\n  if(n &gt; 0){\n    if(off &gt; ip-&gt;size)\n      ip-&gt;size = off;\n    // write the i-node back to disk even if the size didn't change\n    // because the loop above might have called bmap() and added a new\n    // block to ip-&gt;addrs[].\n    iupdate(ip);\n  }\n\n  return n;\n}\n</code></pre> <p>Both <code>readi</code> and <code>writei</code> begin by checking for <code>ip-&gt;type == T_DEV</code>. This case handles special devices whose data does not live in the file system; we will return to this case in the file descriptor layer.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#stati","title":"<code>stati</code>","text":"<p>The function <code>stati</code> (kernel/fs.c:442) copies <code>inode</code> metadata into the stat structure, which is exposed to user programs via the stat system call.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#811-code-directory-layer","title":"8.11 Code: directory layer","text":"<p>A directory is implemented internally much like a file. Its <code>inode</code> has type <code>T_DIR</code> and its data is a sequence of directory entries. Each entry is a struct <code>dirent</code> (kernel/fs.h:56), which contains a name and an <code>inode</code> number. The name is at most <code>DIRSIZ (14)</code> characters; if shorter, it is terminated by a NUL (0) byte. Directory entries with <code>inode</code> number zero are free.</p> <p>\u6587\u4ef6\u5939\u548c\u6587\u4ef6\u7684\u5b9e\u73b0\u5176\u5b9e\u662f\u5f88\u76f8\u4f3c\u7684\u3002\u6587\u4ef6\u91cc\u5b58\u50a8\u4e86\u8bb8\u591aBLOCK\u7684\u5730\u5740\uff0c\u6587\u4ef6\u5939\u5b58\u50a8\u4e86\u8bb8\u591a\u5176\u4ed6\u6587\u4ef6\u5939\u7684\u5730\u5740\u3002\u8fd9\u4e9b\u5730\u5740\u6307\u5411\u4e0b\u8fb9\u6240\u793a\u7684\u6570\u636e\u7ed3\u6784\u3002</p> <pre><code>// Directory is a file containing a sequence of dirent structures.\n##define DIRSIZ 14\n\nstruct dirent {\n  ushort inum;\n  char name[DIRSIZ];\n};\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#dirlookup","title":"<code>dirlookup</code>","text":"<p>The function <code>dirlookup</code> (kernel/fs.c:527) searches a directory for an entry with the given name.</p> <p>If it finds one, it returns a pointer to the corresponding <code>inode</code>, unlocked, and sets <code>*poff</code> to the byte offset of the entry within the directory, in case the caller wishes to edit it.</p> <p>If <code>dirlookup</code> finds an entry with the right name, it updates <code>*poff</code> and returns an unlocked <code>inode</code> obtained via <code>iget</code>.</p> <p>\u6587\u4ef6\u67e5\u627e\u6700\u540e\u8fd4\u56de\u7684\u662f\u4e00\u4e2a\u6ca1\u6709\u88ab\u9501\u4f4f\u7684<code>inode</code>\u7f13\u5b58\uff0c\u8fd9\u4e00\u70b9\u57288.9\u8282<code>iget</code>\u4e2d\u5c31\u6709\u4e86\u8bba\u8ff0\uff0c\u8fd9\u91cc\u7ed3\u5408\u8fd9\u4e2a\u529f\u80fd\u66f4\u6df1\u5165\u7684\u8ba8\u8bba\u4e86\u8fd9\u4e00\u70b9\u3002</p> <p>\u8981\u67e5\u8be2<code>dp</code>\u6587\u4ef6\u5939\u7684\u4eba\u5df2\u7ecf\u7ed9<code>dp</code>\u52a0\u9501\u4e86\uff0c\u6b64\u65f6\u6211\u4eec\u7684name\u662f\u5f53\u524d\u6587\u4ef6\u5939\uff0c\u4e5f\u5c31\u662f\u901a\u8fc7<code>dp</code>\u627e<code>dp</code>\uff0c\u5982\u679c\u6211\u4eec\u7684<code>iget</code>\u4e5f\u8981\u7ed9<code>dp</code>\u52a0\u9501\u7684\u8bdd\uff0c\u90a3\u5c31\u9020\u6210\u6b7b\u9501\u4e86\u3002</p> <p><code>Dirlookup</code>is the reason that<code>iget</code> returns unlocked <code>inodes</code>. The caller has locked <code>dp</code>, so if the lookup was for <code>.</code>, an alias for the current directory, attempting to lock the <code>inode</code> before returning would try to re-lock <code>dp</code> and deadlock. (There are more complicated deadlock scenarios involving multiple processes and <code>..</code>, an alias for the parent directory; . is not the only problem.) The caller can unlock <code>dp</code> and then lock <code>ip</code>, ensuring that it only holds one lock at a time.</p> <pre><code>// Look for a directory entry in a directory.\n// If found, set *poff to byte offset of entry.\nstruct inode*\ndirlookup(struct inode *dp, char *name, uint *poff)\n{\n  uint off, inum;\n  struct dirent de;\n\n  if(dp-&gt;type != T_DIR)\n    panic(\"dirlookup not DIR\");\n\n  for(off = 0; off &lt; dp-&gt;size; off += sizeof(de)){\n    if(readi(dp, 0, (uint64)&amp;de, off, sizeof(de)) != sizeof(de))\n      panic(\"dirlookup read\");\n    if(de.inum == 0)\n      continue;\n    if(namecmp(name, de.name) == 0){\n      // entry matches path element\n      if(poff)\n        *poff = off;\n      inum = de.inum;\n      return iget(dp-&gt;dev, inum);\n    }\n  }\n\n  return 0;\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#dirlink","title":"<code>dirlink</code>","text":"<p>\u521b\u5efa\u65b0\u6587\u4ef6\u5939</p> <p>The function <code>dirlink</code> (kernel/fs.c:554) writes a new directory entry with the given name and <code>inode</code> number into the directory <code>dp</code>.</p> <p>If the name already exists, <code>dirlink</code> returns an error (kernel/fs.c:560- 564).</p> <p>The main loop reads directory entries looking for an unallocated entry. When it finds one, it stops the loop early (kernel/fs.c:538-539), with off set to the offset of the available entry. Otherwise, the loop ends with off set to <code>dp-&gt;size</code>. Either way, <code>dirlink</code> then adds a new entry to the directory by writing at offset off (kernel/fs.c:574-577).</p> <pre><code>// Write a new directory entry (name, inum) into the directory dp.\nint\ndirlink(struct inode *dp, char *name, uint inum)\n{\n  int off;\n  struct dirent de;\n  struct inode *ip;\n\n  // Check that name is not present.\n  if((ip = dirlookup(dp, name, 0)) != 0){\n    iput(ip);\n    return -1;\n  }\n\n  // Look for an empty dirent.\n  for(off = 0; off &lt; dp-&gt;size; off += sizeof(de)){\n    if(readi(dp, 0, (uint64)&amp;de, off, sizeof(de)) != sizeof(de))\n      panic(\"dirlink read\");\n    if(de.inum == 0)\n      break;\n  }\n\n  strncpy(de.name, name, DIRSIZ);\n  de.inum = inum;\n  if(writei(dp, 0, (uint64)&amp;de, off, sizeof(de)) != sizeof(de))\n    panic(\"dirlink\");\n\n  return 0;\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#812-code-path-names","title":"8.12 Code: Path names","text":"<p>Path name lookup involves a succession of calls to <code>dirlookup</code>, one for each path component.</p> <p>\u4e24\u4e2a\u901a\u8fc7\u540d\u5b57\u627e<code>inode</code>\u7684\u51fd\u6570</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#nameinameiparent","title":"<code>Namei/nameiparent</code>","text":"<p><code>Namei</code> (kernel/fs.c:661) evaluates path and returns the corresponding <code>inode</code>.</p> <p>The function <code>nameiparent</code> is a variant: it stops before the last element, returning the <code>inode</code> of the parent directory and copying the final element into name. Both call the generalized function <code>namex</code> to do the real work.</p> <pre><code>struct inode*\nnamei(char *path)\n{\n  char name[DIRSIZ];\n  return namex(path, 0, name);\n}\n\nstruct inode*\nnameiparent(char *path, char *name)\n{\n  return namex(path, 1, name);\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#namex","title":"<code>Namex</code>","text":"<p>\u7b2c\u4e00\u6b65\uff0c\u76f8\u5bf9\u8def\u5f84\u8fd8\u662f\u7edd\u5bf9\u8def\u5f84\uff1f</p> <p><code>Namex</code> (kernel/fs.c:626) starts by deciding where the path evaluation begins. If the path begins with a slash, evaluation begins at the root; otherwise, the current directory (kernel/fs.c:630-633).</p> <p>\u7b2c\u4e8c\u6b65\uff0c\u68c0\u67e5path\u4e2d\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20</p> <p>Then it uses <code>skipelem</code> to consider each element of the path in turn (kernel/fs.c:635). Each iteration of the loop must look up name in the current <code>inode ip</code>.</p> <p>\u7b2c\u4e09\u6b65\uff0c\u786e\u4fddpath\u4e2d\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20\u7684<code>inode</code>\u90fd\u662f\u6587\u4ef6\u5939</p> <p>\u6ce8\u610f\uff0c<code>ilock</code>\u5728\u8fd9\u91cc\u88ab\u4f7f\u7528\u4e86\uff0cpath\u4e2d\u7684\u6bcf\u4e2a\u6587\u4ef6\u5939\u90fd\u662f\u4e00\u4e2a<code>inode</code>\uff0c\u5728\u67e5\u770b\u4ed6\u4eec\u7684Type\u4e4b\u524d\u9700\u8981\u901a\u8fc7<code>ilock</code>\u4fdd\u8bc1\u4ed6\u4eec\u90fd\u88ab\u52a0\u8f7d\u5230\u4e86cache\u4e2d\uff0c\u8fd9\u91cc\u7684lock\u7684\u4f5c\u7528\u5f88\u7279\u522b\uff01\uff01\uff01</p> <p>The iteration begins by locking <code>ip</code> and checking that it is a directory. If not, the lookup fails (kernel/fs.c:636-640). (Locking <code>ip</code> is necessary not because <code>ip-&gt;type</code> can change underfoot\u2014it can\u2019t\u2014but because until <code>ilock</code> runs, <code>ip-&gt;type</code> is not guaranteed to have been loaded from disk.)</p> <p>\u7b2c\u56db\u6b65\uff0c\u6839\u636e\u76f8\u5e94\u7684\u6761\u4ef6\uff0c\u627e\u5230\u6587\u4ef6\u6216\u8005\u6587\u4ef6\u7684parent</p> <p>If the call is <code>nameiparent</code> and this is the last path element, the loop stops early, as per the definition of <code>nameiparent</code>; the final path element has already been copied into name, so <code>namex</code> need only return the unlocked <code>ip</code> (kernel/fs.c:641-645).</p> <p>Finally, the loop looks for the path element using <code>dirlookup</code> and prepares for the next iteration by setting <code>ip = next</code> (kernel/fs.c:646-651). When the loop runs out of path elements, it returns <code>ip</code>.</p> <pre><code>// Look up and return the inode for a path name.\n// If parent != 0, return the inode for the parent and copy the final\n// path element into name, which must have room for DIRSIZ bytes.\n// Must be called inside a transaction since it calls iput().\nstatic struct inode*\nnamex(char *path, int nameiparent, char *name)\n{\n  struct inode *ip, *next;\n\n  if(*path == '/')\n    ip = iget(ROOTDEV, ROOTINO);\n  else\n    ip = idup(myproc()-&gt;cwd);\n\n  while((path = skipelem(path, name)) != 0){\n    ilock(ip);\n    if(ip-&gt;type != T_DIR){\n      iunlockput(ip);\n      return 0;\n    }\n    if(nameiparent &amp;&amp; *path == '\\0'){\n      // Stop one level early.\n      iunlock(ip);\n      return ip;\n    }\n    if((next = dirlookup(ip, name, 0)) == 0){\n      iunlockput(ip);\n      return 0;\n    }\n    iunlockput(ip);\n    ip = next;\n  }\n  if(nameiparent){\n    iput(ip);\n    return 0;\n  }\n  return ip;\n}\n</code></pre> <p>\u8fd9\u91cc\u7684\u8bbe\u8ba1\u4eae\u70b9\u5c31\u662f\uff0cpath\u4e2d\u7684\u6bcf\u4e2a\u6587\u4ef6\u5939\u90fd\u662f\u7528\u7684\u65f6\u5019\u9501\u4f4f\uff0c\u7528\u5b8c\u4e86\u5c31\u91ca\u653e\u3002\u8fd9\u4f7f\u5f97\u5e76\u884c\u5f97\u4ee5\u5b9e\u73b0\u3002</p> <p>The procedure <code>namex</code> may take a long time to complete: it could involve several disk operations to read <code>inodes</code> and directory blocks for the directories traversed in the pathname (if they are not in the buffer cache). Xv6 is carefully designed so that if an invocation of <code>namex</code> by one kernel thread is blocked on a disk I/O, another kernel thread looking up a different pathname can proceed concurrently. <code>Namex</code> locks each directory in the path separately so that lookups in different directories can proceed in parallel.</p> <p>\u5e76\u53d1\u5e26\u6765\u7684\u6311\u6218</p> <p>\u6311\u6218\u4e00\uff1a\u8fdb\u7a0b1\u6b63\u5728\u67e5\u8be2\u4e00\u4e2apathname\uff0c\u8fdb\u7a0b\u4e8c\u53ef\u80fd\u5728\u540c\u65f6\u628a\u8def\u5f84\u4e2d\u7684\u6587\u4ef6\u5939\u7ed9\u5220\u9664\u4e86\u3002\u8fd9\ufffd\ufffd\u4f1a\u4f7f\u5f97\u67e5\ufffd\ufffd\ufffd\u5230\u7684\u6587\u4ef6\u53ef\ufffd\ufffd\uff7f\u88ab\u5220\u9664\u4e86\u6216\u8005\u662f\u88ab\u5176\u4ed6\u5185\u5bb9\u7ed9\u8986\u76d6\u4e86\u3002</p> <p>Xv6\u89e3\u51b3\u4e86\u8fd9\u4e2a\u95ee\u9898\uff0c\u9996\u5148<code>Iget</code>\u4f1a\u589e\u52a0<code>inode</code>\u7684reference count\uff0c\u4ece\u800c<code>inode</code>\u4e0d\u4f1a\u4ece\u7f13\u5b58\u4e2d\u88ab\u66ff\u6362\uff1b\u5176\u6b21\uff0c<code>namex</code>\u53ea\u6709\u5728\u83b7\u5f97<code>inode</code>\u4e4b\u540e\u624d\u4f1a\u91ca\u653e\u5bf9\u6587\u4ef6\u5939\u7684\u9501\u3002\u56e0\u6b64\uff0c\u5982\u679c<code>inode</code>\u5df2\u7ecf\u88ab\u53e6\u4e00\u4e2a\u8fdb\u7a0b\u5220\u9664\u4e86\uff0c\u4f46\u662f\u4ed6\u7684pointer reference\u5e76\u6ca1\u6709\u5f520\uff0c\u4ece\u800c\u4e0d\u4f1a\u88ab\u7acb\u523b\u5220\u9664\u3002</p> <p>This concurrency introduces some challenges. For example, while one kernel thread is looking up a pathname another kernel thread may be changing the directory tree by unlinking a directory. A potential risk is that a lookup may be searching a directory that has been deleted by another kernel thread and its blocks have been re-used for another directory or file.</p> <p>Xv6 avoids such races. For example, when executing <code>dirlookup</code> in <code>namex</code>, the lookup thread holds the lock on the directory and <code>dirlookup</code> returns an <code>inode</code> that was obtained using <code>iget</code>. <code>Iget</code> increases the reference count of the <code>inode</code>. Only after receiving the <code>inode</code> from <code>dirlookup</code> does <code>namex</code> release the lock on the directory. Now another thread may unlink the <code>inode</code> from the directory but xv6 will not delete the <code>inode</code> yet, because the reference count of the <code>inode</code> is still larger than zero.</p> <p>\u6311\u6218\u4e8c\uff1a\u6b7b\u9501\u3002\u53ef\u4ee5\u9884\u60f3\u8fd9\u6837\u4e00\u79cd\u60c5\u51b5\uff0c<code>./a.txt</code>\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c<code>namex</code>\u4f1a\u5148\u5bf9\u8fd9\u4e2a<code>.</code>\u8fdb\u884c\u67e5\u8be2\uff0c\u4e5f\u5c31\u662f\u6211\u67e5\u6211\u81ea\u5df1\u3002\u6211\u4eec\u5df2\u7ecf\u77e5\u9053\uff0c<code>namex</code>\u4f1a\u7ed9\u88ab\u67e5\u8be2\u7684\u5f53\u524d\u8282\u70b9\u4e0a\u9501\uff0c\u90a3\u4e48\uff0c\u5f53\u524d\u8282\u70b9\u5df2\u7ecf\u88ab\u9501\u4e86\uff0c\u4e0b\u4e00\u4e2a\u8282\u70b9\u4e5f\u662f\u5f53\u524d\u8282\u70b9\uff0c\u8fd9\u5c31\u9020\u6210\u4e86\u6b7b\u9501\u3002\u5f53\u7136\uff0c\u4ee3\u7801\u4e2d\u53ef\u4ee5\u770b\u51fa\uff0c\u5728\u8fdb\u5165\u4e0b\u4e00\u4e2a\u8282\u70b9\u4e4b\u524d\uff0c<code>namex</code>\u4f1a\u91ca\u653e\u5f53\u524d\u8282\u70b9\u7684\u9501\uff0c\u4ece\u800c\u8fd9\u79cd\u6b7b\u9501\u4e5f\u5c31\u4e0d\u4f1a\u53d1\u751f\u4e86\u3002</p> <p>\u8fd9\u91cc\u4e5f\u5c31\u4f53\u73b0\u51fa<code>inode cache</code> \u548c<code>buffer cache</code>\u4e0a\u9501\u7406\u5ff5\u7684\u4e0d\u540c\u4e86\u3002<code>buffer cache</code>\u4ea4\u7ed9\u4e0a\u5c42\u7684\u90fd\u662f\u4e00\u4e2a\u4e0a\u8fc7\u9501\u7684buffer\uff0c\u800c<code>inode cache</code>\u4f1a\u7ed9\u4e0a\u5c42\u4e00\u4e2a\u4e0d\u52a0\u9501\u7684<code>inode</code>\uff0c\u5bf9\u8fd9\u4e2a<code>inode</code>\u7684\u4e0a\u9501\u9700\u8981\u4ea4\u7ed9\u4e0a\u5c42\u6765\u5904\u7406\u3002</p> <p>Another risk is deadlock. For example, next points to the same <code>inode</code> as <code>ip</code> when looking up \".\". Locking next before releasing the lock on <code>ip</code> would result in a deadlock. To avoid this deadlock, <code>namex</code> unlocks the directory before obtaining a lock on next. Here again we see why the separation between <code>iget</code> and <code>ilock</code> is important.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#813-file-descriptor-layer","title":"8.13 File descriptor layer","text":"<p>File descriptor,\u53e5\u67c4\uff0c\u662f\u5bf9\u786c\u76d8\u6216\u8005\u5176\u4ed6\u786c\u4ef6\u8d44\u6e90\u7684\u8fdb\u4e00\u6b65\u62bd\u8c61\u3002</p> <p>A cool aspect of the Unix interface is that most resources in Unix are represented as files, including devices such as the console, pipes, and of course, real files. The file descriptor layer is the layer that achieves this uniformity.</p> <p>\u6bcf\u4e2a\u8fdb\u7a0b\u90fd\u6709\u4e00\u4e2afile descriptor table\u3002\u8fd9\u4e2a\u53e5\u67c4\u8868\u91cc\u5b58\u653e\u7684\u662ffile\u8fd9\u4e2a\u6570\u636e\u7ed3\u6784\uff0c\u4ed6\u5185\u90e8\u53ef\u80fd\u662f\u4e00\u4e2a<code>inode</code>\u6216\u8005\u662f\u4e00\u4e2apipe\u3002</p> <pre><code>// Per-process state\nstruct proc {\n  struct spinlock lock;\n\n  // p-&gt;lock must be held when using these:\n  enum procstate state;        // Process state\n  struct proc *parent;         // Parent process\n  void *chan;                  // If non-zero, sleeping on chan\n  int killed;                  // If non-zero, have been killed\n  int xstate;                  // Exit status to be returned to parent's wait\n  int pid;                     // Process ID\n\n  // these are private to the process, so p-&gt;lock need not be held.\n  uint64 kstack;               // Virtual address of kernel stack\n  uint64 sz;                   // Size of process memory (bytes)\n  pagetable_t pagetable;       // User page table\n  struct trapframe *trapframe; // data page for trampoline.S\n  struct context context;      // swtch() here to run process\n  struct file *ofile[NOFILE];  // Open files\n  struct inode *cwd;           // Current directory\n  char name[16];               // Process name (debugging)\n};\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#struct-file","title":"Struct <code>file</code>","text":"<p>Xv6 gives each process its own table of open files, or file descriptors, as we saw in Chapter 1. Each open file is represented by a struct file (kernel/file.h:1), which is a wrapper around either an <code>inode</code> or a <code>pipe</code>, plus an I/O offset.</p> <p>\u6bcf\u5f53\u6211\u4eec\u5728\u4e00\u4e2a\u8fdb\u7a0b\u4e2dopen\u4e00\u4e2a\u6587\u4ef6\u65f6\uff0c\u4e00\u4e2afile\u7ed3\u6784\u4f53\u5c31\u4f1a\u88ab\u5199\u5165<code>proc</code>\u4e2d\u7684\u53e5\u67c4\u8868\u4e2d\u3002</p> <p>\u591a\u4e2a\u8fdb\u7a0b\u53ef\u4ee5\u6253\u5f00\u540c\u4e00\u4e2a\u6587\u4ef6\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u4ed6\u4eec\u5404\u81ea\u7684\u53e5\u67c4\u8868\u4e2d\u90fd\u4f1a\u8bb0\u5f55\u540c\u4e00\u4e2a<code>inode</code>,\u4f46\u662foffset\u53ef\u80fd\u4f1a\u5404\u6709\u4e0d\u540c\u3002</p> <p>\u4e00\u4e2a\u8fdb\u7a0b\u4e5f\u53ef\u4ee5\u591a\u6b21\u6253\u5f00\u540c\u4e00\u4e2a\u6587\u4ef6\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u4e00\u4e2a\u8fdb\u7a0b\u7684\u53e5\u67c4\u8868\u4e2d\u53ef\u4ee5\u591a\u6b21\u5b58\u653e\u540c\u4e00\u4e2a<code>inode</code>\u3002</p> <p>Each call to open creates a new open file (a new struct file): if multiple processes open the same file independently, the different instances will have different I/O offsets. On the other hand, a single open file (the same struct file) can appear multiple times in one process\u2019s file table and also in the file tables of multiple processes. This would happen if one process used open to open the file and then created aliases using dup or shared it with a child using fork.</p> <p>A reference count tracks the number of references to a particular open file. A file can be open for reading or writing or both. The readable and writable fields track this.</p> <pre><code>struct file {\n  enum { FD_NONE, FD_PIPE, FD_INODE, FD_DEVICE } type;\n\n  int ref; // reference count\n  char readable;\n  char writable;\n  struct pipe *pipe; // FD_PIPE\n  struct inode *ip;  // FD_INODE and FD_DEVICE\n  uint off;          // FD_INODE\n  short major;       // FD_DEVICE\n};\n</code></pre> <p>All the open files in the system are kept in a global file table, the <code>ftable</code>. The file table has functions to allocate a file (<code>filealloc</code>), create a duplicate reference (<code>filedup</code>), release a reference (<code>fileclose</code>), and read and write data (<code>fileread</code> and <code>filewrite</code>).</p> <pre><code>struct {\n  struct spinlock lock;\n  struct file file[NFILE];\n} ftable;\n</code></pre> <p>\u64cd\u4f5c\u7cfb\u7edf\u7528\u4e86\u4e00\u4e2a\u5168\u5c40\u53d8\u91cf\u6765\u5b58\u50a8\u6240\u6709\u7684\u88ab\u6253\u5f00\u7684\u6587\u4ef6</p> <p>The first three follow the now-familiar form. <code>Filealloc</code> (kernel/file.c:30) scans the file table for an unreferenced file (f-&gt;ref == 0) and returns a new reference; <code>filedup</code> (kernel/file.c:48) increments the reference count; and <code>fileclose</code> (kernel/file.c:60) decrements it. When a file\u2019s reference count reaches zero, <code>fileclose</code> releases the underlying pipe or <code>inode</code>, according to the type.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#filealloc","title":"<code>Filealloc</code>","text":"<p>\u4ece\u5168\u5c40\u8868\u4e2d\u627e\u51fa\u4e00\u4e2a\u7a7a\u95f2\u7684\u53e5\u67c4\uff0c\u7136\u540e\u8fd4\u56de\u7ed9\u4e0a\u4e00\u7ea7</p> <pre><code>// Allocate a file structure.\nstruct file*\nfilealloc(void)\n{\n  struct file *f;\n\n  acquire(&amp;ftable.lock);\n  for(f = ftable.file; f &lt; ftable.file + NFILE; f++){\n    if(f-&gt;ref == 0){\n      f-&gt;ref = 1;\n      release(&amp;ftable.lock);\n      return f;\n    }\n  }\n  release(&amp;ftable.lock);\n  return 0;\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#filedup","title":"<code>Filedup</code>","text":"<p>\u589e\u51cf\u53e5\u67c4\u88ab\u5f15\u7528\u7684\u4e2a\u6570\u5e76\u8fd4\u56de\u53e5\u67c4</p> <pre><code>// Increment ref count for file f.\nstruct file*\nfiledup(struct file *f)\n{\n  acquire(&amp;ftable.lock);\n  if(f-&gt;ref &lt; 1)\n    panic(\"filedup\");\n  f-&gt;ref++;\n  release(&amp;ftable.lock);\n  return f;\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#fileclose","title":"<code>Fileclose</code>","text":"<p>\u5f53\u786e\u8ba4\u53e5\u67c4\u6ca1\u6709\u5f15\u7528\u4e4b\u540e\uff0c\u91ca\u653e<code>inode</code>\u6216\u8005pipe</p> <pre><code>// Close file f.  (Decrement ref count, close when reaches 0.)\nvoid\nfileclose(struct file *f)\n{\n  struct file ff;\n\n  acquire(&amp;ftable.lock);\n  if(f-&gt;ref &lt; 1)\n    panic(\"fileclose\");\n  if(--f-&gt;ref &gt; 0){\n    release(&amp;ftable.lock);\n    return;\n  }\n  ff = *f;\n  f-&gt;ref = 0;\n  f-&gt;type = FD_NONE;\n  release(&amp;ftable.lock);\n\n  if(ff.type == FD_PIPE){\n    pipeclose(ff.pipe, ff.writable);\n  } else if(ff.type == FD_INODE || ff.type == FD_DEVICE){\n    begin_op();\n    iput(ff.ip);\n    end_op();\n  }\n}\n</code></pre> <p>The functions <code>filestat</code>, <code>fileread</code>, and <code>filewrite</code> implement the stat, read, and write operations on files.</p> <p><code>Filestat</code> (kernel/file.c:88) is only allowed on <code>inodes</code> and calls <code>stati</code>.</p> <p><code>Fileread</code> and <code>filewrite</code> check that the operation is allowed by the open mode and then pass the call through to either the pipe or <code>inode</code> implementation.</p> <ul> <li> <p>If the file represents an <code>inode</code>, <code>fileread</code> and <code>filewrite</code> use the I/O offset as the offset for the operation and then advance it (kernel/file.c:122- 123) (kernel/file.c:153-154).</p> </li> <li> <p>Pipes have no concept of offset. Recall that the <code>inode</code> functions require the caller to handle locking (kernel/file.c:94-96) (kernel/file.c:121-124) (kernel/file.c:163-166).</p> </li> </ul> <p>\u901a\u8fc7\u53e5\u67c4\u8bfb\u5199pipe\u6ca1\u4ec0\u4e48\u5f88\u7279\u522b\u7684\uff0c\u90fd\u5728<code>pipe.c</code>\u4e2d\u3002</p> <p>\u901a\u8fc7\u53e5\u67c4\u8bfb\u5199<code>inode</code>\u662f\u5f88\u6709\u610f\u601d\u7684\u73af\u8282\uff0c\u5b83\u53c8**\u518d\u6b21\u4f53\u73b0\u4e86Xv6\u628a\u7ed9<code>inode</code>\u7684\u4e0a\u9501\u89e3\u9501\u4efb\u52a1\u4ea4\u7ed9\u8c03\u7528\u8005\u7684\u8bbe\u8ba1**\uff0c\u4ece\u4e0b\u9762\u7684\u51fd\u6570\u6765\u770b\uff0c<code>fileread</code>\u548c<code>filewrite</code>\u4fdd\u8bc1\u4e86\u5bf9<code>inode</code>\u7684offset\u66f4\u65b0\u7684\u539f\u5b50\u6027\u3002\u4ece\u800c\uff0c\u591a\u4e2a\u8fdb\u7a0b\u540c\u65f6\u5bf9\u6587\u4ef6\u5199\u5165\u5e76\u4e0d\u4f1a\u4e92\u76f8\u8986\u76d6\uff0c\u4e00\u4e2a\u8fdb\u7a0b\u5fc5\u987b\u5728\u53e6\u4e00\u4e2a\u8fdb\u7a0b\u66f4\u65b0\u5b8coffset\u4e4b\u540e\u624d\u80fd\u7ee7\u7eed\u5199\u5165\u3002</p> <p>The <code>inode</code> locking has the convenient side effect that the read and write offsets are updated atomically, so that multiple writing to the same file simultaneously cannot overwrite each other\u2019s data, though their writes may end up interlaced.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#fileread","title":"<code>fileread</code>","text":"<pre><code>// Read from file f.\n// addr is a user virtual address.\nint\nfileread(struct file *f, uint64 addr, int n)\n{\n  int r = 0;\n\n  if(f-&gt;readable == 0)\n    return -1;\n\n  if(f-&gt;type == FD_PIPE){\n    r = piperead(f-&gt;pipe, addr, n);\n  } else if(f-&gt;type == FD_DEVICE){\n    if(f-&gt;major &lt; 0 || f-&gt;major &gt;= NDEV || !devsw[f-&gt;major].read)\n      return -1;\n    r = devsw[f-&gt;major].read(1, addr, n);\n  } else if(f-&gt;type == FD_INODE){\n    ilock(f-&gt;ip);\n    if((r = readi(f-&gt;ip, 1, addr, f-&gt;off, n)) &gt; 0)\n      f-&gt;off += r;\n    iunlock(f-&gt;ip);\n  } else {\n    panic(\"fileread\");\n  }\n\n  return r;\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#filewrite","title":"<code>filewrite</code>","text":"<p>\u7ed3\u54088.6Logging\u7ae0\u8282\uff0c\u6587\u4ef6\u4e00\u6b21\u5199\u5165\u7684\u5927\u5c0f\u662f\u6709\u9650\u5236\u7684\uff0c\u56e0\u4e3aLOG\u5728DISK\u4e0a\u7684\u7a7a\u95f4\u662f\u6709\u9650\u7684\uff0c\u9047\u5230\u5927\u6587\u4ef6\u53ea\u80fd\u628a\u5b83\u6309\u7167LOG\u7684\u6700\u5927\u7a7a\u95f4\u591a\u6b21\u5199\u5165\u3002</p> <pre><code>// Write to file f.\n// addr is a user virtual address.\nint\nfilewrite(struct file *f, uint64 addr, int n)\n{\n  int r, ret = 0;\n\n  if(f-&gt;writable == 0)\n    return -1;\n\n  if(f-&gt;type == FD_PIPE){\n    ret = pipewrite(f-&gt;pipe, addr, n);\n  } else if(f-&gt;type == FD_DEVICE){\n    if(f-&gt;major &lt; 0 || f-&gt;major &gt;= NDEV || !devsw[f-&gt;major].write)\n      return -1;\n    ret = devsw[f-&gt;major].write(1, addr, n);\n  } else if(f-&gt;type == FD_INODE){\n    // write a few blocks at a time to avoid exceeding\n    // the maximum log transaction size, including\n    // i-node, indirect block, allocation blocks,\n    // and 2 blocks of slop for non-aligned writes.\n    // this really belongs lower down, since writei()\n    // might be writing a device like the console.\n    int max = ((MAXOPBLOCKS-1-1-2) / 2) * BSIZE;\n    int i = 0;\n    while(i &lt; n){\n      int n1 = n - i;\n      if(n1 &gt; max)\n        n1 = max;\n\n      begin_op();\n      ilock(f-&gt;ip);\n      if ((r = writei(f-&gt;ip, 1, addr + i, f-&gt;off, n1)) &gt; 0)\n        f-&gt;off += r;\n      iunlock(f-&gt;ip);\n      end_op();\n\n      if(r &lt; 0)\n        break;\n      if(r != n1)\n        panic(\"short filewrite\");\n      i += r;\n    }\n    ret = (i == n ? n : -1);\n  } else {\n    panic(\"filewrite\");\n  }\n\n  return ret;\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#814-code-system-calls","title":"8.14 Code: System calls","text":"<p>With the functions that the lower layers provide the implementation of most system calls is trivial (see (<code>kernel/sysfile.c</code>)). There are a few calls that deserve a closer look.</p> <p>The functions <code>sys_link</code> and <code>sys_unlink</code> edit directories, creating or removing references to <code>inodes</code>. They are another good example of the power of using transactions.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#sys_link","title":"<code>sys_link</code>(\u786c\u94fe\u63a5)","text":"<p><code>sys_link</code>\u6240\u505a\u7684\u662f\u5c31\u662f\u8ba9new pathname\u548cold pathname\u6307\u5411\u540c\u4e00\u5757<code>inode</code>\u3002</p> <ol> <li>\u4fdd\u8bc1old pathname\u662f\u5b58\u5728\u7684\u5e76\u4e14\u4e0d\u662f\u6587\u4ef6\u5939</li> <li>\u5bf9old pathname\u5bf9\u5e94\u7684<code>inode</code>\u7684\u5f15\u7528++</li> <li>new pathname\u7684\u4e0a\u5c42\u6587\u4ef6\u5939\u5fc5\u987b\u662f\u5b58\u5728\u7684\uff0c\u5e76\u4e14new pathname\u548cold pathname\u5bf9\u5e94\u7684\u662f\u540c\u4e00\u4e2a\u786c\u4ef6\u8bbe\u5907</li> <li>\u5982\u679c\u4e00\u5207\u90fd\u6ca1\u95ee\u9898\uff0c\u5c31\u628aold pathname\u6240\u6307\u5411\u7684<code>inode</code>\u5b58\u5165new pathname\u5bf9\u5e94\u7684\u6587\u4ef6\u5939\u76ee\u5f55\u91cc\u8fb9\u53bb\uff08<code>dirlink(dp, name, ip-&gt;inum)</code>\uff09</li> <li>\u6700\u540e\u628a\u5171\u4eab\u7684<code>inode</code>\u7f13\u5b58\u540c\u6b65\u5230disk\u91cc\u8fb9\u53bb</li> </ol> <p><code>Sys_link</code> (kernel/sysfile.c:120) begins by fetching its arguments, two strings old and new (kernel/sysfile.c:125). Assuming old exists and is not a directory (kernel/sysfile.c:129-132), sys_link increments its <code>ip-&gt;nlink</code> count. Then sys_link calls <code>nameiparent</code> to find the parent directory and final path element of new (kernel/sysfile.c:145) and creates a new directory entry pointing at old \u2019s <code>inode</code> (kernel/sysfile.c:148). The new parent directory must exist and be on the same device as the existing <code>inode</code>: <code>inode</code> numbers only have a unique meaning on a single disk. If an error like this occurs, <code>sys_link</code> must go back and decrement <code>ip-&gt;nlink</code>.</p> <pre><code>// Create the path new as a link to the same inode as old.\nuint64\nsys_link(void)\n{\n  char name[DIRSIZ], new[MAXPATH], old[MAXPATH];\n  struct inode *dp, *ip;\n\n  if(argstr(0, old, MAXPATH) &lt; 0 || argstr(1, new, MAXPATH) &lt; 0)\n    return -1;\n\n  begin_op();\n  if((ip = namei(old)) == 0){\n    end_op();\n    return -1;\n  }\n\n  ilock(ip);\n  if(ip-&gt;type == T_DIR){\n    iunlockput(ip);\n    end_op();\n    return -1;\n  }\n\n  ip-&gt;nlink++;\n  iupdate(ip);\n  iunlock(ip);\n\n  if((dp = nameiparent(new, name)) == 0)\n    goto bad;\n  ilock(dp);\n  if(dp-&gt;dev != ip-&gt;dev || dirlink(dp, name, ip-&gt;inum) &lt; 0){\n    iunlockput(dp);\n    goto bad;\n  }\n  iunlockput(dp);\n  iput(ip);\n\n  end_op();\n\n  return 0;\n\nbad:\n  ilock(ip);\n  ip-&gt;nlink--;\n  iupdate(ip);\n  iunlockput(ip);\n  end_op();\n  return -1;\n}\n</code></pre> <p>Logging\u90e8\u5206\u7684\u5185\u5bb9</p> <p>Transactions simplify the implementation because it requires updating multiple disk blocks, but we don\u2019t have to worry about the order in which we do them. They either will all succeed or none. For example, without transactions, updating <code>ip-&gt;nlink</code> before creating a link, would put the file system temporarily in an unsafe state, and a crash in between could result in havoc. With transactions we don\u2019t have to worry about this.</p> <p><code>Sys_link</code> creates a new name for an existing <code>inode</code>.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#create","title":"<code>create</code>","text":"<p>The function <code>create</code> (kernel/sysfile.c:242) creates a new name for a new <code>inode</code>.</p> <p>It is a generalization of the three file creation system calls: open with the O_CREATE flag makes a new ordinary file, <code>mkdir</code> makes a new directory, and <code>mkdev</code> makes a new device file.</p> <ul> <li> <p>Like sys_link, create starts by calling <code>nameiparent</code> to get the <code>inode</code> of the parent directory.</p> </li> <li> <p>It then calls <code>dirlookup</code> to check whether the name already exists (kernel/sysfile.c:252).</p> </li> <li> <p>If the name does exist, <code>create</code>\u2019s behavior depends on which system call it is being used for:</p> </li> <li> <p>open has different semantics from <code>mkdir</code> and <code>mkdev</code>.</p> </li> <li> <p>If create is being used on behalf of open (type == T_FILE) and the name that exists is itself a regular file, then open treats that as a success, so create does too (kernel/sysfile.c:256).</p> </li> <li> <p>Otherwise, it is an error (kernel/sysfile.c:257-258).</p> </li> <li> <p>If the name does not already exist, create now allocates a new <code>inode</code> with <code>ialloc</code>(kernel/sysfile.c:261).</p> </li> </ul> <p>I**f the new <code>inode</code> is a directory, create initializes it with . and .. entries.**</p> <p>Finally, now that the data is initialized properly, create can link it into the parent directory (kernel/sysfile.c:274). Create, like sys_link, holds two <code>inode</code> locks simultaneously: <code>ip</code> and <code>dp</code>. There is no possibility of deadlock because the <code>inode</code> <code>ip</code> is freshly allocated: no other process in the system will hold <code>ip</code> \u2019s lock and then try to lock <code>dp</code>.</p> <pre><code>static struct inode*\ncreate(char *path, short type, short major, short minor)\n{\n  struct inode *ip, *dp;\n  char name[DIRSIZ];\n  // \u83b7\u5f97\u6587\u4ef6\u5939\u5bf9\u5e94\u7684inode\n  if((dp = nameiparent(path, name)) == 0)\n    return 0;\n\n  ilock(dp);\n  // \u67e5\u770b\u6587\u4ef6\u5939\u4e2d\u7684\u6bcf\u4e00\u4e2adrient\uff0c\u4fdd\u8bc1\u6ca1\u6709\u91cd\u540d\u7684inode\n  if((ip = dirlookup(dp, name, 0)) != 0){\n    // \u540d\u5b57\u91cd\u590d\n    iunlockput(dp);\n    ilock(ip);\n    // \u540d\u5b57\u91cd\u590d\u7684inode\u662f\u4e00\u4e2a\u6587\u4ef6\uff0c\u76f4\u63a5\u8fd4\u56de\u5df2\u7ecf\u5b58\u5728\u7684\u6587\u4ef6\n    if(type == T_FILE &amp;&amp; (ip-&gt;type == T_FILE || ip-&gt;type == T_DEVICE))\n      return ip;\n    iunlockput(ip);\n    // \u5426\u5219\u8fd4\u56de\u9519\u8bef\n    return 0;\n  }\n  // \u8fd9\u91cc\u53ef\u4ee5\u4fdd\u8bc1dp\u4e2d\u6ca1\u6709\u53ebname\u7684\u6587\u4ef6\n  // ialloc,\u7ed9\u8fd9\u4e2aname\u5206\u914d\u4e00\u4e2ainode\n  if((ip = ialloc(dp-&gt;dev, type)) == 0)\n    panic(\"create: ialloc\");\n\n  ilock(ip);\n  ip-&gt;major = major;\n  ip-&gt;minor = minor;\n  ip-&gt;nlink = 1;\n  iupdate(ip);\n  // \u5982\u679c\u8fd9\u4e2ainode\u4ee3\u8868\u7684\u662f\u4e00\u4e2a\u6587\u4ef6\u5939\n  if(type == T_DIR){  // Create . and .. entries.\n    dp-&gt;nlink++;  // for \"..\"\n    iupdate(dp);\n    // No ip-&gt;nlink++ for \".\": avoid cyclic ref count.\n    // \u7ed9\u8fd9\u4e2a\u6587\u4ef6\u5939\u521d\u59cb\u5316\u4e24\u4e2a\u57fa\u672c\u7684dirent . \u548c ..\n    if(dirlink(ip, \".\", ip-&gt;inum) &lt; 0 || dirlink(ip, \"..\", dp-&gt;inum) &lt; 0)\n      panic(\"create dots\");\n  }\n  // \u6700\u540e\uff0c\u628a\u8fd9\u4e2a\u6587\u4ef6inode\u653e\u5230\u6587\u4ef6\u5939dp\u7684\u5176\u4e2d\u4e00\u4e2adirent\u4e2d\n  if(dirlink(dp, name, ip-&gt;inum) &lt; 0)\n    panic(\"create: dirlink\");\n\n  iunlockput(dp);\n\n  return ip;\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#sys_open","title":"<code>sys_open</code>","text":"<p>Using create, it is easy to implement <code>sys_open</code>, <code>sys_mkdir</code>, and <code>sys_mknod</code>.</p> <p>Sys_open (kernel/sysfile.c:287) is the most complex, because creating a new file is only a small part of what it can do.</p> <ul> <li> <p>If open is passed the O_CREATE flag, it calls create (kernel/sysfile.c:301).</p> </li> <li> <p>Otherwise, it calls <code>namei</code> (kernel/sysfile.c:307). Create returns a locked <code>inode</code>, but <code>namei</code> does not, so sys_open must lock the <code>inode</code> itself. This provides a convenient place to check that directories are only opened for reading, not writing.</p> </li> <li> <p>Assuming the <code>inode</code> was obtained one way or the other, <code>sys_open</code> allocates a file and a file descriptor (kernel/sysfile.c:325) and then fills in the file (kernel/sysfile.c:337-342).</p> </li> </ul> <p>Note that no other process can access the partially initialized file since it is only in the current process\u2019s table.</p> <pre><code>uint64\nsys_open(void)\n{\n  char path[MAXPATH];\n  int fd, omode;\n  struct file *f;\n  struct inode *ip;\n  int n;\n\n  if((n = argstr(0, path, MAXPATH)) &lt; 0 || argint(1, &amp;omode) &lt; 0)\n    return -1;\n\n  begin_op();\n\n  if(omode &amp; O_CREATE){\n    ip = create(path, T_FILE, 0, 0);\n    if(ip == 0){\n      end_op();\n      return -1;\n    }\n  } else {\n    if((ip = namei(path)) == 0){\n      end_op();\n      return -1;\n    }\n    ilock(ip);\n    if(ip-&gt;type == T_DIR &amp;&amp; omode != O_RDONLY){\n      iunlockput(ip);\n      end_op();\n      return -1;\n    }\n  }\n\n  if(ip-&gt;type == T_DEVICE &amp;&amp; (ip-&gt;major &lt; 0 || ip-&gt;major &gt;= NDEV)){\n    iunlockput(ip);\n    end_op();\n    return -1;\n  }\n  // \u8fd9\u91cc\u4e00\u5b9a\u62ff\u5230\u4e86\u4e00\u4e2ainode\n  // \u63a5\u4e0b\u6765\u4e3ainode\u5206\u914d\u4e00\u4e2a\u53e5\u67c4\n  if((f = filealloc()) == 0 || (fd = fdalloc(f)) &lt; 0){\n    if(f)\n      fileclose(f);\n    iunlockput(ip);\n    end_op();\n    return -1;\n  }\n  // \u521d\u59cb\u5316\u53e5\u67c4fd\u4e2d\u7684\u7ec6\u8282\n  if(ip-&gt;type == T_DEVICE){\n    f-&gt;type = FD_DEVICE;\n    f-&gt;major = ip-&gt;major;\n  } else {\n    f-&gt;type = FD_INODE;\n    f-&gt;off = 0;\n  }\n  f-&gt;ip = ip;\n  f-&gt;readable = !(omode &amp; O_WRONLY);\n  f-&gt;writable = (omode &amp; O_WRONLY) || (omode &amp; O_RDWR);\n\n  if((omode &amp; O_TRUNC) &amp;&amp; ip-&gt;type == T_FILE){\n    itrunc(ip);\n  }\n\n  iunlock(ip);\n  end_op();\n\n  return fd;\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#sys_pipe","title":"<code>sys_pipe</code>","text":"<p>Chapter 7 examined the implementation of pipes before we even had a file system. The function <code>sys_pipe</code> connects that implementation to the file system by providing a way to create a pipe pair. Its argument is a pointer to space for two integers, where it will record the two new file descriptors. Then it allocates the pipe and installs the file descriptors.</p> <p><code>int pipe(int p[])</code></p> <p>\u8fd9\u91cc\u8bba\u8ff0\u4e00\u4e0b\uff0cpipe\u662f\u5982\u4f55\u8ba9\u8fdb\u7a0b\u95f4\u7684\u6c9f\u901a\u6210\u4e3a\u53ef\u80fd\u7684\u3002pipe \u7cfb\u7edf\u8c03\u7528\u4f1a\u521b\u5efa\u4e24\u4e2a\u53e5\u67c4\u51fa\u6765\uff0c\u8fd9\u4e24\u4e2a\u53e5\u67c4\u4f1a\u88ab\u5b58\u50a8\u5728\u521b\u5efapipe\u7684\u8fdb\u7a0bA\u7684open file\u8868\u4e2d\u3002\u5982\u679c\u6211\u4eec\u4f7f\u7528fork\uff0c\u90a3\u4e48\u5b50\u8fdb\u7a0bB\u5c31\u4f1a\u590d\u5236\u4e00\u4efd\u8fdb\u7a0bA\u5185\u5b58\u7a7a\u95f4\uff0c\u4ece\u800c\uff0c\u5b50\u8fdb\u7a0bB\u4e5f\u5c31\u80fd\u4f7f\u7528\u8fdb\u7a0bA\u4e2d\u521b\u9020\u51fa\u7684pipe\u4e86\u3002</p> <p>\u4e5f\u5c31\u662f\u8bf4\uff0c\u8fdb\u7a0bA\u548c\u8fdb\u7a0bB\u7684\u53e5\u67c4\u8868\u4e2d\u6709\u7740\u76f8\u540c\u7684\u4e24\u4e2a\u4e2a\u53e5\u67c4\uff0c\u8fd9\u4e24\u4e2a\u53e5\u67c4\u6307\u5411\u4e86\u540c\u4e00\u5757\u5185\u6838\u6001\u5f00\u8f9f\u7684\u5185\u5b58\u7a7a\u95f4\uff0c\u8fd9\u5757\u7a7a\u95f4\u5c31\u662f\u6240\u8c13\u7684\u7ba1\u9053\u4e86\u3002</p> <pre><code>uint64\nsys_pipe(void)\n{\n  uint64 fdarray; // user pointer to array of two integers\n  struct file *rf, *wf;\n  int fd0, fd1;\n  struct proc *p = myproc();\n  // \u62ff\u5230\u7528\u6237\u4f20\u5165\u7684p[]\n  if(argaddr(0, &amp;fdarray) &lt; 0)\n    return -1;\n  // \u901a\u8fc7pipealloc\u83b7\u5f97\u4e24\u4e2a\u53e5\u67c4\n  // \u4e00\u4e2a\u7528\u6765\u8bfb\uff0c\u4e00\u4e2a\u7528\u6765\u5199\n  if(pipealloc(&amp;rf, &amp;wf) &lt; 0)\n    return -1;\n  fd0 = -1;\n  // \u901a\u8fc7fdalloc\u628a\u4e24\u4e2a\u53e5\u67c4\u5199\u5165\u8fdb\u7a0b\u7684fd\u8868\u4e2d\n  if((fd0 = fdalloc(rf)) &lt; 0 || (fd1 = fdalloc(wf)) &lt; 0){\n    if(fd0 &gt;= 0)\n      p-&gt;ofile[fd0] = 0;\n    fileclose(rf);\n    fileclose(wf);\n    return -1;\n  }\n  // \u628afd0\u548cfd1\u5199\u5165\u7528\u6237\u7a7a\u95f4\u7684\u6570\u7ec4\u4e2d\n  if(copyout(p-&gt;pagetable, fdarray, (char*)&amp;fd0, sizeof(fd0)) &lt; 0 ||\n     copyout(p-&gt;pagetable, fdarray+sizeof(fd0), (char *)&amp;fd1, sizeof(fd1)) &lt; 0){\n    p-&gt;ofile[fd0] = 0;\n    p-&gt;ofile[fd1] = 0;\n    fileclose(rf);\n    fileclose(wf);\n    return -1;\n  }\n  return 0;\n}\n</code></pre> <pre><code>int\npipealloc(struct file **f0, struct file **f1)\n{\n  struct pipe *pi;\n\n  pi = 0;\n  *f0 = *f1 = 0;\n  if((*f0 = filealloc()) == 0 || (*f1 = filealloc()) == 0)\n    goto bad;\n  if((pi = (struct pipe*)kalloc()) == 0)\n    goto bad;\n  pi-&gt;readopen = 1;\n  pi-&gt;writeopen = 1;\n  pi-&gt;nwrite = 0;\n  pi-&gt;nread = 0;\n  initlock(&amp;pi-&gt;lock, \"pipe\");\n  (*f0)-&gt;type = FD_PIPE;\n  (*f0)-&gt;readable = 1;\n  (*f0)-&gt;writable = 0;\n  (*f0)-&gt;pipe = pi;\n  (*f1)-&gt;type = FD_PIPE;\n  (*f1)-&gt;readable = 0;\n  (*f1)-&gt;writable = 1;\n  (*f1)-&gt;pipe = pi;\n  return 0;\n\n bad:\n  if(pi)\n    kfree((char*)pi);\n  if(*f0)\n    fileclose(*f0);\n  if(*f1)\n    fileclose(*f1);\n  return -1;\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#84-logging-layer","title":"8.4 Logging layer","text":"<p>One of the most interesting problems in file system design is crash recovery. The problem arises because many file-system operations involve multiple writes to the disk, and a crash after a subset of the writes may leave the on-disk file system in an inconsistent state. For example, suppose a crash occurs during file truncation (setting the length of a file to zero and freeing its content blocks). Depending on the order of the disk writes, the crash may either leave an <code>inode</code> with a reference to a content block that is marked free, or it may leave an allocated but unreferenced content block.</p> <p>crash\u5e26\u6765\u7684\u95ee\u9898\uff1a</p> <ol> <li><code>inode</code>\u4e2d\u4f9d\u7136\u6307\u5411\u7740\u4e00\u5757\u88ab\u6807\u8bb0\u4e3afree\u7684BLOCK\uff08\u4e25\u91cd\uff09</li> <li>BLOCK\u88ab\u5199\u5165\u4e86\u6570\u636e\u4f46<code>inode</code>\u6ca1\u6709\u6307\u5411\u5b83</li> </ol>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#crash-handling","title":"Crash Handling","text":"<p>The latter is relatively benign, but an <code>inode</code> that refers to a freed block is likely to cause serious problems after a reboot. After reboot, the kernel might allocate that block to another file, and now we have two different files pointing unintentionally to the same block. If xv6 supported multiple users, this situation could be a security problem, since the old file\u2019s owner would be able to read and write blocks in the new file, owned by a different user.</p> <p>\u89e3\u51b3\u65b9\u6848</p> <ol> <li>\u5c06\u6240\u6709\u7684disk\u5199\u8bf7\u6c42\u90fd\u5199\u5165disk\u4e0a\u7684log\u533a\u57df</li> <li>\u5f53log\u4e86\u6240\u6709\u7684\u5199\u8bf7\u6c42\u540e\uff0c\u5199\u5165\u4e00\u4e2acommit record\u7528\u6765\u8868\u793a\u4e00\u4e2a\u5b8c\u6574\u7684\u64cd\u4f5c\u53ef\u4ee5\u8fdb\u884c</li> <li>\u5f00\u59cb\u771f\u6b63\u5411disk\u5199\u5165\u6570\u636e</li> <li>\u5220\u9664\u76f8\u5173\u7684log\u4fe1\u606f</li> </ol> <p>Xv6 solves the problem of crashes during file-system operations with a simple form of logging. An xv6 system call does not directly write the on-disk file system data structures. Instead, it places a description of all the disk writes it wishes to make in a log on the disk.</p> <p>Once the system call has logged all of its writes, it writes a special commit record to the disk indicating that the log contains a complete operation. At that point the system call copies the writes to the on-disk file system data structures. After those writes have completed, the system call erases the log on disk.</p> <p>file system\u7684\u6062\u590d\u8fc7\u7a0b\uff08\u5f00\u59cb\u4e8e\u8fd0\u884c\u4efb\u4f55\u7a0b\u5e8f\u4e4b\u524d\uff09</p> <p>If the system should crash and reboot, the file-system code recovers from the crash as follows, before running any processes.</p> <ul> <li> <p>If the log is marked as containing a complete operation, then the recovery code copies the writes to where they belong in the on-disk file system.</p> </li> <li> <p>If the log is not marked as containing a complete operation, the recovery code ignores the log. The recovery code finishes by erasing the log.</p> </li> </ul> <p>Why does xv6\u2019s log solve the problem of crashes during file system operations?</p> <ul> <li> <p>If the crash occurs before the operation commits, then the log on disk will not be marked as complete, the recovery code will ignore it, and the state of the disk will be as if the operation had not even started.</p> </li> <li> <p>If the crash occurs after the operation commits, then recovery will replay all of the operation\u2019s writes, perhaps repeating them if the operation had started to write them to the on-disk data structure.</p> </li> </ul> <p>In either case, the log makes operations atomic with respect to crashes: after recovery, either all of the operation\u2019s writes appear on the disk, or none of them appear.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#85-log-design","title":"8.5 Log design","text":"<p>The log resides at a known fixed location, specified in the superblock.</p> <p></p> <p>It consists of a header block followed by a sequence of updated block copies (\u201clogged blocks\u201d).</p> <p>The header block contains an array of sector numbers, one for each of the logged blocks, and the count of log blocks.</p> <p>The count in the header block on disk is either zero, indicating that there is no transaction in the log, or nonzero, indicating that the log contains a complete committed transaction with the indicated number of logged blocks.</p> <pre><code>// Contents of the header block, used for both the on-disk header block\n// and to keep track in memory of logged block# before commit.\nstruct logheader {\n  int n;\n  int block[LOGSIZE];\n};\n\nstruct log {\n  struct spinlock lock;\n  int start;\n  int size;\n  int outstanding; // how many FS sys calls are executing.\n  int committing;  // in commit(), please wait.\n  int dev;\n  struct logheader lh;\n};\n</code></pre> <p>\u8fd9\u91cc\u8981\u5bf9\u7167\u7740\u4ee3\u7801\u53bb\u770b</p> <p>Xv6 writes the header block when a transaction commits, but not before, and sets the count to zero after copying the logged blocks to the file system. Thus a crash midway through a transaction will result in a count of zero in the log\u2019s header block; a crash after a commit will result in a non-zero count.</p> <p>\u4e0b\u9762\u7684\u8fd9\u4e24\u70b9\u57288.6\u8282\u7684<code>end_op</code>\u4e2d\u6709\u8be6\u7ec6\u7684\u9610\u8ff0\uff0c\u5e94\u8be5\u7ed3\u5408\u7740\u4ee3\u7801\u7406\u6e05\u903b\u8f91\u518d\u6765\u770b\u8fd9\u91cc\u7684\u7ed3\u8bba</p> <p></p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#challenge-concurrent-fs-syscalls","title":"Challenge: Concurrent FS <code>Syscalls</code>","text":"<p>Each system call\u2019s code indicates the start and end of the sequence of writes that must be atomic with respect to crashes. To allow concurrent execution of file-system operations by different processes, the logging system can accumulate the writes of multiple system calls into one transaction. Thus a single commit may involve the writes of multiple complete system calls. To avoid splitting a system call across transactions, the logging system only commits when no file-system system calls are underway.</p> <p>The idea of committing several transactions together is known as <code>group commit</code>.</p> <ul> <li>Group commit reduces the number of disk operations because it amortizes(\u5206\u644a) the fixed cost of a commit over multiple operations.</li> <li>Group commit also hands the disk system more concurrent writes at the same time, perhaps allowing the disk to write them all during a single disk rotation. Xv6\u2019s <code>virtio</code> driver doesn\u2019t support this kind of batching, but xv6\u2019s file system design allows for it.</li> </ul>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#challenge-max-log-size","title":"Challenge: MAX log size","text":"<p>Xv6 dedicates a fixed amount of space on the disk to hold the log.</p> <p>The total number of blocks written by the system calls in a transaction must fit in that space. This has two consequences.</p> <p>\u7b2c\u4e00\u4e2a\u7ed3\u8bba\uff0c\u8be6\u89c1<code>file write</code></p> <ul> <li>No single system call can be allowed to write more distinct blocks than there is space in the log. This is not a problem for most system calls, but two of them can potentially write many blocks: write and unlink. A large file write may write many data blocks and many bitmap blocks as well as an <code>inode</code> block; unlinking a large file might write many bitmap blocks and an <code>inode</code>. Xv6\u2019s write system call breaks up large writes into multiple smaller writes that fit in the log, and unlink doesn\u2019t cause problems because in practice the xv6 file system uses only one bitmap block.</li> <li>The other consequence of limited log space is that the logging system cannot allow a system call to start unless it is certain that the system call\u2019s writes will fit in the space remaining in the log.</li> </ul>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#86-code-logging","title":"8.6 Code: logging","text":"<p>A typical use of the log in a system call looks like this:</p> <pre><code>begin_op();\n...\nbp = bread(...);\nbp-&gt;data[...] = ...;\nlog_write(bp);\n...\nend_op();\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#begin_op","title":"<code>begin_op</code>","text":"<p><code>begin_op</code> (kernel/log.c:126) waits until the logging system is not currently committing, and until there is enough unreserved log space to hold the writes from this call. <code>log.outstanding</code> counts the number of system calls that have reserved log space; the total reserved space is <code>log.outstanding</code> times MAXOPBLOCKS. Incrementing <code>log.outstanding</code> both reserves space and prevents a commit from occurring during this system call. The code conservatively assumes that each system call might write up to MAXOPBLOCKS distinct blocks.</p> <p><code>begin_op</code>\u5728log\u8fdb\u884ccommit\u7684\u65f6\u5019\u662f\u4e0d\u53ef\u4ee5\u518d\u5411log\u4e2d\u5199\u5165\u7684\uff0c\u8fd9\u4e2a\u5f88\u597d\u7406\u89e3\u3002</p> <p><code>begin_op</code>\u5728operation\u53ef\u80fd\u8017\u5c3dlog\u7a7a\u95f4\u7684\u65f6\u5019\uff0c\u4e5f\u4f1a**\u8fdb\u5165sleep\u8ba9\u51faCPU**\u3002\u8fd9\u91cc\u548c\u4e0a\u4e00\u8282\u63d0\u5230\u7684\u4e24\u4e2achallenge\u6709\u5173\u3002\u6587\u4ef6\u7cfb\u7edf\u652f\u6301\u591a\u4e2a\u8fdb\u7a0b\u5e76\u53d1\u7684\u5411log\u5199\u5165\u81ea\u5df1\u7684\u8bf7\u6c42\uff0c\u5f53\u591a\u4e2a\u8fdb\u7a0b\u90fd\u5199\u5b8c\u4e86\u4ee5\u540e\uff0clog\u53ef\u4ee5\u628a\u591a\u4e2a\u8fdb\u7a0b\u7684\u8bf7\u6c42\u6574\u5408\u6210\u4e3a\u4e00\u4e2a\uff0c\u5f53\u4f5c\u4e00\u4e2acommit\u63d0\u4ea4\u3002\u4f46\u8fd9\u91cc\u4f1a\u6d89\u53ca\u5230\u4e00\u4e2a\u95ee\u9898\uff0c\u5982\u679c\u4e00\u6b21\u6709\u592a\u591a\u7684\u8fdb\u7a0b\u5411log\u4e2d\u5199\u5165\u81ea\u5df1\u7684\u8bf7\u6c42\uff0c\u90a3\u4e48\u6709\u53ef\u80fd\u5bfc\u81f4**\u591a\u4e2a\u8fdb\u7a0b\u90fd\u6ca1\u6709\u5b8c\u6210\u81ea\u5df1\u7684\u5b8c\u6574\u6587\u4ef6\u64cd\u4f5c\uff0c\u4f46\u662flog\u5df2\u7ecf\u88ab\u586b\u6ee1\u4e86\u7684\u95ee\u9898**\uff0c\u8fd9\u6837\u7684\u8bdd\uff0clog\u662f\u4e0d\u80fd\u8fdb\u884ccommit\u7684\uff0c\u56e0\u4e3a\u5982\u679ccommit\u4e86\uff0c\u6240\u6709\u8fdb\u7a0b\u7684\u6587\u4ef6\u64cd\u4f5c\u90fd\u662f\u4e0d\u5b8c\u6574\u7684\u3002\u6240\u4ee5\uff0c\u8fd9\u91cc\u52a0\u5165\u4e86\u8fd9\u6837\u4e00\u4e2a\u5224\u65ad\uff0c\u6765\u9650\u5236\u80fd\u4f7f\u7528log\u7684\u8fdb\u7a0b\u6570\u91cf\u3002</p> <p>\u603b\u7ed3\u4e00\u4e0b\uff0c<code>begin_op</code>\u7528\u6765\u8868\u793a\u4e00\u4e2a\u6587\u4ef6system call\u7684\u5f00\u59cb\uff0c\u540c\u65f6\u4e5f\u662f\u8fdb\u7a0b\u4f7f\u7528log\u524d\u7684\u4e00\u9053\u5173\u5361\uff0c\u4fdd\u8bc1log\u88ab\u5e76\u53d1\u7684\u5199\u5165\u5e76\u4e14\u4e0d\u4f1a\u88ab\u8fc7\u591a\u8fdb\u7a0b\u8017\u5c3dlog\u7a7a\u95f4\u3002</p> <pre><code>// called at the start of each FS system call.\nvoid\nbegin_op(void)\n{\n  acquire(&amp;log.lock);\n  while(1){\n    if(log.committing){\n      sleep(&amp;log, &amp;log.lock);\n    } else if(log.lh.n + (log.outstanding+1)*MAXOPBLOCKS &gt; LOGSIZE){\n      // this op might exhaust log space; wait for commit.\n      sleep(&amp;log, &amp;log.lock);\n    } else {\n      log.outstanding += 1;\n      release(&amp;log.lock);\n      break;\n    }\n  }\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#log_write","title":"<code>log_write</code>","text":"<p><code>log_write</code> (kernel/log.c:214) acts as a proxy for <code>bwrite</code>.</p> <ul> <li> <p>It records the block\u2019s sector number in memory, reserving it a slot in the log on disk, and</p> </li> <li> <p>pins the buffer in the block cache to prevent the block cache from evicting it.</p> </li> </ul> <p>The block must stay in the cache until committed: until then, the cached copy is the only record of the modification; it cannot be written to its place on disk until after commit; and other reads in the same transaction must see the modifications.</p> <p><code>log_write</code> notices when a block is written multiple times during a single transaction, and allocates that block the same slot in the log. This optimization is often called absorption.</p> <p>It is common that, for example, the disk block containing <code>inodes</code> of several files is written several times within a transaction. By absorbing several disk writes into one, the file system can save log space and can achieve better performance because only one copy of the disk block must be written to disk.</p> <p><code>log_write</code>\u662f\u5bf9<code>bwrite</code>\u7684\u4e00\u79cd\u4ee3\u7406\uff0c\u5b83\u4e3b\u8981\u5e72\u4e86\u4e24\u4ef6\u4e8b\uff1a</p> <ol> <li>\u628a\u8981\u8fdb\u884c\u78c1\u76d8\u5199\u5165\u7684BLOCK No\u8bb0\u5f55\u5728log\u7684header\u7684\u6570\u7ec4\u4e2d</li> <li>\u4fdd\u8bc1\u8bb0\u5f55\u5728\u6570\u7ec4\u4e2d\u7684BLOCK\u4e0d\u4f1a\u88ab\u9a71\u9010\u51fabuffer cache</li> </ol> <p>\u5148\u6765\u8bf4\u8bf4**\u9632\u6b62\u9a71\u9010\u7684\u539f\u56e0**\uff0clog\u8981\u5728\u4e00\u4e2asystem call\u5168\u90e8\u5b8c\u6210\u4e4b\u540e\u624d\u4f1a\u8fdb\u884c\u771f\u6b63\u7684\u5199\u5165\u5de5\u4f5c\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u5728\u52a0\u5165log\u7684\u6570\u7ec4\u4e2d\u540e\uff0cdisk\u8fd8\u4e0d\u80fd\u540c\u6b65buffer cache\u91cc\u4fee\u6539\u7684\u5185\u5bb9\uff0c\u6240\u4ee5\uff0c\u5982\u679c\u6211\u4eec\u8ba9\u8fd9\u4e2abuffer\u88abevict\u4e86\uff0c\u90a3\u4e48\u76f4\u63a5\u5199\u5165\u7684\u5185\u5bb9\u4e5f\u5c31\u6ca1\u6709\u673a\u4f1a\u88ab\u540c\u6b65\u5230disk\u4e0a\u4e86\u3002\u6240\u4ee5\u4f7f\u7528<code>bpin()</code>\u7ed9buffer\u7684<code>refcnt++</code>\uff0c\u4fdd\u8bc1LRU\u4e0d\u4f1a\u593a\u8d70\u8fd9\u4e2abuffer cache\u3002</p> <p>\u8fd9\u91cc\u8fd8\u4f53\u73b0\u4e86<code>absorbtion</code>\uff0c\u7b80\u5355\u7684\u6765\u8bf4\uff0c\u5c31\u662f\u6211\u4eec\u5728\u4e00\u4e2asystem call\u4e2d\u53ef\u80fd\u4f1a\u591a\u6b21\u5199\u5165\u540c\u4e00\u5757block\u3002\u4e3e\u4e2a\u4f8b\u5b50\uff0c<code>inodes</code>\u5c31\u6709\u53ef\u80fd\u5904\u4e8e\u540c\u4e00\u5757BLOCK\uff0c\u6211\u4eec\u53ef\u80fd\u4e00\u6b21\u9700\u8981\u66f4\u65b0\u591a\u4e2a\u5728\u540c\u4e00\u5757BLOCK\u4e2d\u7684<code>inodes</code>\uff0c\u6240\u4ee5\u6211\u4eec\u6ca1\u5fc5\u8981\u5728\u6570\u7ec4\u4e2d\u8bb0\u5f55\u8fd9\u4e2aBLOCK\u7f16\u53f7\u4e24\u6b21\uff0c\u56e0\u4e3a\u6211\u4eec\u53ea\u7528\u4e00\u6b21write disk\u5c31\u53ef\u4ee5\u628a\u5bf9\u8fd9\u5757BLOCK\u7684\u591a\u6b21\u66f4\u65b0\u7ed9\u540c\u6b65\u5230disk\u4e86\u3002</p> <p>\u603b\u7ed3\u4e00\u4e0b\uff0c<code>log_write</code>\u5e76\u6ca1\u6709\u8fdb\u884c\u5bf9\u78c1\u76d8\u7684\u5199\u5165\u5de5\u4f5c\uff0c\u4ed6\u53ea\u662f\u628a\u6240\u6709\u7684\u5199\u8bf7\u6c42\u653e\u5230\u4e86log\u4e4b\u4e2d\uff08\u8fd9\u4e2alog\u6307\u7684\u662f\u5185\u5b58\u4e0a\u7684log\uff09</p> <pre><code>void\nlog_write(struct buf *b)\n{\n  int i;\n\n  if (log.lh.n &gt;= LOGSIZE || log.lh.n &gt;= log.size - 1)\n    panic(\"too big a transaction\");\n  if (log.outstanding &lt; 1)\n    panic(\"log_write outside of trans\");\n\n  acquire(&amp;log.lock);\n  for (i = 0; i &lt; log.lh.n; i++) {\n    if (log.lh.block[i] == b-&gt;blockno)   // log absorbtion\n      break;\n  }\n  log.lh.block[i] = b-&gt;blockno;\n  if (i == log.lh.n) {  // Add new block to log?\n    bpin(b);\n    log.lh.n++;\n  }\n  release(&amp;log.lock);\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#end_op","title":"<code>end_op</code>","text":"<p><code>end_op</code>\u4e3b\u8981\u5e72\u4e86\u4e24\u4ef6\u4e8b</p> <ol> <li>\u5c06\u5bf9log\u8fdb\u884c\u5199\u5165\u7684system call\u7684\u6570\u91cf\u51cf1</li> <li>commit()</li> </ol> <p><code>end_op</code>\u7684\u6838\u5fc3\u662fcommit\u51fd\u6570\uff0c\u9664\u6b64\u4e4b\u5916\uff0c\u5b83\u6240\u505a\u7684\u5c31\u662f\u5982\u679ccommit\u7684\u6761\u4ef6\u6ca1\u6709\u8fbe\u6210\uff0c\u53ca\u8fd8\u6709system call\u6ca1\u6709\u5b8c\u6210\u6574\u4e2a\u4e8b\u52a1\uff0c\u90a3\u4e48\u5728<code>begin_op</code>\u8fdb\u5165\u963b\u585e\u7684\u8fdb\u7a0b\u3002</p> <pre><code>// called at the end of each FS system call.\n// commits if this was the last outstanding operation.\nvoid\nend_op(void)\n{\n  int do_commit = 0;\n\n  acquire(&amp;log.lock);\n  log.outstanding -= 1;\n  if(log.committing)\n    panic(\"log.committing\");\n  if(log.outstanding == 0){\n    do_commit = 1;\n    log.committing = 1;\n  } else {\n    // begin_op() may be waiting for log space,\n    // and decrementing log.outstanding has decreased\n    // the amount of reserved space.\n    wakeup(&amp;log);\n  }\n  release(&amp;log.lock);\n\n  if(do_commit){\n    // call commit w/o holding locks, since not allowed\n    // to sleep with locks.\n    commit();\n    acquire(&amp;log.lock);\n    log.committing = 0;\n    wakeup(&amp;log);\n    release(&amp;log.lock);\n  }\n}\n</code></pre> <ul> <li> <p><code>end_op</code> (kernel/log.c:146) first decrements the count of outstanding system calls.</p> </li> <li> <p>If the count is now zero, it commits the current transaction by calling <code>commit()</code>.</p> </li> </ul> <p>\u4e0b\u9762\u5c31\u662f<code>end_op</code>\u7684\u6838\u5fc3\uff0c\u4e5f\u662flog\u8fd9\u4e00\u8282\u7684\u6838\u5fc3\uff0ccommit\u4e86\u3002</p> <pre><code>static void\ncommit()\n{\n  if (log.lh.n &gt; 0) {\n    write_log();     // Write modified blocks from cache to log\n    write_head();    // Write header to disk -- the real commit\n    install_trans(0); // Now install writes to home locations\n    log.lh.n = 0;\n    write_head();    // Erase the transaction from the log\n  }\n}\n</code></pre> <ul> <li> <p>There are four stages in this process. <code>write_log()</code> (kernel/log.c:178) copies each block modified in the transaction from the buffer cache to its slot in the log on disk.</p> <p>\u7b2c\u4e00\u6b65\uff0c\u628alog header\u4e2d\u8bb0\u5f55\u7684\u6bcf\u4e00\u4e2a\u88ab\u4fee\u6539\u7684BLOCK\u4e2d\u4ece\u4ed6\u4eec\u7684buffer cache\u4e2d\uff0c\u8f6c\u79fb\u5230log\u5bf9\u5e94\u7684buffer cache\u4e2d\u3002\uff08\u4fee\u6539\u8fd8\u5728\u5185\u5b58\u4e4b\u4e2d\uff09</p> <p>\u7136\u540e\uff0c\u628alog\u4e2d\u7684\u5728buffer cache\u4e2d\u7684\u5185\u5bb9\u540c\u6b65\u5230disk\u7684log\u4e4b\u4e2d\u3002</p> <pre><code>// Copy modified blocks from cache to log.\nstatic void\nwrite_log(void)\n{\n  int tail;\n\n  for (tail = 0; tail &lt; log.lh.n; tail++) {\n    struct buf *to = bread(log.dev, log.start+tail+1); // log block\n    struct buf *from = bread(log.dev, log.lh.block[tail]); // cache block\n    memmove(to-&gt;data, from-&gt;data, BSIZE);\n    bwrite(to);  // write the log\n    brelse(from);\n    brelse(to);\n  }\n}\n</code></pre> </li> <li> <p><code>write_head()</code> (kernel/log.c:102) writes the header block to disk: this is the commit point, and a crash after the write will result in recovery replaying the transaction\u2019s writes from the log.</p> <p>\u7b2c\u4e8c\u6b65\uff0c\u4fee\u6539\u5185\u5b58\u4e2d\u7684log header\uff0c\u5c06\u8fd9\u6b21\u4e8b\u52a1\u6d89\u53ca\u5230\u7684BLOCK\u6570\u91cf\u5199\u5165\u5230log header\u5bf9\u5e94\u7684disk\u90e8\u5206</p> <p>\u8fd9\u91cc\u662f**commit\u771f\u7684\u53d1\u751f\u7684\u5730\u65b9**\uff0c\u91cd\u70b9\u5728\u4e8e<code>bwrite(buf)</code></p> <p><code>bwrite(buf)</code>\u4e4b\u524d\u65ad\u7535\uff0cdisk\u7684log header\u4e2dn == 0\uff0c\u6240\u4ee5\u4e4b\u524d\u7684\u4e8b\u52a1\u5b8c\u5168\u4e0d\u4f5c\u6570\uff0c\u4e0d\u4f1a\u540c\u6b65\u5230disk\u4e0a\u3002</p> <p><code>bwrite(buf)</code>\u4e4b\u540e\u65ad\u7535\uff0cdisk\u7684log header\u4e2dn \uff01= 0\uff0c\u6240\u4ee5OS\u4f1a\u628alog\u4e2d\u5b58\u50a8\u7684n\u4e2aBLOCKS\u4e2d\u7684\u5185\u5bb9\u540c\u6b65\u5230disk\u4e0a\u3002</p> <pre><code>// Write in-memory log header to disk.\n// This is the true point at which the\n// current transaction commits.\nstatic void\nwrite_head(void)\n{\n  struct buf *buf = bread(log.dev, log.start);\n  struct logheader *hb = (struct logheader *) (buf-&gt;data);\n  int i;\n  hb-&gt;n = log.lh.n;\n  for (i = 0; i &lt; log.lh.n; i++) {\n    hb-&gt;block[i] = log.lh.block[i];\n  }\n  bwrite(buf);\n  brelse(buf);\n}\n</code></pre> </li> <li> <p><code>install_trans</code> (kernel/log.c:69) reads each block from the log and writes it to the proper place in the file system.</p> <p><code>install_trans</code>\u6240\u505a\u7684\u4e8b\uff0c\u5c31\u662f\u628alog\u8bb0\u5f55\u7684BLOCKS\u5168\u90e8\u540c\u6b65\u5230\u4ed6\u4eec\u5728disk\u4e0a\u7684\u5bf9\u5e94\u4f4d\u7f6e\u4e0a\u53bb\u3002</p> <p><code>install_trans</code>\u4f1a\u5728\u4e24\u79cd\u60c5\u51b5\u4e0b\u88ab\u8c03\u7528</p> <ol> <li>\u6062\u590d\u7684\u65f6\u5019</li> <li>\u6b63\u5e38\u7684\u6587\u4ef6\u5199\u64cd\u4f5c\u6267\u884c\u7684\u65f6\u5019</li> </ol> <p>\u53ef\u4ee5\u770b\u5230\u4ee3\u7801\u4e5f\u5bf9\u8fd9\u4e24\u79cd\u60c5\u51b5\u8fdb\u884c\u4e86\u533a\u5206\uff0c\u5982\u679c\u662f\u6062\u590d\uff0c\u90a3\u5c31\u4e0d\u6d89\u53ca\u91ca\u653ebuffer cache\u7684\u95ee\u9898\uff1b\u5982\u679c\u662f\u6b63\u5e38\u6267\u884c\uff0c\u90a3\u5c31\u5f97\u628a<code>begin_op</code>\u7ed9buffer cache\u52a0\u7684\u5f15\u7528\u7ed9\u6d88\u9664\u3002</p> <pre><code>// Copy committed blocks from log to their home location\nstatic void\ninstall_trans(int recovering)\n{\n  int tail;\n\n  for (tail = 0; tail &lt; log.lh.n; tail++) {\n    struct buf *lbuf = bread(log.dev, log.start+tail+1); // read log block\n    struct buf *dbuf = bread(log.dev, log.lh.block[tail]); // read dst\n    memmove(dbuf-&gt;data, lbuf-&gt;data, BSIZE);  // copy block to dst\n    bwrite(dbuf);  // write dst to disk\n    if(recovering == 0)\n      bunpin(dbuf);\n    brelse(lbuf);\n    brelse(dbuf);\n  }\n}\n</code></pre> </li> <li> <p>Finally <code>end_op</code> writes the log header with a count of zero;</p> </li> </ul> <pre><code>static void\ncommit()\n{\n  if (log.lh.n &gt; 0) {\n    write_log();     // Write modified blocks from cache to log\n    write_head();    // Write header to disk -- the real commit\n    install_trans(0); // Now install writes to home locations\n    log.lh.n = 0;\n    write_head();    // Erase the transaction from the log\n  }\n}\n</code></pre> <p>\u6700\u540e\u6211\u4eec\u518d\u6b21\u4fee\u6539log header\u4e2d\u7684n\u503c\u4e3a0\uff0c\u5e76\u628a\u5b83\u5199\u5165disk</p> <p>\u6700\u540e\u7684\u8fd9\u6b21\u5bf9header\u7684\u5199\u5165\u5fc5\u987b\u53d1\u751f\u5728\u4e0b\u4e00\u6b21\u4e8b\u52a1\u5f00\u59cb\u4e4b\u524d\uff0c<code>end_op</code>\u4fdd\u8bc1\u4e86\u8fd9\u4e00\u70b9\u3002\u5982\u679c\u4e0d\u8fd9\u6837\u7684\u8bdd\uff0c\u5982\u679c\u53d1\u751f\u4e86crash\uff0clog\u7684disk\u4e2d\u8bb0\u5f55\u7684\u662f\u65b0Transaction\u4fdd\u5b58\u5728log\u4e2d\u7684\u4fee\u6539\u5185\u5bb9\uff0c\u800cn\u5374\u8fd8\u662f\u4e0a\u4e00\u4e2aTransaction\u7684\u8ba1\u6570\u3002</p> <p>\u8fd9\u4e5f\u5c31\u89e3\u91ca\u4e86\uff0c\u4e00\u4e2a\u4e8b\u52a1\u5fc5\u987b\u5168\u90e8\u5b8c\u6210\u4e4b\u540e\uff0c\u624d\u4f1a\u5141\u8bb8\u65b0\u7684\u4e8b\u52a1\u5f00\u59cb\u3002</p> <p>this has to happen before the next transaction starts writing logged blocks, so that a crash doesn\u2019t result in recovery using one transaction\u2019s header with the subsequent transaction\u2019s logged blocks.</p> <p><code>recover_from_log</code> (kernel/log.c:116) is called from <code>initlog</code> (kernel/log.c:55), which is called from <code>fsinit</code>(kernel/fs.c:42) during boot before the first user process runs (kernel/proc.c:539). It reads the log header, and mimics the actions of end_op if the header indicates that the log contains a committed transaction.</p> <pre><code>static void\nrecover_from_log(void)\n{\n  read_head();\n  install_trans(1); // if committed, copy from log to disk\n  log.lh.n = 0;\n  write_head(); // clear the log\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#summary-figure","title":"Summary Figure","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#journaling-the-linux-ext2fs-filesystem","title":"Journaling the Linux ext2fs Filesystem","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#labs","title":"Labs","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#gdb","title":"GDB","text":"<pre><code>$ make CPUS=1 qemu-gdb\n*** Now run 'gdb' in another window. qemu-system-riscv64 -machine virt -bios none -kernel kernel/kernel -m 128M -smp 3 -nographic -drive file=fs.img,if=none,format=raw,id=x0 -device virtio-blk-device,drive=x0,bus=virtio-mmio-bus.0 -S -gdb tcp::26000\n</code></pre> <pre><code>echo \"add-auto-load-safe-path $(pwd)/.gdbinit \" &gt;&gt; ~/.gdbinit\n\n$ gdb-multiarch\n</code></pre> <pre><code>(gdb) layout split\n\n(gdb) file user/_ls\n(gdb) b main\n(gdb) c\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#lab-xv6-and-unix-utilities","title":"Lab: Xv6 and Unix utilities","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#sleep_1","title":"sleep","text":"<p>\u6b8b\u7559\u95ee\u9898\uff1awhile\u5faa\u73af\u7528\u4e8e\u786e\u4fdd\u7528\u6237\u7684\u8f93\u5165\u53ea\u6709\u6570\u5b57\uff0c\u4f46\u5728<code>xv6</code> \u8fd0\u884c\u8fc7\u7a0b\u4e2d\u4f1a\u6709\u8fd0\u884c\u5931\u8d25\u7684\u60c5\u51b5\u3002\u672a\u80fd\u5b9a\u4f4d\u539f\u56e0\u3002\u5220\u53bbwhile\u53ef\u4ee5\u5b8c\u7f8e\u8fd0\u884c\u4f46\u903b\u8f91\u4e0d\u5b8c\u6574\u3002</p> <pre><code>##include \"kernel/types.h\"\n##include \"kernel/stat.h\"\n##include \"user/user.h\"\n\nint main(int argc, char *argv[])\n{\n    if (argc != 2)\n    {\n        fprintf(2, \"usage: sleep ticks....\\n\");\n        exit(1);\n    }\n\n    char *s = argv[1];\n    //Since the end of s points to 0x0000 0000 (NULL)\n    //So while can be terminated\n    while (*s)\n    {\n        if ('0' &lt;= *s &amp;&amp; *s &lt;= '9')\n            s++;\n        else\n        {\n            fprintf(2, \"only digits are allowed in inputs\\n\");\n            exit(1);\n        }\n    }\n\n    int ticks = atoi(argv[1]);\n\n    sleep(ticks);\n\n    exit(0);\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#pingpong","title":"pingpong","text":"<p>\u8bb0\u5f97\u5728\u4f7f\u7528\u5b8cfile descriptor\u540e\u5c06\u5176\u5173\u95ed\uff0c\u5426\u5219\u5f53\u591a\u6b21\u8fd0\u884cping pong\u540e\uff0c<code>pipe()</code>\u5c31\u6ca1\u6709\u591a\u4f59\u7684file descriptor\u53ef\u4f9b\u5206\u914d\u4e86\u3002</p> <p></p> <pre><code>##include \"kernel/types.h\"\n##include \"kernel/stat.h\"\n##include \"user/user.h\"\n\nint main(int argc, char const *argv[])\n{\n    int p2c[2];\n    int c2p[2];\n    pipe(p2c);\n    pipe(c2p);\n\n    char ball;\n\n    int pid = fork();\n    if (pid &lt; 0)\n    {\n        fprintf(2, \"fork error\");\n        exit(1);\n    }\n\n    if (pid == 0)\n    {\n        close(p2c[1]);\n        read(p2c[0], &amp;ball, 1);\n        close(p2c[0]);\n        printf(\"%d: received ping\\n\", getpid());\n\n        close(c2p[0]);\n        write(c2p[1], &amp;ball, 1);\n        close(c2p[1]);\n        exit(0);\n    }\n    else\n    {\n        close(p2c[0]);\n        write(p2c[1], &amp;ball, 1);\n        close(p2c[1]);\n        wait(0);\n\n        close(c2p[1]);\n        read(c2p[0], &amp;ball, 1);\n        close(c2p[0]);\n        printf(\"%d: received pong\\n\", getpid());\n    }\n\n    exit(0);\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#primes","title":"primes(*)","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#find","title":"find","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#lab-system-calls","title":"Lab: system calls","text":"<p>\u672c\u90e8\u5206\u8bb0\u5f55\u4e86\u7cfb\u7edf\u8c03\u7528\u7684\u6574\u4e2a\u8fc7\u7a0b\uff0c\u6240\u6709\u7684\u5b9e\u73b0\u7ec6\u8282\u89c1<code>github</code>\u3002</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#system-call-tracing","title":"System call tracing","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#user-mode_1","title":"user mode","text":"<p>\u5728user mode\u4e2d\u7684<code>user/trace.c</code>\u4e2d\uff0c\u4f7f\u7528\u4e86system call \uff1a<code>trace()</code>\u3002</p> <pre><code>##include \"kernel/param.h\"\n##include \"kernel/types.h\"\n##include \"kernel/stat.h\"\n##include \"user/user.h\"\n\nint\nmain(int argc, char *argv[])\n{\n  int i;\n  char *nargv[MAXARG];\n\n  if(argc &lt; 3 || (argv[1][0] &lt; '0' || argv[1][0] &gt; '9')){\n    fprintf(2, \"Usage: %s mask command\\n\", argv[0]);\n    exit(1);\n  }\n\n  if (trace(atoi(argv[1])) &lt; 0) {\n    fprintf(2, \"%s: trace failed\\n\", argv[0]);\n    exit(1);\n  }\n\n  for(i = 2; i &lt; argc &amp;&amp; i &lt; MAXARG; i++){\n    nargv[i-2] = argv[i];\n  }\n  exec(nargv[0], nargv);\n  exit(0);\n}\n</code></pre> <p><code>trace()</code>\u88ab\u58f0\u660e\u5728<code>user/user.h</code>\u91cc\uff0c</p> <pre><code>int trace(int);\n</code></pre> <p><code>trace()</code>\u7684\u5b9a\u4e49\u5728<code>usys.S</code>\u4e2d\uff0c\u56e0\u4e3a\u6240\u6709\u7684system call\u90fd\u5177\u6709\u76f8\u540c\u5b9a\u4e49\u7684\u5f62\u5f0f\uff0c\u6240\u4ee5\u4e0b\u8fb9\u7684\u4ee3\u7801<code>usys.pl</code>\u53ef\u4ee5\u7528\u6765\u6279\u91cf\u7f16\u5199\u4e0d\u540csystem call\u7684\u6c47\u7f16\u4ee3\u7801\u3002</p> <p>\u5176\u4e2d\uff0c<code>li a7, SYS_${name}\\n</code> \u8fd9\u4e00\u53e5\u662f\u5c06system call\u7684\u7f16\u53f7\u653e\u5165<code>a7</code>\u5bc4\u5b58\u5668\u5f53\u4e2d\u3002system call\u7684\u7f16\u53f7\u8bb0\u5f55\u5728<code>kernel/syscall.h</code>\u6587\u4ef6\u4e2d\u3002</p> <p><code>ecall</code>\u901a\u8fc7\u786c\u4ef6\u5b9e\u73b0user mode\u8fdb\u5165kernel mode\u3002</p> <pre><code>##!/usr/bin/perl -w\n## Generate usys.S, the stubs for syscalls.\nprint \"# generated by usys.pl - do not edit\\n\";\nprint \"#include \\\"kernel/syscall.h\\\"\\n\";\nsub entry {\n    my $name = shift;\n    print \".global $name\\n\";\n    print \"${name}:\\n\";\n    print \" li a7, SYS_${name}\\n\";\n    print \" ecall\\n\";\n    print \" ret\\n\";\n}\n\nentry(\"fork\");\nentry(\"exit\");\nentry(\"wait\");\nentry(\"pipe\");\nentry(\"read\");\n.\n.\n.\nentry(\"trace\");\n</code></pre> <p><code>kernel/syscall.h</code></p> <pre><code>// System call numbers\n##define SYS_fork    1\n##define SYS_exit    2\n##define SYS_wait    3\n##define SYS_pipe    4\n##define SYS_read    5\n##define SYS_kill    6\n##define SYS_exec    7\n##define SYS_fstat   8\n##define SYS_chdir   9\n##define SYS_dup    10\n##define SYS_getpid 11\n##define SYS_sbrk   12\n##define SYS_sleep  13\n##define SYS_uptime 14\n##define SYS_open   15\n##define SYS_write  16\n##define SYS_mknod  17\n##define SYS_unlink 18\n##define SYS_link   19\n##define SYS_mkdir  20\n##define SYS_close  21\n##define SYS_trace  22\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#kernel-mode","title":"kernel mode","text":"<p>\u5728\u5185\u6838\u6001\uff0c\u6267\u884csystem call\u7684\u5165\u53e3\u5728<code>kernel/syscall.c</code>\u4e2d\u3002<code>uint64 (*syscalls[])(void)</code> \u662f\u4e00\u4e2a\u51fd\u6570\u6307\u9488\u6570\u7ec4\uff0c\u7c7b\u4f3c\u4e8ejava\u4e2d\u7684<code>Method[]</code>.</p> <p><code>void syscall(void)</code>\u662f\u6267\u884c\u7cfb\u7edf\u8c03\u7528\u7684\u6838\u5fc3\u4ee3\u7801\uff0c\u4ed6\u4ece\u5f53\u524d\u8fdb\u7a0b\u7684\u9875\u8868\u4e2d\u53d6\u51fa<code>a7</code>\u4e2d\u4fdd\u5b58\u7684\u7cfb\u7edf\u8c03\u7528\u53f7\u7801\uff0c\u7136\u540e\u4ece\u6307\u9488\u6570\u7ec4\u4e2d\u53d6\u51fa\u5bf9\u5e94\u7684\u51fd\u6570\u5e76\u6267\u884c\uff0c\u5c06\u8fd4\u56de\u503c\u5199\u5165\u9875\u8868\u7684<code>a0</code>\u5bc4\u5b58\u5668\u4e2d\u3002</p> <p><code>kernel/syscall.c</code></p> <pre><code>static uint64 (*syscalls[])(void) = {\n[SYS_fork]    sys_fork,\n[SYS_exit]    sys_exit,\n[SYS_wait]    sys_wait,\n[SYS_pipe]    sys_pipe,\n[SYS_read]    sys_read,\n[SYS_kill]    sys_kill,\n[SYS_exec]    sys_exec,\n[SYS_fstat]   sys_fstat,\n[SYS_chdir]   sys_chdir,\n[SYS_dup]     sys_dup,\n[SYS_getpid]  sys_getpid,\n[SYS_sbrk]    sys_sbrk,\n[SYS_sleep]   sys_sleep,\n[SYS_uptime]  sys_uptime,\n[SYS_open]    sys_open,\n[SYS_write]   sys_write,\n[SYS_mknod]   sys_mknod,\n[SYS_unlink]  sys_unlink,\n[SYS_link]    sys_link,\n[SYS_mkdir]   sys_mkdir,\n[SYS_close]   sys_close,\n[SYS_trace]   sys_trace,\n};\n\nvoid\nsyscall(void)\n{\n  int num;\n  struct proc *p = myproc();\n  num = p-&gt;trapframe-&gt;a7;\n  if(num &gt; 0 &amp;&amp; num &lt; NELEM(syscalls) &amp;&amp; syscalls[num]) {\n    p-&gt;trapframe-&gt;a0 = syscalls[num]();\n    //print trace of syscall\n    if (p-&gt;mask &amp; (1 &lt;&lt; num)) {\n      printf(\"%d: systemcall %s -&gt; %d\\n\",\n              p-&gt;pid, syscallnames[num], p-&gt;trapframe-&gt;a0);\n    }\n  } else {\n    printf(\"%d %s: unknown sys call %d\\n\",\n            p-&gt;pid, p-&gt;name, num);\n    p-&gt;trapframe-&gt;a0 = -1;\n  }\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#get-args-from-user-mode","title":"get <code>args</code> from user mode","text":"<p><code>kernel/sysproc.c</code> \u4e2d\u8bb0\u5f55\u4e86sys_trace\u7684\u5177\u4f53\u5b9e\u73b0\u3002</p> <p>\u4ece<code>uint64 (*syscalls[])(void)</code>\u53ef\u4ee5\u770b\u51fa\uff0c\u6240\u6709\u7684\u7cfb\u7edf\u8c03\u7528\u90fd\u6ca1\u6709\u53c2\u6570\u4f20\u5165\uff0c\u800c\u4e14\u8fd4\u56de\u503c\u7c7b\u578b\u90fd\u4e3auint64\u3002\u90a3\u4e48\uff0c\u7cfb\u7edf\u8c03\u7528\u662f\u5982\u4f55\u4ece\u7528\u6237\u6001\u83b7\u5f97\u4f20\u5165\u7684\u53c2\u6570\u7684\u5462\uff1f<code>kernel/syscall.c</code>\u4e2d\u63d0\u4f9b\u4e86\u8bb8\u591a\u51fd\u6570\u7528\u4e8e\u4ece\u7528\u6237\u6001\u62ff\u5230\u6570\u636e\u5e76\u8d4b\u503c\u7ed9\u5185\u6838\u6001\u7684\u53d8\u91cf\u3002\u4ee5<code>argint(0, &amp;mask)</code>\u4e3a\u4f8b\uff0c\u8be5\u51fd\u6570\u53ef\u4ee5\u5c06\u7528\u6237\u6001\u4f20\u5165\u7684\u7b2c0\u4e2a\u53c2\u6570\u8d4b\u503c\u7ed9\u5185\u6838\u6001\u53d8\u91cfmask\u3002</p> <pre><code>//trace system calls of a process and its child process\nuint64\nsys_trace(void)\n{\n  int mask;\n\n  //get 0th arg from user mode sys call trace(int mask)\n  if(argint(0, &amp;mask) &lt; 0)\n    return -1;\n\n  myproc()-&gt;mask = mask;\n\n  return 0;\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#sysinfo","title":"Sysinfo","text":"<p>\u7cfb\u7edf\u8c03\u7528\u7684\u8fc7\u7a0b\u4e0d\u518d\u8d58\u8ff0\uff0c\u8fd9\u4e00\u90e8\u5206\u7684\u5b9e\u9a8c\u6d89\u53ca\u4e86process\u548cpage table\u7684\u90e8\u5206\u4ee3\u7801\uff0c\u8fd9\u91cc\u4e0d\u505a\u8be6\u8ff0\u3002\u8fd9\u4e2a\u5b9e\u9a8c\u7684\u91cd\u70b9\u5728\u4e8e\uff0c\u5185\u6838\u6001\u5982\u4f55\u628a\u5185\u6838\u6001\u4e2d\u7684\u53d8\u91cf\u8fd4\u56de\u7ed9\u7528\u6237\u6001\u3002<code>copyout(p-&gt;pagetable, st, (char *)&amp;xv6info, sizeof(xv6info))</code>\u505a\u5230\u4e86\u8fd9\u4e00\u70b9\uff0c<code>copyout</code>\u662f\u5982\u4f55\u505a\u5230\u7684\u4e0d\u662f\u8fd9\u4e2alab\u7684\u91cd\u70b9\uff0c\u4f1a\u5728\u4e4b\u540e\u7684\u7ae0\u8282\u4e2d\u8bb2\u660e\u3002</p> <p><code>kernel/sysproc.c</code></p> <pre><code>//return sysinfo to user space\nuint64\nsys_sysinfo(void)\n{\n  uint64 st; // user pointer to struct sysinfo\n  struct sysinfo xv6info;\n\n  //get syscall args[0]\n  //in this case, the argument is a address\n  //points to struct sysinfo\n  //\u62ff\u5230\u7528\u6237\u6001\u7684\u53c2\u6570-&gt;\u4e00\u4e2a\u6307\u5411sysinfo\u7684\u6307\u9488\n  if(argaddr(0, &amp;st) &lt; 0)\n    return -1;\n\n  xv6info.freemem = free_memory();\n  xv6info.nproc = num_process();\n\n  struct proc *p = myproc();\n  //\u5c06\u5185\u6838\u6001\u83b7\u5f97\u7684xv6info\u6309\u5b57\u8282\u590d\u5236\u5230\u4e4b\u524d\u83b7\u5f97\u7684\u7528\u6237\u5730\u5740\u6307\u5411\u7684\u5185\u5b58\u533a\u57df\u4e2d\n  if(copyout(p-&gt;pagetable, st, (char *)&amp;xv6info, sizeof(xv6info)) &lt; 0)\n      return -1;\n\n  return 0;\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#lab-page-table","title":"Lab: Page Table","text":"<pre><code>test sbrkbugs: usertrap(): unexpected scause 0x000000000000000c pid=3234\n            sepc=0x0000000000005406 stval=0x0000000000005406\nusertrap(): unexpected scause 0x000000000000000c pid=3235\n            sepc=0x0000000000005406 stval=0x0000000000005406\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#lab3-page-tables","title":"Lab3 : Page Tables","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#lab-31-print-a-page-table","title":"Lab 3.1 Print a page table","text":"<p>Define a function called <code>vmprint()</code>. It should take a <code>pagetable_t</code> argument, and print that page table in the format described below. Insert <code>if(p-&gt;pid==1) vmprint(p-&gt;pagetable)</code> in <code>exec.c</code> just before the <code>return argc</code>, to print the first process's page table.</p> <pre><code>page table 0x0000000087f6e000\n..0: pte 0x0000000021fda801 pa 0x0000000087f6a000\n.. ..0: pte 0x0000000021fda401 pa 0x0000000087f69000\n.. .. ..0: pte 0x0000000021fdac1f pa 0x0000000087f6b000\n.. .. ..1: pte 0x0000000021fda00f pa 0x0000000087f68000\n.. .. ..2: pte 0x0000000021fd9c1f pa 0x0000000087f67000\n..255: pte 0x0000000021fdb401 pa 0x0000000087f6d000\n.. ..511: pte 0x0000000021fdb001 pa 0x0000000087f6c000\n.. .. ..510: pte 0x0000000021fdd807 pa 0x0000000087f76000\n.. .. ..511: pte 0x0000000020001c0b pa 0x0000000080007000\n</code></pre> <p>The first line displays the argument to <code>vmprint</code>. After that there is a line for each PTE, including PTEs that refer to page-table pages deeper in the tree. Each PTE line is indented by a number of <code>\" ..\"</code> that indicates its depth in the tree. Each PTE line shows the PTE index in its page-table page, the <code>pte</code> bits, and the physical address extracted from the PTE. Don't print PTEs that are not valid. In the above example, the top-level page-table page has mappings for entries 0 and 255. The next level down for entry 0 has only index 0 mapped, and the bottom-level for that index 0 has entries 0, 1, and 2 mapped.</p> <pre><code>// Print pagetable\n// display its three level tree\nvoid\nvmprint(pagetable_t pagetable)\n{\n  printf(\"page table %p\\n\", pagetable);\n  pteprint(pagetable, 1);\n}\n\n//A helper function to aid vmprint()\nvoid\npteprint(pagetable_t pagetable, int level)\n{\n  for (int i = 0; i &lt; 512; i++) {\n    pte_t pte = pagetable[i];\n    //pte\u662f\u975e\u53f6\u5b50\u8282\u70b9\uff0c\u5176flags\u7684\u540e\u516b\u4f4d\u53ea\u6709PTE_V = 1\n    if((pte &amp; PTE_V) &amp;&amp; (pte &amp; (PTE_R|PTE_W|PTE_X)) == 0) {\n        // this PTE points to a lower-level page table.\n        // print page table level\n        for (int j = 0; j &lt; level; j++) {\n        if(j != 0)\n            printf(\" \");\n        printf(\"..\");\n        }\n\n        uint64 child = PTE2PA(pte);\n        printf(\"%d: pte %p pa %p\\n\", i, pte, child);\n        pteprint((pagetable_t) child, level + 1);\n    } else if((pte &amp; PTE_V)) {\n        //pte\u662f\u53f6\u5b50\u8282\u70b9\uff0c\u5176flags\u7684\u540e\u516b\u4f4d\u4e0d\u53ea\u6709PTE_V = 1\n        // print page table level\n        for (int j = 0; j &lt; level; j++) {\n          if(j != 0)\n            printf(\" \");\n          printf(\"..\");\n        }\n      printf(\"%d: pte %p pa %p\\n\", i, pte, PTE2PA(pte));\n    }\n  }\n}\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#lab-32-a-kernel-page-table-per-process","title":"Lab 3.2 A kernel page table per process","text":"<p>Xv6 has a single kernel page table that's used whenever it executes in the kernel. The kernel page table is a direct mapping to physical addresses, so that kernel virtual address x maps to physical address x. Xv6 also has a separate page table for each process's user address space, containing only mappings for that process's user memory, starting at virtual address zero. Because the kernel page table doesn't contain these mappings, user addresses are not valid in the kernel. Thus, when the kernel needs to use a user pointer passed in a system call (e.g., the buffer pointer passed to <code>write()</code>), the kernel must first translate the pointer to a physical address. The goal of this section and the next is to allow the kernel to directly dereference user pointers.</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#lab4-traps","title":"Lab4: Traps","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#lab-32-alarm","title":"Lab 3.2 Alarm","text":"<p><code>kernel/proc.h</code></p> <pre><code>// store the alarm interval and the pointer to the handler function\n// for lab alarm\n  int ticks;\n  int passed_ticks;            // how many ticks have passed since the last call\n  uint64 handler;              // the user space address of handler function\n  struct trapframe *alarm_trapframe; // contains the state of the user process before calling sigalarm()\n  int alarm_mode;\n};\n</code></pre> <p>ticks\u8868\u793a\u591a\u5c11\u4e2a\u65f6\u949f\u5468\u671f\u8fd0\u884c\u4e00\u6b21handler</p> <p>passed_ticks\u8868\u793a\u5f53\u524d\u8fdb\u7a0b\u4ece\u4e0a\u4e00\u6b21\u56de\u8c03\u51fd\u6570\u7ed3\u675f\u8d77\u7ecf\u8fc7\u4e86\u591a\u5c11\u4e2a\u65f6\u949f\u5468\u671f</p> <p>handler\u5b58\u653e\u7684\u662f\u7528\u6237\u6001\u4e0bhandler\u51fd\u6570\u7684\u5730\u5740</p> <p><code>alarm_trapframe</code>\u7528\u4e8e\u4fdd\u5b58\u8c03\u7528handler\u65f6\uff0c\u7528\u6237\u8fdb\u7a0b\u7684\u72b6\u6001</p> <p>alarm_mode\u8868\u793a\u5f53\u524d\u8fdb\u7a0b\u662f\u5426\u5904\u5728\u4e00\u4e2aalarm\u72b6\u6001\u4e4b\u4e2d</p> <p><code>kernel/sysproc.c</code></p> <pre><code>uint64\nsys_sigalarm(void)\n{\n  int ticks;\n  uint64 handler;\n  struct proc *p = myproc();\n\n  // get ticks from user trapframe\n  if(argint(0, &amp;ticks) &lt; 0)\n    return -1;\n\n  // get handler address from user trapframe\n  if(argaddr(1, &amp;handler))\n    return -1;\n\n  // check if the process has already\n  // been in a sigalarm\n  // sigalarm(2, 0) cannot be called again\n  // but sigalarm(0, 0) can be called to terminate\n  // the sigalarm\n  // \u82e5alarm_mode\u662f\u5f00\u542f\u7684\u4e14\u7528\u6237\u5e76\u6ca1\u6709\u4f20\u6765\u505c\u6b62alarm\u7684\u547d\u4ee4\uff08ticks = 0\uff09\n  // \u5185\u6838\u4e0d\u4f1a\u6267\u884c\u65b0\u7684sigalarm()\u6307\u4ee4\n  if(p-&gt;alarm_mode == 1 &amp;&amp; ticks != 0)\n    return -1;\n\n  p-&gt;ticks = ticks;\n  p-&gt;handler = handler;\n\n  // sigalarm()\u5408\u6cd5\uff0c\u6b64\u65f6\u9700\u8981\u5224\u65ad\u4ed6\u662f\u5f00\u542falarm\u547d\u4ee4\n  // \u8fd8\u662f\u7ed3\u675falarm\u547d\u4ee4\n  if(ticks != 0)\n    p-&gt;alarm_mode = 1;\n  else\n    p-&gt;alarm_mode = 0;\n\n  return 0;\n}\n\nuint64\nsys_sigreturn(void)\n{\n  struct proc *p = myproc();\n  // \u6062\u590d\u8c03\u7528handler\u4e4b\u524d\u7528\u6237\u8fdb\u7a0b\u7684\u72b6\u6001\n  memmove(p-&gt;trapframe, p-&gt;alarm_trapframe, PGSIZE);\n  return 0;\n}\n</code></pre> <p><code>kernel/trap.c</code></p> <pre><code>if(which_dev == 2) {\n    p-&gt;passed_ticks += 1;\n    if (p-&gt;ticks != 0 &amp;&amp; p-&gt;ticks == p-&gt;passed_ticks) {\n      // save the user trapframe, since we will modify it\n      memmove(p-&gt;alarm_trapframe, p-&gt;trapframe, PGSIZE);\n      p-&gt;passed_ticks = 0;\n      p-&gt;trapframe-&gt;epc = p-&gt;handler;\n    }\n    yield();\n  }\n\n  usertrapret();\n}\n</code></pre> <p>\u8fdb\u7a0b\u6bcf\u8fdb\u5165\u4e00\u6b21timer trap\uff0c\u5c31\u5bf9passed_ticks\u52a0\u4e00\u3002\u5f53\u7ecf\u8fc7\u7684\u65f6\u949f\u6b21\u6570\u548c\u9884\u8bbe\u7684\u4e00\u81f4\u65f6\uff0c\u89e6\u53d1handler\uff0c\u8fd9\u91cc\u5e76\u4e0d\u9700\u8981\u6211\u4eec\u4e3b\u52a8\u53bb\u8c03\u7528handler\uff0c\u5c06<code>trapframe</code>\u4e2d\u8bb0\u5f55\u8fd4\u56de\u5730\u5740\u7684<code>epc</code>\u6539\u4e3ahandler\u5373\u53ef\u3002\u540c\u65f6\uff0c\u6211\u4eec\u9700\u8981\u5148\u5c06\u539f\u6765\u7684<code>trapframe</code>\u4fdd\u5b58\u4e0b\u6765\uff0c\u56e0\u4e3a\u6211\u4eec\u5728\u8c03\u7528\u5b8chandler\u4e4b\u540e\u8fd8\u9700\u8981\u8fd4\u56de\u7528\u6237\u8fdb\u7a0btimer\u4e2d\u65ad\u65f6\u7684\u8fd0\u884c\u4f4d\u7f6e\u3002</p> <p>\u6ce8\u610f\uff1atest 2 fork\u4e86\u4e00\u4e2a\u65b0\u7684\u8fdb\u7a0b\u540c\u65f6\u5e76\u6ca1\u6709\u5173\u95edtest 1\u5f00\u542f\u7684alarm\u529f\u80fd\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u4fee\u6539fork()\u90e8\u5206\u7684\u4ee3\u7801\uff0c\u8ba9\u65b0\u7684\u8fdb\u7a0b\u548c\u7236\u8fdb\u7a0b\u7684alarm\u72b6\u6001\u4e00\u81f4\u3002</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#lab5-lazy-allocation","title":"Lab5 Lazy Allocation","text":"","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#lab-51-eliminate-allocation-from-sbrk","title":"Lab 5.1 Eliminate allocation from <code>sbrk()</code>","text":"<pre><code>uint64\nsys_sbrk(void)\n{\n  int addr;\n  int n;\n\n  if(argint(0, &amp;n) &lt; 0)\n    return -1;\n  addr = myproc()-&gt;sz;\n  // if(growproc(n) &lt; 0)\n  //   return -1;\n  // Only increase the size of the process\n  // but allocate no memory for it\n  myproc()-&gt;sz += n;\n  return addr;\n}\n</code></pre> <pre><code>xv6 kernel is booting\n\ninit: starting sh\n$ echo hi\nusertrap(): unexpected scause 0x000000000000000f pid=3\n            sepc=0x00000000000012ac stval=0x0000000000004008\npanic: uvmunmap: not mapped\n</code></pre>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#lab-52-lazy-allocation","title":"Lab 5.2 Lazy Allocation","text":"<pre><code>else if((which_dev = devintr()) != 0){\n    // ok\n  } else {\n    // store/AMO page fault\n    if(r_scause() == 15) {\n      // \u82e5\u53d1\u751f\u4e86\u65e0\u6cd5\u5199\u5165\u7684page fault\n      // \u83b7\u53d6\u65e0\u6cd5\u8bbf\u95ee\u7684\u865a\u62df\u5730\u5740\n      // \u8fd9\u91cc\u8bbf\u95ee\u4e0d\u5230\u7684\u539f\u56e0\u4e3b\u8981\u662f\u6211\u4eec\u52a0\u5165\u4e86\u61d2\u5206\u914d\n      uint64 va = r_stval();\n      uint64 va_downborder = PGROUNDDOWN(va);\n      pagetable_t pagetable = p-&gt;pagetable;\n      // \u7ed9\u8be5\u8fdb\u7a0b\u5206\u914d\u4e00\u9875\u5927\u5c0f\u7684\u7269\u7406\u5185\u5b58\n      uint64 pa = (uint64) kalloc();\n      // \u82e5\u7269\u7406\u5185\u5b58\u5df2\u7ecf\u6ee1\u4e86\uff0c\u90a3\u4e48\u53ea\u80fd\u6740\u6389\u8fdb\u7a0b\n      if(pa == 0) {\n        p-&gt;killed = 1;\n      }\n\n      memset((void *)pa, 0, PGSIZE);\n      // \u4f7f\u5f97\u7528\u6237\u65e0\u6cd5\u8bbf\u95ee\u7684\u9875\u8868\u90e8\u5206\u4e0e\u65b0\u5206\u914d\u7684\u7269\u7406\u5185\u5b58\u5efa\u7acb\u6620\u5c04\n      // \u7ed9\u4e88\u5979\u4eec\u53ef\u88ab\u8bfb\u5199\u7684\u6743\u9650\n      if(mappages(pagetable, va_downborder, PGSIZE, pa, PTE_W|PTE_R|PTE_U) != 0){\n          kfree((void *) pa);\n          p-&gt;killed = 1;\n      }\n      // \u4e4b\u540e\u4e2d\u65ad\u8fd4\u56de\u51fa\u73b0\u9519\u8bef\u7684\u7a0b\u5e8f\u5730\u5740\uff0c\u7ee7\u7eed\u6267\u884c\uff0c\u8fd9\u65f6\u4e4b\u524d\u65e0\u6cd5\u8bfb\u5199\u7684\u5185\u5b58\u5730\u5740\u5c31\u53ef\u4ee5\u8bfb\u5199\u4e86\n    }\n    else {\n      printf(\"usertrap(): unexpected scause %p pid=%d\\n\", r_scause(), p-&gt;pid);\n      printf(\"            sepc=%p stval=%p\\n\", r_sepc(), r_stval());\n      p-&gt;killed = 1;\n    }\n\n  }\n</code></pre> <p>trap\u6709\u4e09\u79cd\u5f62\u5f0f\uff0c\u8fd9\u91cc\u662f\u5728exception\u7684\u60c5\u51b5\u4e0b\u6dfb\u52a0\u4ee3\u7801\u3002</p> <p>page fault\u4e00\u822c\u6709\u4e24\u79cd\u539f\u56e0\uff0c\u5982\u56fe\u4e2d\u6240\u793a\uff0c13\u4ee3\u8868\u65e0\u6cd5\u8bfb\uff0c15\u4ee3\u8868\u65e0\u6cd5\u5199\u3002\u8fd9\u91cc\u7684\u76ee\u7684\u4ec5\u4ec5\u53ea\u4e3a\u4e86\u80fd\u8ba9<code>echo hi</code>\u6b63\u5e38\u8fd0\u884c\uff0c\u6240\u4ee5\u6ca1\u6709\u8003\u8651\u8fc7\u591a\u7ec6\u8282\u3002</p>","tags":["operating system"]},{"location":"blog/2022/07/01/notes---xv6/#lab-53-lazytests-and-usertests","title":"Lab 5.3 <code>Lazytests</code> and <code>Usertests</code>","text":"<p>\u5b9e\u9a8c5.2\u4ec5\u4ec5\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u672c\u7684\u529f\u80fd\uff0c\u4f46\u662f\u4ed6\u53ea\u652f\u6301\u4e3a\u6ca1\u6709\u5206\u914d\u5185\u5b58\u7684\u865a\u62df\u5730\u5740\u7a7a\u95f4\u589e\u52a0\u5185\u5b58\uff0c\u4f46\u6ca1\u6709\u8003\u8651\u7528\u6237\u5e0c\u671b\u91ca\u653e\u5185\u5b58\u7684\u8bf7\u6c42</p> <p>\u8fd9\u4e00\u90e8\u5206\u5c31\u662f\u8981\u89e3\u51b3\u8fd9\u4e00\u7c7b\u7684\u8fb9\u754c\u95ee\u9898\uff0c\u4f7f\u5f97\u4ed6\u5177\u6709\u5b8c\u6574\u7684\u529f\u80fd\u3002</p> <p>freewalk\u6309\u7167page\u7684\u4e2a\u6570\u5220\u9664\uff0c\u7136\u800c\u73b0\u5728\u6211\u4eec\u7684\u9875\u8868\u5e76\u4e0d\u662f\u8fde\u7eed\u7684</p> <p></p> <p>\u4e3a\u4ec0\u4e48\u4f1a\u9047\u5230\u8fd9\u4e2a\u95ee\u9898\uff0c\u56e0\u4e3a\u5728\u6211\u4eec\u7f29\u5c0f\u4e86sbrk\u4ee5\u540e</p> <p>test02\u53c8\u5c1d\u8bd5\u5f80\u6ca1\u6709\u6620\u5c04\u7684\u5730\u65b9\u5199\u6570\u636e\uff0c\u8fd9\u65f6\u4e2d\u65ad\u5c31\u53c8\u4f1a\u7ed9\u4ed6\u5206\u914d\u7a7a\u95f4\uff0c4\u5c31\u662f\u8fd9\u4e48\u88ab\u5206\u914d\u7684</p> <p>\u6240\u4ee5\u5e94\u8be5\u5148\u5224\u65adva\u662f\u5426\u8d85\u51fa\u4e86size\uff0c\u82e5\u6ca1\u6709\u624d\u80fd\u4e3a\u5b83\u5206\u914d\u7a7a\u95f4</p> <p><code>kernel trap\u95ee\u9898</code></p> <p>user tests\u8fdb\u4e0d\u53bb\uff0c\u4e3b\u8981\u539f\u56e0\u662f<code>trap.c</code>\u903b\u8f91\u592a\u6df7\u4e71\u4e86\uff0c\u9700\u8981\u6539\u4e00\u6539\uff0c\u9519\u8bef\u539f\u56e0\u5728\u4e8e\u5f53<code>kalloc</code>\u5931\u8d25\u4ec5\u4ec5\u5c06killed\u8bbe\u7f6e\u6210\u4e861\uff0c\u4f46\u4e4b\u540e\u7684\u6b63\u5e38\u903b\u8f91\u4f9d\u7136\u4f1a\u88ab\u6267\u884c\u3002\u4e5f\u5c31\u662f\u8bf4\u5185\u6838\u4ee3\u7801\u5728\u4fee\u6539pa==0\u5730\u5740\u7684\u7269\u7406\u5185\u5b58\u91cc\u7684\u6570\u636e\uff0c\u6240\u4ee5kernel\u76f4\u63a5\u51fa\u53d1\u4e86device\u9519\u8bef\u3002</p> <p>// remap \u9519\u8bef \u6211\u4eec\u867d\u7136\u89e3\u51b3\u4e86\u7528\u6237\u76f4\u63a5\u53bb\u8bfb\u5199\u6ca1\u6709\u5206\u914d\u7684va\u7684\u60c5\u51b5\uff0c\u6211\u4eec\u7684\u89e3\u51b3\u65b9\u6848\u662f\u5728walkaddr\u91cc\u5224\u65adva\u662f\u4e0d\u662f\u5728sz\u4e4b\u4e2d\uff0c\u662f\u7684\u8bdd\u5c31\u5206\u914d\u3002\u7136\u800c\uff0c\u8fd9\u6837\u4e00\u6765\uff0c\u6709\u4e9b\u6709pa\ufffd\ufffdva\u4e5f\u4f1a\u88ab\u6211\u4eec\u91cd\u65b0\u5206\u6279\u7a7a\u95f4\u5e76remap\uff0c\u6240\u4ee5\u8981\u5728\u5224\u65adistouchable\u65f6\u518d\u786e\u5b9a\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u8fd9\u4e2ava\u662f\u5426\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\u6620\u5c04\u8fc7\u4e86\u3002</p> <p></p>","tags":["operating system"]},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/archive/2023/","title":"2023","text":""},{"location":"blog/archive/2022/","title":"2022","text":""},{"location":"blog/category/software-engineering/","title":"Software Engineering","text":""},{"location":"blog/category/logic/","title":"Logic","text":""},{"location":"blog/category/computer-science/","title":"Computer Science","text":""},{"location":"blog/page/2/","title":"Blog","text":""}]}